Table of Contents







38 Audio Sinks
38.1 abuffersink
38.2 anullsink
39 Video Filters
39.1 addroi
39.1.1 Examples
39.2 alphaextract
39.3 alphamerge
39.4 amplify
39.4.1 Commands
39.5 ass
39.6 atadenoise
39.6.1 Commands
39.7 avgblur
39.7.1 Commands
39.8 backgroundkey
39.8.1 Commands
39.9 bbox
39.9.1 Commands
39.10 bilateral
39.10.1 Commands
39.11 bilateral_cuda
39.11.1 Examples
39.12 bitplanenoise
39.13 blackdetect
39.14 blackframe
39.15 blend
39.15.1 Examples
39.15.2 Commands
39.16 blockdetect
39.16.1 Examples
39.17 blurdetect
39.17.1 Examples
39.18 bm3d
39.18.1 Examples
39.19 boxblur
39.19.1 Examples
39.20 bwdif
39.21 bwdif_cuda
39.22 ccrepack
39.23 cas
39.23.1 Commands
39.24 chromahold
39.24.1 Commands
39.25 chromakey
39.25.1 Commands
39.25.2 Examples
39.26 chromakey_cuda
39.26.1 Examples
39.27 chromanr
39.27.1 Commands
39.28 chromashift
39.28.1 Commands
39.29 ciescope
39.30 codecview
39.30.1 Examples
39.31 colorbalance
39.31.1 Examples
39.31.2 Commands
39.32 colorcontrast
39.32.1 Commands
39.33 colorcorrect
39.33.1 Commands
39.34 colorchannelmixer
39.34.1 Examples
39.34.2 Commands
39.35 colorize
39.35.1 Commands
39.36 colorkey
39.36.1 Examples
39.36.2 Commands
39.37 colorhold
39.37.1 Commands
39.38 colorlevels
39.38.1 Examples
39.38.2 Commands
39.39 colormap
39.40 colormatrix
39.41 colorspace
39.42 colorspace_cuda
39.43 colortemperature
39.43.1 Commands
39.44 convolution
39.44.1 Commands
39.44.2 Examples
39.45 convolve
39.46 copy
39.47 coreimage
39.47.1 Examples
39.48 corr
39.49 cover_rect
39.49.1 Examples
39.50 crop
39.50.1 Examples
39.50.2 Commands
39.51 cropdetect
39.51.1 Examples
39.51.2 Commands
39.52 cue
39.53 curves
39.53.1 Commands
39.53.2 Examples
39.54 datascope
39.54.1 Commands
39.55 dblur
39.55.1 Commands
39.56 dctdnoiz
39.56.1 Examples
39.57 deband
39.57.1 Commands
39.58 deblock
39.58.1 Examples
39.58.2 Commands
39.59 decimate
39.60 deconvolve
39.61 dedot
39.62 deflate
39.62.1 Commands
39.63 deflicker
39.64 dejudder
39.65 delogo
39.65.1 Examples
39.66 derain
39.67 deshake
39.68 despill
39.68.1 Commands
39.69 detelecine
39.70 dilation
39.70.1 Commands
39.71 displace
39.71.1 Examples
39.72 dnn_classify
39.73 dnn_detect
39.74 dnn_processing
39.74.1 Examples
39.75 drawbox
39.75.1 Examples
39.75.2 Commands
39.76 drawgraph
39.77 drawgrid
39.77.1 Examples
39.77.2 Commands
39.78 drawtext
39.78.1 Syntax
39.78.2 Text expansion
39.78.3 Commands
39.78.4 Examples
39.79 edgedetect
39.79.1 Examples
39.80 elbg
39.81 entropy
39.82 epx
39.83 eq
39.83.1 Commands
39.84 erosion
39.84.1 Commands
39.85 estdif
39.85.1 Commands
39.86 exposure
39.86.1 Commands
39.87 extractplanes
39.87.1 Examples
39.88 fade
39.88.1 Examples
39.89 feedback
39.89.1 Examples
39.90 fftdnoiz
39.91 fftfilt
39.91.1 Examples
39.92 field
39.93 fieldhint
39.94 fieldmatch
39.94.1 p/c/n/u/b meaning
39.94.1.1 p/c/n
39.94.1.2 u/b
39.94.2 Examples
39.95 fieldorder
39.96 fillborders
39.96.1 Commands
39.97 find_rect
39.97.1 Examples
39.98 floodfill
39.99 format
39.99.1 Examples
39.100 fps
39.100.1 Examples
39.101 framepack
39.102 framerate
39.103 framestep
39.104 freezedetect
39.105 freezeframes
39.106 frei0r
39.106.1 Examples
39.106.2 Commands
39.107 fspp
39.108 fsync
39.109 gblur
39.109.1 Commands
39.110 geq
39.110.1 Examples
39.111 gradfun
39.111.1 Examples
39.112 graphmonitor
39.113 grayworld
39.114 greyedge
39.114.1 Examples
39.115 guided
39.115.1 Commands
39.115.2 Examples
39.116 haldclut
39.116.1 Commands
39.116.2 Workflow examples
39.116.2.1 Hald CLUT video stream
39.116.2.2 Hald CLUT with preview
39.117 hflip
39.118 histeq
39.119 histogram
39.119.1 Examples
39.120 hqdn3d
39.120.1 Commands
39.121 hwdownload
39.122 hwmap
39.123 hwupload
39.124 hwupload_cuda
39.125 hqx
39.126 hstack
39.127 hsvhold
39.128 hsvkey
39.129 hue
39.129.1 Examples
39.129.2 Commands
39.130 huesaturation
39.131 hysteresis
39.132 iccdetect
39.133 iccgen
39.134 identity
39.135 idet
39.135.1 Examples
39.136 il
39.136.1 Commands
39.137 inflate
39.137.1 Commands
39.138 interlace
39.139 kerndeint
39.139.1 Examples
39.140 kirsch
39.140.1 Commands
39.141 lagfun
39.141.1 Commands
39.142 lenscorrection
39.142.1 Options
39.142.2 Commands
39.143 lensfun
39.143.1 Examples
39.144 lcevc
39.145 libplacebo
39.145.1 Options
39.145.1.1 Output mode
39.145.1.2 Scaling
39.145.1.3 Debanding
39.145.1.4 Color adjustment
39.145.1.5 Peak detection
39.145.1.6 Tone mapping
39.145.1.7 Dithering
39.145.1.8 Custom shaders
39.145.1.9 Debugging / performance
39.145.2 Commands
39.145.3 Examples
39.146 libvmaf
39.146.1 Examples
39.147 libvmaf_cuda
39.147.1 Examples
39.148 limitdiff
39.148.1 Commands
39.149 limiter
39.149.1 Commands
39.150 loop
39.150.1 Examples
39.151 lut1d
39.151.1 Commands
39.152 lut3d
39.152.1 Commands
39.153 lumakey
39.153.1 Commands
39.154 lut, lutrgb, lutyuv
39.154.1 Commands
39.154.2 Examples
39.155 lut2, tlut2
39.155.1 Commands
39.155.2 Examples
39.156 maskedclamp
39.156.1 Commands
39.157 maskedmax
39.157.1 Commands
39.158 maskedmerge
39.158.1 Commands
39.159 maskedmin
39.159.1 Commands
39.160 maskedthreshold
39.160.1 Commands
39.161 maskfun
39.161.1 Commands
39.162 mcdeint
39.163 median
39.163.1 Commands
39.164 mergeplanes
39.164.1 Examples
39.165 mestimate
39.166 midequalizer
39.167 minterpolate
39.168 mix
39.168.1 Commands
39.169 monochrome
39.169.1 Commands
39.170 morpho
39.170.1 Commands
39.171 mpdecimate
39.172 msad
39.173 multiply
39.173.1 Commands
39.174 negate
39.174.1 Commands
39.175 nlmeans
39.176 nnedi
39.176.1 Commands
39.177 noformat
39.177.1 Examples
39.178 noise
39.178.1 Examples
39.179 normalize
39.179.1 Commands
39.179.2 Examples
39.180 null
39.181 ocr
39.182 ocv
39.182.1 dilate
39.182.2 erode
39.182.3 smooth
39.183 oscilloscope
39.183.1 Commands
39.183.2 Examples
39.184 overlay
39.184.1 Commands
39.184.2 Examples
39.185 overlay_cuda
39.186 owdenoise
39.187 pad
39.187.1 Examples
39.188 palettegen
39.188.1 Examples
39.189 paletteuse
39.189.1 Examples
39.190 perspective
39.191 phase
39.191.1 Commands
39.192 photosensitivity
39.193 pixdesctest
39.194 pixelize
39.194.1 Commands
39.195 pixscope
39.195.1 Commands
39.196 pp
39.196.1 Examples
39.197 pp7
39.198 premultiply
39.199 prewitt
39.199.1 Commands
39.200 pseudocolor
39.200.1 Commands
39.200.2 Examples
39.201 psnr
39.201.1 Examples
39.202 pullup
39.203 qp
39.203.1 Examples
39.204 qrencode
39.204.1 qrencode Expressions
39.204.2 qrencode Text expansion
39.204.3 Examples
39.205 quirc
39.206 random
39.207 readeia608
39.207.1 Commands
39.207.2 Examples
39.208 readvitc
39.208.1 Examples
39.209 remap
39.210 removegrain
39.211 removelogo
39.212 repeatfields
39.213 reverse
39.213.1 Examples
39.214 rgbashift
39.214.1 Commands
39.215 roberts
39.215.1 Commands
39.216 rotate
39.216.1 Examples
39.216.2 Commands
39.217 sab
39.218 scale
39.218.1 Options
39.218.2 Examples
39.218.3 Commands
39.219 scale_cuda
39.219.1 Examples
39.220 scale_npp
39.221 scale2ref_npp
39.221.1 Examples
39.222 scale_vt
39.223 scharr
39.223.1 Commands
39.224 scroll
39.224.1 Commands
39.225 scdet
39.226 selectivecolor
39.226.1 Examples
39.227 separatefields
39.228 setdar, setsar
39.228.1 Examples
39.229 setfield
39.230 setparams
39.231 sharpen_npp
39.232 shear
39.232.1 Commands
39.233 showinfo
39.234 showpalette
39.235 shuffleframes
39.235.1 Examples
39.236 shufflepixels
39.237 shuffleplanes
39.237.1 Examples
39.238 signalstats
39.238.1 Examples
39.239 signature
39.239.1 Examples
39.240 siti
39.240.1 Examples
39.241 smartblur
39.242 sobel
39.242.1 Commands
39.243 spp
39.243.1 Commands
39.244 sr
39.245 ssim
39.245.1 Examples
39.246 stereo3d
39.246.1 Examples
39.247 streamselect, astreamselect
39.247.1 Commands
39.247.2 Examples
39.248 subtitles
39.249 super2xsai
39.250 swaprect
39.250.1 Commands
39.251 swapuv
39.252 tblend
39.253 telecine
39.254 thistogram
39.255 threshold
39.255.1 Commands
39.255.2 Examples
39.256 thumbnail
39.256.1 Examples
39.257 tile
39.257.1 Examples
39.258 tiltandshift
39.259 tinterlace
39.260 tmedian
39.260.1 Commands
39.261 tmidequalizer
39.262 tmix
39.262.1 Examples
39.262.2 Commands
39.263 tonemap
39.263.1 Options
39.264 tpad
39.265 transpose
39.266 transpose_npp
39.267 trim
39.268 unpremultiply
39.269 unsharp
39.269.1 Examples
39.270 untile
39.270.1 Examples
39.271 uspp
39.272 v360
39.272.1 Examples
39.272.2 Commands
39.273 vaguedenoiser
39.274 varblur
39.274.1 Commands
39.275 vectorscope
39.276 vidstabdetect
39.276.1 Examples
39.277 vidstabtransform
39.277.1 Options
39.277.2 Examples
39.278 vflip
39.279 vfrdet
39.280 vibrance
39.280.1 Commands
39.281 vif
39.282 vignette
39.282.1 Expressions
39.282.2 Examples
39.283 vmafmotion
39.284 vstack
39.285 w3fdif
39.285.1 Commands
39.286 waveform
39.287 weave, doubleweave
39.287.1 Examples
39.288 xbr
39.289 xcorrelate
39.290 xfade
39.290.1 Examples
39.291 xmedian
39.291.1 Commands
39.292 xpsnr
39.292.1 Examples
39.293 xstack
39.293.1 Examples
39.294 yadif
39.295 yadif_cuda
39.296 yaepblur
39.296.1 Commands
39.297 zoompan
39.297.1 Examples
39.298 zscale
39.298.1 Options
39.298.2 Commands
40 OpenCL Video Filters
40.1 avgblur_opencl
40.1.1 Example
40.2 boxblur_opencl
40.2.1 Examples
40.3 colorkey_opencl
40.3.1 Examples
40.4 convolution_opencl
40.4.1 Examples
40.5 erosion_opencl
40.5.1 Example
40.6 deshake_opencl
40.6.1 Examples
40.7 dilation_opencl
40.7.1 Example
40.8 nlmeans_opencl
40.9 overlay_opencl
40.9.1 Examples
40.10 pad_opencl
40.11 prewitt_opencl
40.11.1 Example
40.12 program_opencl
40.13 remap_opencl
40.14 roberts_opencl
40.14.1 Example
40.15 sobel_opencl
40.15.1 Example
40.16 tonemap_opencl
40.16.1 Example
40.17 unsharp_opencl
40.17.1 Examples
40.18 xfade_opencl
41 VAAPI Video Filters
41.1 overlay_vaapi
41.1.1 Examples
41.2 tonemap_vaapi
41.2.1 Example
41.3 hstack_vaapi
41.4 vstack_vaapi
41.5 xstack_vaapi
41.6 pad_vaapi
41.7 drawbox_vaapi
41.7.1 Examples
42 Vulkan Video Filters
42.1 avgblur_vulkan
42.2 blend_vulkan
42.3 bwdif_vulkan
42.4 chromaber_vulkan
42.5 color_vulkan
42.6 vflip_vulkan
42.7 hflip_vulkan
42.8 flip_vulkan
42.9 gblur_vulkan
42.10 nlmeans_vulkan
42.11 overlay_vulkan
42.12 transpose_vt
42.13 transpose_vulkan
43 QSV Video Filters
43.1 hstack_qsv
43.2 vstack_qsv
43.3 xstack_qsv
44 Video Sources
44.1 buffer
44.2 cellauto
44.2.1 Examples
44.3 coreimagesrc
44.3.1 Examples
44.4 ddagrab
44.4.1 Examples
44.5 gradients
44.5.1 Commands
44.6 mandelbrot
44.7 mptestsrc
44.8 frei0r_src
44.9 life
44.9.1 Examples
44.10 perlin
44.10.1 Options
44.10.2 Examples
44.11 qrencodesrc
44.11.1 Examples
44.12 allrgb, allyuv, color, colorchart, colorspectrum, haldclutsrc, nullsrc, pal75bars, pal100bars, rgbtestsrc, smptebars, smptehdbars, testsrc, testsrc2, yuvtestsrc
44.12.1 Examples
44.12.2 Commands
44.13 openclsrc
44.14 sierpinski
44.15 zoneplate
44.15.1 Commands
44.15.2 Examples
45 Video Sinks
45.1 buffersink
45.2 nullsink
46 Multimedia Filters
46.1 a3dscope
46.1.1 Commands
46.2 abitscope
46.3 adrawgraph
46.4 agraphmonitor
46.5 ahistogram
46.6 aphasemeter
46.6.1 phasing detection
46.6.2 Examples
46.7 avectorscope
46.7.1 Examples
46.7.2 Commands
46.8 bench, abench
46.8.1 Examples
46.9 concat
46.9.1 Examples
46.9.2 Commands
46.10 ebur128
46.10.1 Examples
46.11 interleave, ainterleave
46.11.1 Examples
46.12 latency, alatency
46.13 metadata, ametadata
46.13.1 Examples
46.14 perms, aperms
46.15 realtime, arealtime
46.15.1 Commands
46.16 segment, asegment
46.16.1 Examples
46.17 select, aselect
46.17.1 Examples
46.18 sendcmd, asendcmd
46.18.1 Commands syntax
46.18.2 Examples
46.19 setpts, asetpts
46.19.1 Examples
46.19.2 Commands
46.20 setrange
46.21 settb, asettb
46.21.1 Examples
46.22 showcqt
46.22.1 Examples
46.23 showcwt
46.24 showfreqs
46.25 showspatial
46.26 showspectrum
46.26.1 Examples
46.27 showspectrumpic
46.27.1 Examples
46.28 showvolume
46.29 showwaves
46.29.1 Examples
46.30 showwavespic
46.30.1 Examples
46.31 sidedata, asidedata
46.32 spectrumsynth
46.32.1 Examples
46.33 split, asplit
46.33.1 Examples
46.34 zmq, azmq
46.34.1 Examples
47 Multimedia Sources
47.1 amovie
47.2 avsynctest
47.2.1 Commands
47.3 movie
47.3.1 Examples
47.3.2 Commands

40 OpenCL Video Filters
Below is a description of the currently available OpenCL video filters.
To enable compilation of these filters you need to configure FFmpeg with
--enable-opencl.
Running OpenCL filters requires you to initialize a hardware device and to pass that device to all filters in any filter graph.
-init_hw_device opencl[=name][:device[,key=value...]]
Initialise a new hardware device of type opencl called name, using the
given device parameters.
-filter_hw_device name
Pass the hardware device called name to all filters in any filter graph.
For more detailed information see https://www.ffmpeg.org/ffmpeg.html#Advanced-Video-options
Example of choosing the first device on the second platform and running avgblur_opencl filter with default parameters on it.
-init_hw_device opencl=gpu:1.0 -filter_hw_device gpu -i INPUT -vf "hwupload, avgblur_opencl, hwdownload" OUTPUT
Since OpenCL filters are not able to access frame data in normal memory, all frame data needs to be uploaded(hwupload) to hardware surfaces connected to the appropriate device before being used and then downloaded(hwdownload) back to normal memory. Note that hwupload will upload to a surface with the same layout as the software frame, so it may be necessary to add a format filter immediately before to get the input into the right format and hwdownload does not support all formats on the output - it may be necessary to insert an additional format filter immediately following in the graph to get the output in a supported format.
40.1 avgblur_opencl
Apply average blur filter.
The filter accepts the following options:
sizeX
Set horizontal radius size.
Range is [1, 1024] and default value is 1.
planes
Set which planes to filter. Default value is 0xf, by which all planes are processed.
sizeY
Set vertical radius size. Range is [1, 1024] and default value is 0. If zero, sizeX value will be used.
40.1.1 Example
Apply average blur filter with horizontal and vertical size of 3, setting each pixel of the output to the average value of the 7x7 region centered on it in the input. For pixels on the edges of the image, the region does not extend beyond the image boundaries, and so out-of-range coordinates are not used in the calculations.
-i INPUT -vf "hwupload, avgblur_opencl=3, hwdownload" OUTPUT
40.2 boxblur_opencl
Apply a boxblur algorithm to the input video.
It accepts the following parameters:
luma_radius, lr
luma_power, lp
chroma_radius, cr
chroma_power, cp
alpha_radius, ar
alpha_power, ap
A description of the accepted options follows.
luma_radius, lr
chroma_radius, cr
alpha_radius, ar
Set an expression for the box radius in pixels used for blurring the
corresponding input plane.
The radius value must be a non-negative number, and must not be
greater than the value of the expression min(w,h)/2 for the
luma and alpha planes, and of min(cw,ch)/2 for the chroma
planes.
Default value for luma_radius is "2". If not specified,
chroma_radius and alpha_radius default to the
corresponding value set for luma_radius.
The expressions can contain the following constants:
w
h
The input width and height in pixels.
cw
ch
The input chroma image width and height in pixels.
hsub
vsub
The horizontal and vertical chroma subsample values. For example, for the
pixel format "yuv422p", hsub is 2 and vsub is 1.
luma_power, lp
chroma_power, cp
alpha_power, ap
Specify how many times the boxblur filter is applied to the
corresponding plane.
Default value for luma_power is 2. If not specified,
chroma_power and alpha_power default to the
corresponding value set for luma_power.
A value of 0 will disable the effect.
40.2.1 Examples
Apply boxblur filter, setting each pixel of the output to the average value of box-radiuses luma_radius, chroma_radius, alpha_radius for each plane respectively. The filter will apply luma_power, chroma_power, alpha_power times onto the corresponding plane. For pixels on the edges of the image, the radius does not extend beyond the image boundaries, and so out-of-range coordinates are not used in the calculations.
Apply a boxblur filter with the luma, chroma, and alpha radius
set to 2 and luma, chroma, and alpha power set to 3. The filter will run 3 times with box-radius set to 2 for every plane of the image.
-i INPUT -vf "hwupload, boxblur_opencl=luma_radius=2:luma_power=3, hwdownload" OUTPUT
-i INPUT -vf "hwupload, boxblur_opencl=2:3, hwdownload" OUTPUT
Apply a boxblur filter with luma radius set to 2, luma_power to 1, chroma_radius to 4, chroma_power to 5, alpha_radius to 3 and alpha_power to 7.
For the luma plane, a 2x2 box radius will be run once.
For the chroma plane, a 4x4 box radius will be run 5 times.
For the alpha plane, a 3x3 box radius will be run 7 times.
-i INPUT -vf "hwupload, boxblur_opencl=2:1:4:5:3:7, hwdownload" OUTPUT
40.3 colorkey_opencl
RGB colorspace color keying.
The filter accepts the following options:
color
The color which will be replaced with transparency.
similarity
Similarity percentage with the key color.
0.01 matches only the exact key color, while 1.0 matches everything.
blend
Blend percentage.
0.0 makes pixels either fully transparent, or not transparent at all.
Higher values result in semi-transparent pixels, with a higher transparency
the more similar the pixels color is to the key color.
40.3.1 Examples
Make every semi-green pixel in the input transparent with some slight blending:
-i INPUT -vf "hwupload, colorkey_opencl=green:0.3:0.1, hwdownload" OUTPUT
40.4 convolution_opencl
Apply convolution of 3x3, 5x5, 7x7 matrix.
The filter accepts the following options:
0m
1m
2m
3m
Set matrix for each plane.
Matrix is sequence of 9, 25 or 49 signed numbers.
Default value for each plane is 0 0 0 0 1 0 0 0 0.
0rdiv
1rdiv
2rdiv
3rdiv
Set multiplier for calculated value for each plane.
If unset or 0, it will be sum of all matrix elements.
The option value must be a float number greater or equal to 0.0. Default value is 1.0.
0bias
1bias
2bias
3bias
Set bias for each plane. This value is added to the result of the multiplication.
Useful for making the overall image brighter or darker.
The option value must be a float number greater or equal to 0.0. Default value is 0.0.
40.4.1 Examples
Apply sharpen:
-i INPUT -vf "hwupload, convolution_opencl=0 -1 0 -1 5 -1 0 -1 0:0 -1 0 -1 5 -1 0 -1 0:0 -1 0 -1 5 -1 0 -1 0:0 -1 0 -1 5 -1 0 -1 0, hwdownload" OUTPUT
Apply blur:
-i INPUT -vf "hwupload, convolution_opencl=1 1 1 1 1 1 1 1 1:1 1 1 1 1 1 1 1 1:1 1 1 1 1 1 1 1 1:1 1 1 1 1 1 1 1 1:1/9:1/9:1/9:1/9, hwdownload" OUTPUT
Apply edge enhance:
-i INPUT -vf "hwupload, convolution_opencl=0 0 0 -1 1 0 0 0 0:0 0 0 -1 1 0 0 0 0:0 0 0 -1 1 0 0 0 0:0 0 0 -1 1 0 0 0 0:5:1:1:1:0:128:128:128, hwdownload" OUTPUT
Apply edge detect:
-i INPUT -vf "hwupload, convolution_opencl=0 1 0 1 -4 1 0 1 0:0 1 0 1 -4 1 0 1 0:0 1 0 1 -4 1 0 1 0:0 1 0 1 -4 1 0 1 0:5:5:5:1:0:128:128:128, hwdownload" OUTPUT
Apply laplacian edge detector which includes diagonals:
-i INPUT -vf "hwupload, convolution_opencl=1 1 1 1 -8 1 1 1 1:1 1 1 1 -8 1 1 1 1:1 1 1 1 -8 1 1 1 1:1 1 1 1 -8 1 1 1 1:5:5:5:1:0:128:128:0, hwdownload" OUTPUT
Apply emboss:
-i INPUT -vf "hwupload, convolution_opencl=-2 -1 0 -1 1 1 0 1 2:-2 -1 0 -1 1 1 0 1 2:-2 -1 0 -1 1 1 0 1 2:-2 -1 0 -1 1 1 0 1 2, hwdownload" OUTPUT
40.5 erosion_opencl
Apply erosion effect to the video.
This filter replaces the pixel by the local(3x3) minimum.
It accepts the following options:
threshold0
threshold1
threshold2
threshold3
Limit the maximum change for each plane. Range is [0, 65535] and default value is 65535.
If 0, plane will remain unchanged.
coordinates
Flag which specifies the pixel to refer to.
Range is [0, 255] and default value is 255, i.e. all eight pixels are used.
Flags to local 3x3 coordinates region centered on x:
1 2 3
4 x 5
6 7 8
40.5.1 Example
Apply erosion filter with threshold0 set to 30, threshold1 set 40, threshold2 set to 50 and coordinates set to 231, setting each pixel of the output to the local minimum between pixels: 1, 2, 3, 6, 7, 8 of the 3x3 region centered on it in the input. If the difference between input pixel and local minimum is more then threshold of the corresponding plane, output pixel will be set to input pixel - threshold of corresponding plane.
-i INPUT -vf "hwupload, erosion_opencl=30:40:50:coordinates=231, hwdownload" OUTPUT
40.6 deshake_opencl
Feature-point based video stabilization filter.
The filter accepts the following options:
tripod
Simulates a tripod by preventing any camera movement whatsoever from the original frame. Defaults to 0.
debug
Whether or not additional debug info should be displayed, both in the processed output and in the console.
Note that in order to see console debug output you will also need to pass -v verbose to ffmpeg.
Viewing point matches in the output video is only supported for RGB input.
Defaults to 0.
adaptive_crop
Whether or not to do a tiny bit of cropping at the borders to cut down on the amount of mirrored pixels.
Defaults to 1.
refine_features
Whether or not feature points should be refined at a sub-pixel level.
This can be turned off for a slight performance gain at the cost of precision.
Defaults to 1.
smooth_strength
The strength of the smoothing applied to the camera path from 0.0 to 1.0.
1.0 is the maximum smoothing strength while values less than that result in less smoothing.
0.0 causes the filter to adaptively choose a smoothing strength on a per-frame basis.
Defaults to 0.0.
smooth_window_multiplier
Controls the size of the smoothing window (the number of frames buffered to determine motion information from).
The size of the smoothing window is determined by multiplying the framerate of the video by this number.
Acceptable values range from 0.1 to 10.0.
Larger values increase the amount of motion data available for determining how to smooth the camera path,
potentially improving smoothness, but also increase latency and memory usage.
Defaults to 2.0.
40.6.1 Examples
Stabilize a video with a fixed, medium smoothing strength:
-i INPUT -vf "hwupload, deshake_opencl=smooth_strength=0.5, hwdownload" OUTPUT
Stabilize a video with debugging (both in console and in rendered video):
-i INPUT -filter_complex "[0:v]format=rgba, hwupload, deshake_opencl=debug=1, hwdownload, format=rgba, format=yuv420p" -v verbose OUTPUT
40.7 dilation_opencl
Apply dilation effect to the video.
This filter replaces the pixel by the local(3x3) maximum.
It accepts the following options:
threshold0
threshold1
threshold2
threshold3
Limit the maximum change for each plane. Range is [0, 65535] and default value is 65535.
If 0, plane will remain unchanged.
coordinates
Flag which specifies the pixel to refer to.
Range is [0, 255] and default value is 255, i.e. all eight pixels are used.
Flags to local 3x3 coordinates region centered on x:
1 2 3
4 x 5
6 7 8
40.7.1 Example
Apply dilation filter with threshold0 set to 30, threshold1 set 40, threshold2 set to 50 and coordinates set to 231, setting each pixel of the output to the local maximum between pixels: 1, 2, 3, 6, 7, 8 of the 3x3 region centered on it in the input. If the difference between input pixel and local maximum is more then threshold of the corresponding plane, output pixel will be set to input pixel + threshold of corresponding plane.
-i INPUT -vf "hwupload, dilation_opencl=30:40:50:coordinates=231, hwdownload" OUTPUT
40.8 nlmeans_opencl
Non-local Means denoise filter through OpenCL, this filter accepts same options as nlmeans.
40.9 overlay_opencl
Overlay one video on top of another.
It takes two inputs and has one output. The first input is the "main" video on which the second input is overlaid.
This filter requires same memory layout for all the inputs. So, format conversion may be needed.
The filter accepts the following options:
x
Set the x coordinate of the overlaid video on the main video.
Default value is 0.
y
Set the y coordinate of the overlaid video on the main video.
Default value is 0.
40.9.1 Examples
Overlay an image LOGO at the top-left corner of the INPUT video. Both inputs are yuv420p format.
-i INPUT -i LOGO -filter_complex "[0:v]hwupload[a], [1:v]format=yuv420p, hwupload[b], [a][b]overlay_opencl, hwdownload" OUTPUT
The inputs have same memory layout for color channels , the overlay has additional alpha plane, like INPUT is yuv420p, and the LOGO is yuva420p.
-i INPUT -i LOGO -filter_complex "[0:v]hwupload[a], [1:v]format=yuva420p, hwupload[b], [a][b]overlay_opencl, hwdownload" OUTPUT
40.10 pad_opencl
Add paddings to the input image, and place the original input at the
provided x, y coordinates.
It accepts the following options:
width, w
height, h
Specify an expression for the size of the output image with the
paddings added. If the value for width or height is 0, the
corresponding input size is used for the output.
The width expression can reference the value set by the
height expression, and vice versa.
The default value of width and height is 0.
x
y
Specify the offsets to place the input image at within the padded area,
with respect to the top/left border of the output image.
The x expression can reference the value set by the y
expression, and vice versa.
The default value of x and y is 0.
If x or y evaluate to a negative number, they’ll be changed
so the input image is centered on the padded area.
color
Specify the color of the padded area. For the syntax of this option,
check the (ffmpeg-utils)"Color" section in the ffmpeg-utils
manual.
aspect
Pad to an aspect instead to a resolution.
The value for the width, height, x, and y
options are expressions containing the following constants:
in_w
in_h
The input video width and height.
iw
ih
These are the same as in_w and in_h.
out_w
out_h
The output width and height (the size of the padded area), as
specified by the width and height expressions.
ow
oh
These are the same as out_w and out_h.
x
y
The x and y offsets as specified by the x and y
expressions, or NAN if not yet specified.
a
same as iw / ih
sar
input sample aspect ratio
dar
input display aspect ratio, it is the same as (iw / ih) * sar
40.11 prewitt_opencl
Apply the Prewitt operator (https://en.wikipedia.org/wiki/Prewitt_operator) to input video stream.
The filter accepts the following option:
planes
Set which planes to filter. Default value is 0xf, by which all planes are processed.
scale
Set value which will be multiplied with filtered result.
Range is [0.0, 65535] and default value is 1.0.
delta
Set value which will be added to filtered result.
Range is [-65535, 65535] and default value is 0.0.
40.11.1 Example
Apply the Prewitt operator with scale set to 2 and delta set to 10.
-i INPUT -vf "hwupload, prewitt_opencl=scale=2:delta=10, hwdownload" OUTPUT
40.12 program_opencl
Filter video using an OpenCL program.
source
OpenCL program source file.
kernel
Kernel name in program.
inputs
Number of inputs to the filter.  Defaults to 1.
size, s
Size of output frames.  Defaults to the same as the first input.
The program_opencl filter also supports the framesync options.
The program source file must contain a kernel function with the given name,
which will be run once for each plane of the output.  Each run on a plane
gets enqueued as a separate 2D global NDRange with one work-item for each
pixel to be generated.  The global ID offset for each work-item is therefore
the coordinates of a pixel in the destination image.
The kernel function needs to take the following arguments:
Destination image, __write_only image2d_t.
This image will become the output; the kernel should write all of it.
Frame index, unsigned int.
This is a counter starting from zero and increasing by one for each frame.
Source images, __read_only image2d_t.
These are the most recent images on each input.  The kernel may read from
them to generate the output, but they can’t be written to.
Example programs:
Copy the input to the output (output must be the same size as the input).
__kernel void copy(__write_only image2d_t destination,
unsigned int index,
__read_only  image2d_t source)
{
const sampler_t sampler = CLK_NORMALIZED_COORDS_FALSE;
int2 location = (int2)(get_global_id(0), get_global_id(1));
float4 value = read_imagef(source, sampler, location);
write_imagef(destination, location, value);
}
Apply a simple transformation, rotating the input by an amount increasing
with the index counter.  Pixel values are linearly interpolated by the
sampler, and the output need not have the same dimensions as the input.
__kernel void rotate_image(__write_only image2d_t dst,
unsigned int index,
__read_only  image2d_t src)
{
const sampler_t sampler = (CLK_NORMALIZED_COORDS_FALSE |
CLK_FILTER_LINEAR);
float angle = (float)index / 100.0f;
float2 dst_dim = convert_float2(get_image_dim(dst));
float2 src_dim = convert_float2(get_image_dim(src));
float2 dst_cen = dst_dim / 2.0f;
float2 src_cen = src_dim / 2.0f;
int2   dst_loc = (int2)(get_global_id(0), get_global_id(1));
float2 dst_pos = convert_float2(dst_loc) - dst_cen;
float2 src_pos = {
cos(angle) * dst_pos.x - sin(angle) * dst_pos.y,
sin(angle) * dst_pos.x + cos(angle) * dst_pos.y
};
src_pos = src_pos * src_dim / dst_dim;
float2 src_loc = src_pos + src_cen;
if (src_loc.x < 0.0f      || src_loc.y < 0.0f ||
src_loc.x > src_dim.x || src_loc.y > src_dim.y)
write_imagef(dst, dst_loc, 0.5f);
else
write_imagef(dst, dst_loc, read_imagef(src, sampler, src_loc));
}
Blend two inputs together, with the amount of each input used varying
with the index counter.
__kernel void blend_images(__write_only image2d_t dst,
unsigned int index,
__read_only  image2d_t src1,
__read_only  image2d_t src2)
{
const sampler_t sampler = (CLK_NORMALIZED_COORDS_FALSE |
CLK_FILTER_LINEAR);
float blend = (cos((float)index / 50.0f) + 1.0f) / 2.0f;
int2  dst_loc = (int2)(get_global_id(0), get_global_id(1));
int2 src1_loc = dst_loc * get_image_dim(src1) / get_image_dim(dst);
int2 src2_loc = dst_loc * get_image_dim(src2) / get_image_dim(dst);
float4 val1 = read_imagef(src1, sampler, src1_loc);
float4 val2 = read_imagef(src2, sampler, src2_loc);
write_imagef(dst, dst_loc, val1 * blend + val2 * (1.0f - blend));
}
40.13 remap_opencl
Remap pixels using 2nd: Xmap and 3rd: Ymap input video stream.
Destination pixel at position (X, Y) will be picked from source (x, y) position
where x = Xmap(X, Y) and y = Ymap(X, Y). If mapping values are out of range, zero
value for pixel will be used for destination pixel.
Xmap and Ymap input video streams must be of same dimensions. Output video stream
will have Xmap/Ymap video stream dimensions.
Xmap and Ymap input video streams are 32bit float pixel format, single channel.
interp
Specify interpolation used for remapping of pixels.
Allowed values are near and linear.
Default value is linear.
fill
Specify the color of the unmapped pixels. For the syntax of this option,
check the (ffmpeg-utils)"Color" section in the ffmpeg-utils
manual. Default color is black.
40.14 roberts_opencl
Apply the Roberts cross operator (https://en.wikipedia.org/wiki/Roberts_cross) to input video stream.
The filter accepts the following option:
planes
Set which planes to filter. Default value is 0xf, by which all planes are processed.
scale
Set value which will be multiplied with filtered result.
Range is [0.0, 65535] and default value is 1.0.
delta
Set value which will be added to filtered result.
Range is [-65535, 65535] and default value is 0.0.
40.14.1 Example
Apply the Roberts cross operator with scale set to 2 and delta set to 10
-i INPUT -vf "hwupload, roberts_opencl=scale=2:delta=10, hwdownload" OUTPUT
40.15 sobel_opencl
Apply the Sobel operator (https://en.wikipedia.org/wiki/Sobel_operator) to input video stream.
The filter accepts the following option:
planes
Set which planes to filter. Default value is 0xf, by which all planes are processed.
scale
Set value which will be multiplied with filtered result.
Range is [0.0, 65535] and default value is 1.0.
delta
Set value which will be added to filtered result.
Range is [-65535, 65535] and default value is 0.0.
40.15.1 Example
Apply sobel operator with scale set to 2 and delta set to 10
-i INPUT -vf "hwupload, sobel_opencl=scale=2:delta=10, hwdownload" OUTPUT
40.16 tonemap_opencl
Perform HDR(PQ/HLG) to SDR conversion with tone-mapping.
It accepts the following parameters:
tonemap
Specify the tone-mapping operator to be used. Same as tonemap option in tonemap.
param
Tune the tone mapping algorithm. same as param option in tonemap.
desat
Apply desaturation for highlights that exceed this level of brightness. The
higher the parameter, the more color information will be preserved. This
setting helps prevent unnaturally blown-out colors for super-highlights, by
(smoothly) turning into white instead. This makes images feel more natural,
at the cost of reducing information about out-of-range colors.
The default value is 0.5, and the algorithm here is a little different from
the cpu version tonemap currently. A setting of 0.0 disables this option.
threshold
The tonemapping algorithm parameters is fine-tuned per each scene. And a threshold
is used to detect whether the scene has changed or not. If the distance between
the current frame average brightness and the current running average exceeds
a threshold value, we would re-calculate scene average and peak brightness.
The default value is 0.2.
format
Specify the output pixel format.
Currently supported formats are:
p010
nv12
range, r
Set the output color range.
Possible values are:
tv/mpeg
pc/jpeg
Default is same as input.
primaries, p
Set the output color primaries.
Possible values are:
bt709
bt2020
Default is same as input.
transfer, t
Set the output transfer characteristics.
Possible values are:
bt709
bt2020
Default is bt709.
matrix, m
Set the output colorspace matrix.
Possible value are:
bt709
bt2020
Default is same as input.
40.16.1 Example
Convert HDR(PQ/HLG) video to bt2020-transfer-characteristic p010 format using linear operator.
-i INPUT -vf "format=p010,hwupload,tonemap_opencl=t=bt2020:tonemap=linear:format=p010,hwdownload,format=p010" OUTPUT
40.17 unsharp_opencl
Sharpen or blur the input video.
It accepts the following parameters:
luma_msize_x, lx
Set the luma matrix horizontal size.
Range is [1, 23] and default value is 5.
luma_msize_y, ly
Set the luma matrix vertical size.
Range is [1, 23] and default value is 5.
luma_amount, la
Set the luma effect strength.
Range is [-10, 10] and default value is 1.0.
Negative values will blur the input video, while positive values will
sharpen it, a value of zero will disable the effect.
chroma_msize_x, cx
Set the chroma matrix horizontal size.
Range is [1, 23] and default value is 5.
chroma_msize_y, cy
Set the chroma matrix vertical size.
Range is [1, 23] and default value is 5.
chroma_amount, ca
Set the chroma effect strength.
Range is [-10, 10] and default value is 0.0.
Negative values will blur the input video, while positive values will
sharpen it, a value of zero will disable the effect.
All parameters are optional and default to the equivalent of the
string ’5:5:1.0:5:5:0.0’.
40.17.1 Examples
Apply strong luma sharpen effect:
-i INPUT -vf "hwupload, unsharp_opencl=luma_msize_x=7:luma_msize_y=7:luma_amount=2.5, hwdownload" OUTPUT
Apply a strong blur of both luma and chroma parameters:
-i INPUT -vf "hwupload, unsharp_opencl=7:7:-2:7:7:-2, hwdownload" OUTPUT
40.18 xfade_opencl
Cross fade two videos with custom transition effect by using OpenCL.
It accepts the following options:
transition
Set one of possible transition effects.
custom
Select custom transition effect, the actual transition description
will be picked from source and kernel options.
fade
wipeleft
wiperight
wipeup
wipedown
slideleft
slideright
slideup
slidedown
Default transition is fade.
source
OpenCL program source file for custom transition.
kernel
Set name of kernel to use for custom transition from program source file.
duration
Set duration of video transition.
offset
Set time of start of transition relative to first video.
The program source file must contain a kernel function with the given name,
which will be run once for each plane of the output.  Each run on a plane
gets enqueued as a separate 2D global NDRange with one work-item for each
pixel to be generated.  The global ID offset for each work-item is therefore
the coordinates of a pixel in the destination image.
The kernel function needs to take the following arguments:
Destination image, __write_only image2d_t.
This image will become the output; the kernel should write all of it.
First Source image, __read_only image2d_t.
Second Source image, __read_only image2d_t.
These are the most recent images on each input.  The kernel may read from
them to generate the output, but they can’t be written to.
Transition progress, float. This value is always between 0 and 1 inclusive.
Example programs:
Apply dots curtain transition effect:
__kernel void blend_images(__write_only image2d_t dst,
__read_only  image2d_t src1,
__read_only  image2d_t src2,
float progress)
{
const sampler_t sampler = (CLK_NORMALIZED_COORDS_FALSE |
CLK_FILTER_LINEAR);
int2  p = (int2)(get_global_id(0), get_global_id(1));
float2 rp = (float2)(get_global_id(0), get_global_id(1));
float2 dim = (float2)(get_image_dim(src1).x, get_image_dim(src1).y);
rp = rp / dim;
float2 dots = (float2)(20.0, 20.0);
float2 center = (float2)(0,0);
float2 unused;
float4 val1 = read_imagef(src1, sampler, p);
float4 val2 = read_imagef(src2, sampler, p);
bool next = distance(fract(rp * dots, &unused), (float2)(0.5, 0.5)) < (progress / distance(rp, center));
write_imagef(dst, p, next ? val1 : val2);
}
41 VAAPI Video Filters
VAAPI Video filters are usually used with VAAPI decoder and VAAPI encoder. Below is a description of VAAPI video filters.
To enable compilation of these filters you need to configure FFmpeg with
--enable-vaapi.
To use vaapi filters, you need to setup the vaapi device correctly. For more information, please read https://trac.ffmpeg.org/wiki/Hardware/VAAPI
41.1 overlay_vaapi
Overlay one video on the top of another.
It takes two inputs and has one output. The first input is the "main" video on which the second input is overlaid.
The filter accepts the following options:
x
y
Set expressions for the x and y coordinates of the overlaid video
on the main video.
Default value is "0" for both expressions.
w
h
Set expressions for the width and height the overlaid video
on the main video.
Default values are ’overlay_iw’ for ’w’ and ’overlay_ih*w/overlay_iw’ for ’h’.
The expressions can contain the following parameters:
main_w, W
main_h, H
The main input width and height.
overlay_iw
overlay_ih
The overlay input width and height.
overlay_w, w
overlay_h, h
The overlay output width and height.
overlay_x, x
overlay_y, y
Position of the overlay layer inside of main
alpha
Set transparency of overlaid video. Allowed range is 0.0 to 1.0.
Higher value means lower transparency.
Default value is 1.0.
eof_action
See framesync.
shortest
See framesync.
repeatlast
See framesync.
This filter also supports the framesync options.
41.1.1 Examples
Overlay an image LOGO at the top-left corner of the INPUT video. Both inputs for this filter are yuv420p format.
-i INPUT -i LOGO -filter_complex "[0:v]hwupload[a], [1:v]format=yuv420p, hwupload[b], [a][b]overlay_vaapi" OUTPUT
Overlay an image LOGO at the offset (200, 100) from the top-left corner of the INPUT video.
The inputs have same memory layout for color channels, the overlay has additional alpha plane, like INPUT is yuv420p, and the LOGO is yuva420p.
-i INPUT -i LOGO -filter_complex "[0:v]hwupload[a], [1:v]format=yuva420p, hwupload[b], [a][b]overlay_vaapi=x=200:y=100:w=400:h=300:alpha=1.0, hwdownload, format=nv12" OUTPUT
41.2 tonemap_vaapi
Perform HDR-to-SDR or HDR-to-HDR tone-mapping.
It currently only accepts HDR10 as input.
It accepts the following parameters:
format
Specify the output pixel format.
Default is nv12 for HDR-to-SDR tone-mapping and p010 for HDR-to-HDR
tone-mapping.
primaries, p
Set the output color primaries.
Default is bt709 for HDR-to-SDR tone-mapping and same as input for HDR-to-HDR
tone-mapping.
transfer, t
Set the output transfer characteristics.
Default is bt709 for HDR-to-SDR tone-mapping and same as input for HDR-to-HDR
tone-mapping.
matrix, m
Set the output colorspace matrix.
Default is bt709 for HDR-to-SDR tone-mapping and same as input for HDR-to-HDR
tone-mapping.
display
Set the output mastering display colour volume. It is given by a ’|’-separated
list of two values, two values are space separated. It set display primaries
x & y in G, B, R order, then white point x & y, the nominal minimum & maximum
display luminances.
HDR-to-HDR tone-mapping will be performed when this option is set.
light
Set the output content light level information. It accepts 2 space-separated
values, the first input is the maximum light level and the second input is
the maximum average light level.
It is ignored for HDR-to-SDR tone-mapping, and optional for HDR-to-HDR
tone-mapping.
41.2.1 Example
Convert HDR(HDR10) video to bt2020-transfer-characteristic p010 format
tonemap_vaapi=format=p010:t=bt2020-10
Convert HDR video to HDR video
tonemap_vaapi=display=7500\ 3000|34000\ 16000|13250\ 34500|15635\ 16450|500\ 10000000
41.3 hstack_vaapi
Stack input videos horizontally.
This is the VA-API variant of the hstack filter, each input stream may
have different height, this filter will scale down/up each input stream while
keeping the original aspect.
It accepts the following options:
inputs
See hstack.
shortest
See hstack.
height
Set height of output. If set to 0, this filter will set height of output to
height of the first input stream. Default value is 0.
41.4 vstack_vaapi
Stack input videos vertically.
This is the VA-API variant of the vstack filter, each input stream may
have different width, this filter will scale down/up each input stream while
keeping the original aspect.
It accepts the following options:
inputs
See vstack.
shortest
See vstack.
width
Set width of output. If set to 0, this filter will set width of output to
width of the first input stream. Default value is 0.
41.5 xstack_vaapi
Stack video inputs into custom layout.
This is the VA-API variant of the xstack filter,  each input stream may
have different size, this filter will scale down/up each input stream to the
given output size, or the size of the first input stream.
It accepts the following options:
inputs
See xstack.
shortest
See xstack.
layout
See xstack.
Moreover, this permits the user to supply output size for each input stream.
xstack_vaapi=inputs=4:layout=0_0_1920x1080|0_h0_1920x1080|w0_0_1920x1080|w0_h0_1920x1080
grid
See xstack.
grid_tile_size
Set output size for each input stream when grid is set. If this option
is not set, this filter will set output size by default to the size of the
first input stream. For the syntax of this option, check the
(ffmpeg-utils)"Video size" section in the ffmpeg-utils manual.
fill
See xstack.
41.6 pad_vaapi
Add paddings to the input image, and place the original input at the
provided x, y coordinates.
It accepts the following options:
width, w
height, h
Specify an expression for the size of the output image with the
paddings added. If the value for width or height is 0, the
corresponding input size is used for the output.
The width expression can reference the value set by the
height expression, and vice versa.
The default value of width and height is 0.
x
y
Specify the offsets to place the input image at within the padded area,
with respect to the top/left border of the output image.
The x expression can reference the value set by the y
expression, and vice versa.
The default value of x and y is 0.
If x or y evaluate to a negative number, they’ll be changed
so the input image is centered on the padded area.
color
Specify the color of the padded area. For the syntax of this option,
check the (ffmpeg-utils)"Color" section in the ffmpeg-utils
manual.
aspect
Pad to an aspect instead to a resolution.
The value for the width, height, x, and y
options are expressions containing the following constants:
in_w
in_h
The input video width and height.
iw
ih
These are the same as in_w and in_h.
out_w
out_h
The output width and height (the size of the padded area), as
specified by the width and height expressions.
ow
oh
These are the same as out_w and out_h.
x
y
The x and y offsets as specified by the x and y
expressions, or NAN if not yet specified.
a
same as iw / ih
sar
input sample aspect ratio
dar
input display aspect ratio, it is the same as (iw / ih) * sar
41.7 drawbox_vaapi
Draw a colored box on the input image.
It accepts the following parameters:
x
y
The expressions which specify the top left corner coordinates of the box. It defaults to 0.
width, w
height, h
The expressions which specify the width and height of the box; if 0 they are interpreted as
the input width and height. It defaults to 0.
color, c
Specify the color of the box to write. For the general syntax of this option,
check the (ffmpeg-utils)"Color" section in the ffmpeg-utils manual.
thickness, t
The expression which sets the thickness of the box edge.
A value of fill will create a filled box. Default value is 3.
See below for the list of accepted constants.
replace
With value 1, the pixels of the painted box will overwrite the video’s color and alpha pixels.
Default is 0, which composites the box onto the input video.
The parameters for x, y, w and h and t are expressions containing the
following constants:
in_h, ih
in_w, iw
The input width and height.
x
y
The x and y offset coordinates where the box is drawn.
w
h
The width and height of the drawn box.
t
The thickness of the drawn box.
41.7.1 Examples
Draw a black box around the edge of the input image:
drawbox
Draw a box with color red and an opacity of 50%:
drawbox=10:20:200:60:[email protected]
The previous example can be specified as:
drawbox=x=10:y=20:w=200:h=60:[email protected]
Fill the box with pink color:
drawbox=x=10:y=10:w=100:h=100:[email protected]:t=fill
Draw a 2-pixel red 2.40:1 mask:
drawbox=x=-t:y=0.5*(ih-iw/2.4)-t:w=iw+t*2:h=iw/2.4+t*2:t=2:c=red
42 Vulkan Video Filters
Below is a description of the currently available Vulkan video filters.
To enable compilation of these filters you need to configure FFmpeg with
--enable-vulkan and either --enable-libglslang or --enable-libshaderc.
Running Vulkan filters requires you to initialize a hardware device and to pass that device to all filters in any filter graph.
-init_hw_device vulkan[=name][:device[,key=value...]]
Initialise a new hardware device of type vulkan called name, using the
given device parameters and options in key=value. The following options
are supported:
debug
Switches validation layers on if set to 1.
linear_images
Allocates linear images. Does not apply to decoding.
disable_multiplane
Disables multiplane images. Does not apply to decoding.
-filter_hw_device name
Pass the hardware device called name to all filters in any filter graph.
For more detailed information see https://www.ffmpeg.org/ffmpeg.html#Advanced-Video-options
Example of choosing the first device and running nlmeans_vulkan filter with default parameters on it.
-init_hw_device vulkan=vk:0 -filter_hw_device vk -i INPUT -vf "hwupload,nlmeans_vulkan,hwdownload" OUTPUT
As Vulkan filters are not able to access frame data in normal memory, all frame data needs to be uploaded (hwupload) to hardware surfaces connected to the appropriate device before being used and then downloaded (hwdownload) back to normal memory. Note that hwupload will upload to a frame with the same layout as the software frame, so it may be necessary to add a format filter immediately before to get the input into the right format and hwdownload does not support all formats on the output - it is usually necessary to insert an additional format filter immediately following in the graph to get the output in a supported format.
42.1 avgblur_vulkan
Apply an average blur filter, implemented on the GPU using Vulkan.
The filter accepts the following options:
sizeX
Set horizontal radius size.
Range is [1, 32] and default value is 3.
sizeY
Set vertical radius size. Range is [1, 32] and default value is 3.
planes
Set which planes to filter. Default value is 0xf, by which all planes are processed.
42.2 blend_vulkan
Blend two Vulkan frames into each other.
The blend filter takes two input streams and outputs one
stream, the first input is the "top" layer and second input is
"bottom" layer.  By default, the output terminates when the longest input terminates.
A description of the accepted options follows.
c0_mode
c1_mode
c2_mode
c3_mode
all_mode
Set blend mode for specific pixel component or all pixel components in case
of all_mode. Default value is normal.
Available values for component modes are:
‘normal’
‘multiply’
42.3 bwdif_vulkan
Deinterlacer using bwdif, the "Bob Weaver Deinterlacing Filter" algorithm, implemented
on the GPU using Vulkan.
It accepts the following parameters:
mode
The interlacing mode to adopt. It accepts one of the following values:
0, send_frame
Output one frame for each frame.
1, send_field
Output one frame for each field.
The default value is send_field.
parity
The picture field parity assumed for the input interlaced video. It accepts one
of the following values:
0, tff
Assume the top field is first.
1, bff
Assume the bottom field is first.
-1, auto
Enable automatic detection of field parity.
The default value is auto.
If the interlacing is unknown or the decoder does not export this information,
top field first will be assumed.
deint
Specify which frames to deinterlace. Accepts one of the following
values:
0, all
Deinterlace all frames.
1, interlaced
Only deinterlace frames marked as interlaced.
The default value is all.
42.4 chromaber_vulkan
Apply an effect that emulates chromatic aberration. Works best with RGB inputs,
but provides a similar effect with YCbCr inputs too.
dist_x
Horizontal displacement multiplier. Each chroma pixel’s position will be multiplied
by this amount, starting from the center of the image. Default is 0.
dist_y
Similarly, this sets the vertical displacement multiplier. Default is 0.
42.5 color_vulkan
Video source that creates a Vulkan frame of a solid color.
Useful for benchmarking, or overlaying.
It accepts the following parameters:
color
The color to use. Either a name, or a hexadecimal value.
The default value is black.
size
The size of the output frame. Default value is 1920x1080.
rate
The framerate to output at. Default value is 60 frames per second.
duration
The video duration. Default value is -0.000001.
sar
The video signal aspect ratio. Default value is 1/1.
format
The pixel format of the output Vulkan frames. Default value is yuv444p.
out_range
Set the output YCbCr sample range.
This allows the autodetected value to be overridden as well as allows forcing
a specific value used for the output and encoder. If not specified, the
range depends on the pixel format. Possible values:
‘auto/unknown’
Choose automatically.
‘jpeg/full/pc’
Set full range (0-255 in case of 8-bit luma).
‘mpeg/limited/tv’
Set "MPEG" range (16-235 in case of 8-bit luma).
42.6 vflip_vulkan
Flips an image vertically.
42.7 hflip_vulkan
Flips an image horizontally.
42.8 flip_vulkan
Flips an image along both the vertical and horizontal axis.
42.9 gblur_vulkan
Apply Gaussian blur filter on Vulkan frames.
The filter accepts the following options:
sigma
Set horizontal sigma, standard deviation of Gaussian blur. Default is 0.5.
sigmaV
Set vertical sigma, if negative it will be same as sigma.
Default is -1.
planes
Set which planes to filter. By default all planes are filtered.
size
Set the kernel size along the horizontal axis. Default is 19.
sizeV
Set the kernel size along the vertical axis. Default is 0,
which sets to use the same value as size.
42.10 nlmeans_vulkan
Denoise frames using Non-Local Means algorithm, implemented on the GPU using
Vulkan.
Supports more pixel formats than nlmeans or nlmeans_opencl, including
alpha channel support.
The filter accepts the following options.
s
Set denoising strength for all components. Default is 1.0. Must be in range [1.0, 100.0].
p
Set patch size for all planes. Default is 7. Must be odd number in range [0, 99].
r
Set research size. Default is 15. Must be odd number in range [0, 99].
t
Set parallelism. Default is 36. Must be a number in the range [1, 168].
Larger values may speed up processing, at the cost of more VRAM.
Lower values will slow it down, reducing VRAM usage.
Only supported on GPUs with atomic float operations (RDNA3+, Ampere+).
s0
s1
s2
s3
Set denoising strength for a specific component. Default is 1, equal to s.
Must be odd number in range [1, 100].
p0
p1
p2
p3
Set patch size for a specific component. Default is 7, equal to p.
Must be odd number in range [0, 99].
42.11 overlay_vulkan
Overlay one video on top of another.
It takes two inputs and has one output. The first input is the "main" video on which the second input is overlaid.
This filter requires all inputs to use the same pixel format. So, format conversion may be needed.
The filter accepts the following options:
x
Set the x coordinate of the overlaid video on the main video.
Default value is 0.
y
Set the y coordinate of the overlaid video on the main video.
Default value is 0.
42.12 transpose_vt
Transpose rows with columns in the input video and optionally flip it.
For more in depth examples see the transpose video filter, which shares mostly the same options.
It accepts the following parameters:
dir
Specify the transposition direction.
Can assume the following values:
‘cclock_flip’
Rotate by 90 degrees counterclockwise and vertically flip. (default)
‘clock’
Rotate by 90 degrees clockwise.
‘cclock’
Rotate by 90 degrees counterclockwise.
‘clock_flip’
Rotate by 90 degrees clockwise and vertically flip.
‘hflip’
Flip the input video horizontally.
‘vflip’
Flip the input video vertically.
passthrough
Do not apply the transposition if the input geometry matches the one
specified by the specified value. It accepts the following values:
‘none’
Always apply transposition. (default)
‘portrait’
Preserve portrait geometry (when height >= width).
‘landscape’
Preserve landscape geometry (when width >= height).
42.13 transpose_vulkan
Transpose rows with columns in the input video and optionally flip it.
For more in depth examples see the transpose video filter, which shares mostly the same options.
It accepts the following parameters:
dir
Specify the transposition direction.
Can assume the following values:
‘cclock_flip’
Rotate by 90 degrees counterclockwise and vertically flip. (default)
‘clock’
Rotate by 90 degrees clockwise.
‘cclock’
Rotate by 90 degrees counterclockwise.
‘clock_flip’
Rotate by 90 degrees clockwise and vertically flip.
passthrough
Do not apply the transposition if the input geometry matches the one
specified by the specified value. It accepts the following values:
‘none’
Always apply transposition. (default)
‘portrait’
Preserve portrait geometry (when height >= width).
‘landscape’
Preserve landscape geometry (when width >= height).
43 QSV Video Filters
Below is a description of the currently available QSV video filters.
To enable compilation of these filters you need to configure FFmpeg with
--enable-libmfx or --enable-libvpl.
To use QSV filters, you need to setup the QSV device correctly. For more information, please read https://trac.ffmpeg.org/wiki/Hardware/QuickSync
43.1 hstack_qsv
Stack input videos horizontally.
This is the QSV variant of the hstack filter, each input stream may
have different height, this filter will scale down/up each input stream while
keeping the original aspect.
It accepts the following options:
inputs
See hstack.
shortest
See hstack.
height
Set height of output. If set to 0, this filter will set height of output to
height of the first input stream. Default value is 0.
43.2 vstack_qsv
Stack input videos vertically.
This is the QSV variant of the vstack filter, each input stream may
have different width, this filter will scale down/up each input stream while
keeping the original aspect.
It accepts the following options:
inputs
See vstack.
shortest
See vstack.
width
Set width of output. If set to 0, this filter will set width of output to
width of the first input stream. Default value is 0.
43.3 xstack_qsv
Stack video inputs into custom layout.
This is the QSV variant of the xstack filter.
It accepts the following options:
inputs
See xstack.
shortest
See xstack.
layout
See xstack.
Moreover, this permits the user to supply output size for each input stream.
xstack_qsv=inputs=4:layout=0_0_1920x1080|0_h0_1920x1080|w0_0_1920x1080|w0_h0_1920x1080
grid
See xstack.
grid_tile_size
Set output size for each input stream when grid is set. If this option
is not set, this filter will set output size by default to the size of the
first input stream. For the syntax of this option, check the
(ffmpeg-utils)"Video size" section in the ffmpeg-utils manual.
fill
See xstack.
44 Video Sources
Below is a description of the currently available video sources.
44.1 buffer
Buffer video frames, and make them available to the filter chain.
This source is mainly intended for a programmatic use, in particular
through the interface defined in libavfilter/buffersrc.h.
It accepts the following parameters:
video_size
Specify the size (width and height) of the buffered video frames. For the
syntax of this option, check the
(ffmpeg-utils)"Video size" section in the ffmpeg-utils manual.
width
The input video width.
height
The input video height.
pix_fmt
A string representing the pixel format of the buffered video frames.
It may be a number corresponding to a pixel format, or a pixel format
name.
time_base
Specify the timebase assumed by the timestamps of the buffered frames.
frame_rate
Specify the frame rate expected for the video stream.
colorspace
A string representing the color space of the buffered video frames.
It may be a number corresponding to a color space, or a color space
name.
range
A string representing the color range of the buffered video frames.
It may be a number corresponding to a color range, or a color range
name.
pixel_aspect, sar
The sample (pixel) aspect ratio of the input video.
hw_frames_ctx
When using a hardware pixel format, this should be a reference to an
AVHWFramesContext describing input frames.
For example:
buffer=width=320:height=240:pix_fmt=yuv410p:time_base=1/24:sar=1
will instruct the source to accept video frames with size 320x240 and
with format "yuv410p", assuming 1/24 as the timestamps timebase and
square pixels (1:1 sample aspect ratio).
Since the pixel format with name "yuv410p" corresponds to the number 6
(check the enum AVPixelFormat definition in libavutil/pixfmt.h),
this example corresponds to:
buffer=size=320x240:pixfmt=6:time_base=1/24:pixel_aspect=1/1
Alternatively, the options can be specified as a flat string, but this
syntax is deprecated:
width:height:pix_fmt:time_base.num:time_base.den:pixel_aspect.num:pixel_aspect.den
44.2 cellauto
Create a pattern generated by an elementary cellular automaton.
The initial state of the cellular automaton can be defined through the
filename and pattern options. If such options are
not specified an initial state is created randomly.
At each new frame a new row in the video is filled with the result of
the cellular automaton next generation. The behavior when the whole
frame is filled is defined by the scroll option.
This source accepts the following options:
filename, f
Read the initial cellular automaton state, i.e. the starting row, from
the specified file.
In the file, each non-whitespace character is considered an alive
cell, a newline will terminate the row, and further characters in the
file will be ignored.
pattern, p
Read the initial cellular automaton state, i.e. the starting row, from
the specified string.
Each non-whitespace character in the string is considered an alive
cell, a newline will terminate the row, and further characters in the
string will be ignored.
rate, r
Set the video rate, that is the number of frames generated per second.
Default is 25.
random_fill_ratio, ratio
Set the random fill ratio for the initial cellular automaton row. It
is a floating point number value ranging from 0 to 1, defaults to
1/PHI.
This option is ignored when a file or a pattern is specified.
random_seed, seed
Set the seed for filling randomly the initial row, must be an integer
included between 0 and UINT32_MAX. If not specified, or if explicitly
set to -1, the filter will try to use a good random seed on a best
effort basis.
rule
Set the cellular automaton rule, it is a number ranging from 0 to 255.
Default value is 110.
size, s
Set the size of the output video. For the syntax of this option, check the
(ffmpeg-utils)"Video size" section in the ffmpeg-utils manual.
If filename or pattern is specified, the size is set
by default to the width of the specified initial state row, and the
height is set to width * PHI.
If size is set, it must contain the width of the specified
pattern string, and the specified pattern will be centered in the
larger row.
If a filename or a pattern string is not specified, the size value
defaults to "320x518" (used for a randomly generated initial state).
scroll
If set to 1, scroll the output upward when all the rows in the output
have been already filled. If set to 0, the new generated row will be
written over the top row just after the bottom row is filled.
Defaults to 1.
start_full, full
If set to 1, completely fill the output with generated rows before
outputting the first frame.
This is the default behavior, for disabling set the value to 0.
stitch
If set to 1, stitch the left and right row edges together.
This is the default behavior, for disabling set the value to 0.
44.2.1 Examples
Read the initial state from pattern, and specify an output of
size 200x400.
cellauto=f=pattern:s=200x400
Generate a random initial row with a width of 200 cells, with a fill
ratio of 2/3:
cellauto=ratio=2/3:s=200x200
Create a pattern generated by rule 18 starting by a single alive cell
centered on an initial row with width 100:
cellauto=p=@:s=100x400:full=0:rule=18
Specify a more elaborated initial pattern:
cellauto=p='@@ @ @@':s=100x400:full=0:rule=18
44.3 coreimagesrc
Video source generated on GPU using Apple’s CoreImage API on OSX.
This video source is a specialized version of the coreimage video filter.
Use a core image generator at the beginning of the applied filterchain to
generate the content.
The coreimagesrc video source accepts the following options:
list_generators
List all available generators along with all their respective options as well as
possible minimum and maximum values along with the default values.
list_generators=true
size, s
Specify the size of the sourced video. For the syntax of this option, check the
(ffmpeg-utils)"Video size" section in the ffmpeg-utils manual.
The default value is 320x240.
rate, r
Specify the frame rate of the sourced video, as the number of frames
generated per second. It has to be a string in the format
frame_rate_num/frame_rate_den, an integer number, a floating point
number or a valid video frame rate abbreviation. The default value is
"25".
sar
Set the sample aspect ratio of the sourced video.
duration, d
Set the duration of the sourced video. See
(ffmpeg-utils)the Time duration section in the ffmpeg-utils(1) manual
for the accepted syntax.
If not specified, or the expressed duration is negative, the video is
supposed to be generated forever.
Additionally, all options of the coreimage video filter are accepted.
A complete filterchain can be used for further processing of the
generated input without CPU-HOST transfer. See coreimage documentation
and examples for details.
44.3.1 Examples
Use CIQRCodeGenerator to create a QR code for the FFmpeg homepage,
given as complete and escaped command-line for Apple’s standard bash shell:
ffmpeg -f lavfi -i coreimagesrc=s=100x100:filter=CIQRCodeGenerator@inputMessage=https\\\\\://FFmpeg.org/@inputCorrectionLevel=H -frames:v 1 QRCode.png
This example is equivalent to the QRCode example of coreimage without the
need for a nullsrc video source.
44.4 ddagrab
Captures the Windows Desktop via Desktop Duplication API.
The filter exclusively returns D3D11 Hardware Frames, for on-gpu encoding
or processing. So an explicit hwdownload is needed for any kind of
software processing.
It accepts the following options:
output_idx
DXGI Output Index to capture.
Usually corresponds to the index Windows has given the screen minus one,
so it’s starting at 0.
Defaults to output 0.
draw_mouse
Whether to draw the mouse cursor.
Defaults to true.
Only affects hardware cursors. If a game or application renders its own cursor,
it’ll always be captured.
framerate
Maximum framerate at which the desktop will be captured - the interval between
successive frames will not be smaller than the inverse of the framerate. When
dup_frames is true (the default) and the desktop is not being updated
often enough, the filter will duplicate a previous frame. Note that there is no
background buffering going on, so when the filter is not polled often enough
then the actual inter-frame interval may be significantly larger.
Defaults to 30 FPS.
video_size
Specify the size of the captured video.
Defaults to the full size of the screen.
Cropped from the bottom/right if smaller than screen size.
offset_x
Horizontal offset of the captured video.
offset_y
Vertical offset of the captured video.
output_fmt
Desired filter output format.
Defaults to 8 Bit BGRA.
It accepts the following values:
‘auto’
Passes all supported output formats to DDA and returns what DDA decides to use.
‘8bit’
‘bgra’
8 Bit formats always work, and DDA will convert to them if necessary.
‘10bit’
‘x2bgr10’
Filter initialization will fail if 10 bit format is requested but unavailable.
dup_frames
When this option is set to true (the default), the filter will duplicate frames
when the desktop has not been updated in order to maintain approximately
constant target framerate. When this option is set to false, the filter will
wait for the desktop to be updated (inter-frame intervals may vary significantly
in this case).
44.4.1 Examples
Capture primary screen and encode using nvenc:
ffmpeg -f lavfi -i ddagrab -c:v h264_nvenc -cq 18 output.mp4
You can also skip the lavfi device and directly use the filter.
Also demonstrates downloading the frame and encoding with libx264.
Explicit output format specification is required in this case:
ffmpeg -filter_complex ddagrab=output_idx=1:framerate=60,hwdownload,format=bgra -c:v libx264 -crf 18 output.mp4
If you want to capture only a subsection of the desktop, this can be achieved
by specifying a smaller size and its offsets into the screen:
ddagrab=video_size=800x600:offset_x=100:offset_y=100
44.5 gradients
Generate several gradients.
size, s
Set frame size. For the syntax of this option, check the (ffmpeg-utils)"Video
size" section in the ffmpeg-utils manual. Default value is "640x480".
rate, r
Set frame rate, expressed as number of frames per second. Default
value is "25".
c0, c1, c2, c3, c4, c5, c6, c7
Set 8 colors. Default values for colors is to pick random one.
x0, y0, y0, y1
Set gradient line source and destination points. If negative or out of range, random ones
are picked.
nb_colors, n
Set number of colors to use at once. Allowed range is from 2 to 8. Default value is 2.
seed
Set seed for picking gradient line points.
duration, d
Set the duration of the sourced video. See
(ffmpeg-utils)the Time duration section in the ffmpeg-utils(1) manual
for the accepted syntax.
If not specified, or the expressed duration is negative, the video is
supposed to be generated forever.
speed
Set speed of gradients rotation.
type, t
Set type of gradients.
Available values are:
‘linear’
‘radial’
‘circular’
‘spiral’
‘square’
Default type is linear.
44.5.1 Commands
This source supports the some above options as commands.
44.6 mandelbrot
Generate a Mandelbrot set fractal, and progressively zoom towards the
point specified with start_x and start_y.
This source accepts the following options:
end_pts
Set the terminal pts value. Default value is 400.
end_scale
Set the terminal scale value.
Must be a floating point value. Default value is 0.3.
inner
Set the inner coloring mode, that is the algorithm used to draw the
Mandelbrot fractal internal region.
It shall assume one of the following values:
black
Set black mode.
convergence
Show time until convergence.
mincol
Set color based on point closest to the origin of the iterations.
period
Set period mode.
Default value is mincol.
bailout
Set the bailout value. Default value is 10.0.
maxiter
Set the maximum of iterations performed by the rendering
algorithm. Default value is 7189.
outer
Set outer coloring mode.
It shall assume one of following values:
iteration_count
Set iteration count mode.
normalized_iteration_count
set normalized iteration count mode.
Default value is normalized_iteration_count.
rate, r
Set frame rate, expressed as number of frames per second. Default
value is "25".
size, s
Set frame size. For the syntax of this option, check the (ffmpeg-utils)"Video
size" section in the ffmpeg-utils manual. Default value is "640x480".
start_scale
Set the initial scale value. Default value is 3.0.
start_x
Set the initial x position. Must be a floating point value between
-100 and 100. Default value is -0.743643887037158704752191506114774.
start_y
Set the initial y position. Must be a floating point value between
-100 and 100. Default value is -0.131825904205311970493132056385139.
44.7 mptestsrc
Generate various test patterns, as generated by the MPlayer test filter.
The size of the generated video is fixed, and is 256x256.
This source is useful in particular for testing encoding features.
This source accepts the following options:
rate, r
Specify the frame rate of the sourced video, as the number of frames
generated per second. It has to be a string in the format
frame_rate_num/frame_rate_den, an integer number, a floating point
number or a valid video frame rate abbreviation. The default value is
"25".
duration, d
Set the duration of the sourced video. See
(ffmpeg-utils)the Time duration section in the ffmpeg-utils(1) manual
for the accepted syntax.
If not specified, or the expressed duration is negative, the video is
supposed to be generated forever.
test, t
Set the number or the name of the test to perform. Supported tests are:
dc_luma
dc_chroma
freq_luma
freq_chroma
amp_luma
amp_chroma
cbp
mv
ring1
ring2
all
max_frames, m
Set the maximum number of frames generated for each test, default value is 30.
Default value is "all", which will cycle through the list of all tests.
Some examples:
mptestsrc=t=dc_luma
will generate a "dc_luma" test pattern.
44.8 frei0r_src
Provide a frei0r source.
To enable compilation of this filter you need to install the frei0r
header and configure FFmpeg with --enable-frei0r.
This source accepts the following parameters:
size
The size of the video to generate. For the syntax of this option, check the
(ffmpeg-utils)"Video size" section in the ffmpeg-utils manual.
framerate
The framerate of the generated video. It may be a string of the form
num/den or a frame rate abbreviation.
filter_name
The name to the frei0r source to load. For more information regarding frei0r and
how to set the parameters, read the frei0r section in the video filters
documentation.
filter_params
A ’|’-separated list of parameters to pass to the frei0r source.
For example, to generate a frei0r partik0l source with size 200x200
and frame rate 10 which is overlaid on the overlay filter main input:
frei0r_src=size=200x200:framerate=10:filter_name=partik0l:filter_params=1234 [overlay]; [in][overlay] overlay
44.9 life
Generate a life pattern.
This source is based on a generalization of John Conway’s life game.
The sourced input represents a life grid, each pixel represents a cell
which can be in one of two possible states, alive or dead. Every cell
interacts with its eight neighbours, which are the cells that are
horizontally, vertically, or diagonally adjacent.
At each interaction the grid evolves according to the adopted rule,
which specifies the number of neighbor alive cells which will make a
cell stay alive or born. The rule option allows one to specify
the rule to adopt.
This source accepts the following options:
filename, f
Set the file from which to read the initial grid state. In the file,
each non-whitespace character is considered an alive cell, and newline
is used to delimit the end of each row.
If this option is not specified, the initial grid is generated
randomly.
rate, r
Set the video rate, that is the number of frames generated per second.
Default is 25.
random_fill_ratio, ratio
Set the random fill ratio for the initial random grid. It is a
floating point number value ranging from 0 to 1, defaults to 1/PHI.
It is ignored when a file is specified.
random_seed, seed
Set the seed for filling the initial random grid, must be an integer
included between 0 and UINT32_MAX. If not specified, or if explicitly
set to -1, the filter will try to use a good random seed on a best
effort basis.
rule
Set the life rule.
A rule can be specified with a code of the kind "SNS/BNB",
where NS and NB are sequences of numbers in the range 0-8,
NS specifies the number of alive neighbor cells which make a
live cell stay alive, and NB the number of alive neighbor cells
which make a dead cell to become alive (i.e. to "born").
"s" and "b" can be used in place of "S" and "B", respectively.
Alternatively a rule can be specified by an 18-bits integer. The 9
high order bits are used to encode the next cell state if it is alive
for each number of neighbor alive cells, the low order bits specify
the rule for "borning" new cells. Higher order bits encode for an
higher number of neighbor cells.
For example the number 6153 = (12<<9)+9 specifies a stay alive
rule of 12 and a born rule of 9, which corresponds to "S23/B03".
Default value is "S23/B3", which is the original Conway’s game of life
rule, and will keep a cell alive if it has 2 or 3 neighbor alive
cells, and will born a new cell if there are three alive cells around
a dead cell.
size, s
Set the size of the output video. For the syntax of this option, check the
(ffmpeg-utils)"Video size" section in the ffmpeg-utils manual.
If filename is specified, the size is set by default to the
same size of the input file. If size is set, it must contain
the size specified in the input file, and the initial grid defined in
that file is centered in the larger resulting area.
If a filename is not specified, the size value defaults to "320x240"
(used for a randomly generated initial grid).
stitch
If set to 1, stitch the left and right grid edges together, and the
top and bottom edges also. Defaults to 1.
mold
Set cell mold speed. If set, a dead cell will go from death_color to
mold_color with a step of mold. mold can have a
value from 0 to 255.
life_color
Set the color of living (or new born) cells.
death_color
Set the color of dead cells. If mold is set, this is the first color
used to represent a dead cell.
mold_color
Set mold color, for definitely dead and moldy cells.
For the syntax of these 3 color options, check the (ffmpeg-utils)"Color" section in the
ffmpeg-utils manual.
44.9.1 Examples
Read a grid from pattern, and center it on a grid of size
300x300 pixels:
life=f=pattern:s=300x300
Generate a random grid of size 200x200, with a fill ratio of 2/3:
life=ratio=2/3:s=200x200
Specify a custom rule for evolving a randomly generated grid:
life=rule=S14/B34
Full example with slow death effect (mold) using ffplay:
ffplay -f lavfi life=s=300x200:mold=10:r=60:ratio=0.1:death_color=#C83232:life_color=#00ff00,scale=1200:800:flags=16
44.10 perlin
Generate Perlin noise.
Perlin noise is a kind of noise with local continuity in space. This
can be used to generate patterns with continuity in space and time,
e.g. to simulate smoke, fluids, or terrain.
In case more than one octave is specified through the octaves
option, Perlin noise is generated as a sum of components, each one
with doubled frequency. In this case the persistence option
specify the ratio of the amplitude with respect to the previous
component. More octave components enable to specify more high
frequency details in the generated noise (e.g. small size variations
due to boulders in a generated terrain).
44.10.1 Options
size, s
Specify the size (width and height) of the buffered video frames. For the
syntax of this option, check the
(ffmpeg-utils)"Video size" section in the ffmpeg-utils manual.
Default value is 320x240.
rate, r
Specify the frame rate expected for the video stream, expressed as a
number of frames per second. Default value is 25.
octaves
Specify the total number of components making up the noise, each one
with doubled frequency. Default value is 1.
persistence
Set the ratio used to compute the amplitude of the next octave
component with respect to the previous component amplitude. Default
value is 1.
xscale
yscale
Define a scale factor used to multiple the x, y coordinates. This can
be useful to define an effect with a pattern stretched along the x or
y axis. Default value is 1.
tscale
Define a scale factor used to multiple the time coordinate. This can
be useful to change the time variation speed. Default value is 1.
random_mode
Set random mode used to compute initial pattern.
Supported values are:
random
Compute and use random seed.
ken
Use the predefined initial pattern defined by Ken Perlin in the
original article, can be useful to compare the output with other
sources.
seed
Use the value specified by random_seed option.
Default value is random.
random_seed, seed
When random_mode is set to random_seed, use this value
to compute the initial pattern. Default value is 0.
44.10.2 Examples
Generate single component:
perlin
Use Perlin noise with 7 components, each one with a halved contribution
to total amplitude:
perlin=octaves=7:persistence=0.5
Chain Perlin noise with the lutyuv to generate a black&white
effect:
perlin=octaves=3:tscale=0.3,lutyuv=y='if(lt(val\,128)\,255\,0)'
Stretch noise along the y axis, and convert gray level to red-only
signal:
perlin=octaves=7:tscale=0.4:yscale=0.3,lutrgb=r=val:b=0:g=0
44.11 qrencodesrc
Generate a QR code using the libqrencode library (see
https://fukuchi.org/works/qrencode/).
To enable the compilation of this source, you need to configure FFmpeg with
--enable-libqrencode.
The QR code is generated from the provided text or text pattern. The
corresponding QR code is scaled and put in the video output according to the
specified output size options.
In case no text is specified, the QR code is not generated, but an empty colored
output is returned instead.
This source accepts the following options:
qrcode_width, q
padded_qrcode_width, Q
Specify an expression for the width of the rendered QR code, with and without
padding. The qrcode_width expression can reference the value set by the
padded_qrcode_width expression, and vice versa.
By default padded_qrcode_width is set to qrcode_width, meaning that
there is no padding.
These expressions are evaluated only once, when initializing the source.
See the qrencode Expressions section for details.
Note that some of the constants are missing for the source (for example the
x or t or ¸n), since they only makes sense when evaluating the
expression for each frame rather than at initialization time.
rate, r
Specify the frame rate of the sourced video, as the number of frames
generated per second. It has to be a string in the format
frame_rate_num/frame_rate_den, an integer number, a floating point
number or a valid video frame rate abbreviation. The default value is
"25".
case_sensitive, cs
Instruct libqrencode to use case sensitive encoding. This is enabled by
default. This can be disabled to reduce the QR encoding size.
level, l
Specify the QR encoding error correction level. With an higher correction level,
the encoding size will increase but the code will be more robust to corruption.
Lower level is L.
It accepts the following values:
‘L’
‘M’
‘Q’
‘H’
expansion
Select how the input text is expanded. Can be either none, or
normal (default). See the qrencode Text expansion
section for details.
text
textfile
Define the text to be rendered. In case neither is specified, no QR is encoded
(just an empty colored frame).
In case expansion is enabled, the text is treated as a text template, using the
qrencode expansion mechanism. See the qrencode
Text expansion section for details.
background_color, bc
foreground_color, fc
Set the QR code and background color. The default value of
foreground_color is "black", the default value of background_color
is "white".
For the syntax of the color options, check the (ffmpeg-utils)"Color"
section in the ffmpeg-utils manual.
44.11.1 Examples
Generate a QR code encoding the specified text with the default size:
qrencodesrc=text=www.ffmpeg.org
Same as below, but select blue on pink colors:
qrencodesrc=text=www.ffmpeg.org:bc=pink:fc=blue
Generate a QR code with width of 200 pixels and padding, making the padded width
4/3 of the QR code width:
qrencodesrc=text=www.ffmpeg.org:q=200:Q=4/3*q
Generate a QR code with padded width of 200 pixels and padding, making the QR
code width 3/4 of the padded width:
qrencodesrc=text=www.ffmpeg.org:Q=200:q=3/4*Q
Generate a QR code encoding the frame number:
qrencodesrc=text=%{n}
Generate a QR code encoding the GMT timestamp:
qrencodesrc=text=%{gmtime}
Generate a QR code encoding the timestamp expressed as a float:
qrencodesrc=text=%{pts}
44.12 allrgb, allyuv, color, colorchart, colorspectrum, haldclutsrc, nullsrc, pal75bars, pal100bars, rgbtestsrc, smptebars, smptehdbars, testsrc, testsrc2, yuvtestsrc
The allrgb source returns frames of size 4096x4096 of all rgb colors.
The allyuv source returns frames of size 4096x4096 of all yuv colors.
The color source provides an uniformly colored input.
The colorchart source provides a colors checker chart.
The colorspectrum source provides a color spectrum input.
The haldclutsrc source provides an identity Hald CLUT. See also
haldclut filter.
The nullsrc source returns unprocessed video frames. It is
mainly useful to be employed in analysis / debugging tools, or as the
source for filters which ignore the input data.
The pal75bars source generates a color bars pattern, based on
EBU PAL recommendations with 75% color levels.
The pal100bars source generates a color bars pattern, based on
EBU PAL recommendations with 100% color levels.
The rgbtestsrc source generates an RGB test pattern useful for
detecting RGB vs BGR issues. You should see a red, green and blue
stripe from top to bottom.
The smptebars source generates a color bars pattern, based on
the SMPTE Engineering Guideline EG 1-1990.
The smptehdbars source generates a color bars pattern, based on
the SMPTE RP 219-2002.
The testsrc source generates a test video pattern, showing a
color pattern, a scrolling gradient and a timestamp. This is mainly
intended for testing purposes.
The testsrc2 source is similar to testsrc, but supports more
pixel formats instead of just rgb24. This allows using it as an
input for other tests without requiring a format conversion.
The yuvtestsrc source generates an YUV test pattern. You should
see a y, cb and cr stripe from top to bottom.
The sources accept the following parameters:
level
Specify the level of the Hald CLUT, only available in the haldclutsrc
source. A level of N generates a picture of N*N*N by N*N*N
pixels to be used as identity matrix for 3D lookup tables. Each component is
coded on a 1/(N*N) scale.
color, c
Specify the color of the source, only available in the color
source. For the syntax of this option, check the
(ffmpeg-utils)"Color" section in the ffmpeg-utils manual.
size, s
Specify the size of the sourced video. For the syntax of this option, check the
(ffmpeg-utils)"Video size" section in the ffmpeg-utils manual.
The default value is 320x240.
This option is not available with the allrgb, allyuv, and
haldclutsrc filters.
rate, r
Specify the frame rate of the sourced video, as the number of frames
generated per second. It has to be a string in the format
frame_rate_num/frame_rate_den, an integer number, a floating point
number or a valid video frame rate abbreviation. The default value is
"25".
duration, d
Set the duration of the sourced video. See
(ffmpeg-utils)the Time duration section in the ffmpeg-utils(1) manual
for the accepted syntax.
If not specified, or the expressed duration is negative, the video is
supposed to be generated forever.
Since the frame rate is used as time base, all frames including the last one
will have their full duration. If the specified duration is not a multiple
of the frame duration, it will be rounded up.
sar
Set the sample aspect ratio of the sourced video.
alpha
Specify the alpha (opacity) of the background, only available in the
testsrc2 source. The value must be between 0 (fully transparent) and
255 (fully opaque, the default).
decimals, n
Set the number of decimals to show in the timestamp, only available in the
testsrc source.
The displayed timestamp value will correspond to the original
timestamp value multiplied by the power of 10 of the specified
value. Default value is 0.
type
Set the type of the color spectrum, only available in the
colorspectrum source. Can be one of the following:
‘black’
‘white’
‘all’
patch_size
Set patch size of single color patch, only available in the
colorchart source. Default is 64x64.
preset
Set colorchecker colors preset, only available in the
colorchart source.
Available values are:
‘reference’
‘skintones’
Default value is reference.
44.12.1 Examples
Generate a video with a duration of 5.3 seconds, with size
176x144 and a frame rate of 10 frames per second:
testsrc=duration=5.3:size=qcif:rate=10
The following graph description will generate a red source
with an opacity of 0.2, with size "qcif" and a frame rate of 10
frames per second:
[email protected]:s=qcif:r=10
If the input content is to be ignored, nullsrc can be used. The
following command generates noise in the luma plane by employing
the geq filter:
nullsrc=s=256x256, geq=random(1)*255:128:128
44.12.2 Commands
The color source supports the following commands:
c, color
Set the color of the created image. Accepts the same syntax of the
corresponding color option.
44.13 openclsrc
Generate video using an OpenCL program.
source
OpenCL program source file.
kernel
Kernel name in program.
size, s
Size of frames to generate.  This must be set.
format
Pixel format to use for the generated frames.  This must be set.
rate, r
Number of frames generated every second.  Default value is ’25’.
For details of how the program loading works, see the program_opencl
filter.
Example programs:
Generate a colour ramp by setting pixel values from the position of the pixel
in the output image.  (Note that this will work with all pixel formats, but
the generated output will not be the same.)
__kernel void ramp(__write_only image2d_t dst,
unsigned int index)
{
int2 loc = (int2)(get_global_id(0), get_global_id(1));
float4 val;
val.xy = val.zw = convert_float2(loc) / convert_float2(get_image_dim(dst));
write_imagef(dst, loc, val);
}
Generate a Sierpinski carpet pattern, panning by a single pixel each frame.
__kernel void sierpinski_carpet(__write_only image2d_t dst,
unsigned int index)
{
int2 loc = (int2)(get_global_id(0), get_global_id(1));
float4 value = 0.0f;
int x = loc.x + index;
int y = loc.y + index;
while (x > 0 || y > 0) {
if (x % 3 == 1 && y % 3 == 1) {
value = 1.0f;
break;
}
x /= 3;
y /= 3;
}
write_imagef(dst, loc, value);
}
44.14 sierpinski
Generate a Sierpinski carpet/triangle fractal, and randomly pan around.
This source accepts the following options:
size, s
Set frame size. For the syntax of this option, check the (ffmpeg-utils)"Video
size" section in the ffmpeg-utils manual. Default value is "640x480".
rate, r
Set frame rate, expressed as number of frames per second. Default
value is "25".
seed
Set seed which is used for random panning.
jump
Set max jump for single pan destination. Allowed range is from 1 to 10000.
type
Set fractal type, can be default carpet or triangle.
44.15 zoneplate
Generate a zoneplate test video pattern.
This source accepts the following options:
size, s
Set frame size. For the syntax of this option, check the (ffmpeg-utils)"Video
size" section in the ffmpeg-utils manual. Default value is "320x240".
rate, r
Set frame rate, expressed as number of frames per second. Default
value is "25".
duration, d
Set the duration of the sourced video. See
(ffmpeg-utils)the Time duration section in the ffmpeg-utils(1) manual
for the accepted syntax.
If not specified, or the expressed duration is negative, the video is
supposed to be generated forever.
sar
Set the sample aspect ratio of the sourced video.
precision
Set precision in bits for look-up table for sine calculations. Default value is 10.
Allowed range is from 4 to 16.
xo
Set horizontal axis offset for output signal. Default value is 0.
yo
Set vertical axis offset for output signal. Default value is 0.
to
Set time axis offset for output signal. Default value is 0.
k0
Set 0-order, constant added to signal phase. Default value is 0.
kx
Set 1-order, phase factor multiplier for horizontal axis. Default value is 0.
ky
Set 1-order, phase factor multiplier for vertical axis. Default value is 0.
kt
Set 1-order, phase factor multiplier for time axis. Default value is 0.
kxt, kyt, kxy
Set phase factor multipliers for combination of spatial and temporal axis.
Default value is 0.
kx2
Set 2-order, phase factor multiplier for horizontal axis. Default value is 0.
ky2
Set 2-order, phase factor multiplier for vertical axis. Default value is 0.
kt2
Set 2-order, phase factor multiplier for time axis. Default value is 0.
ku
Set the constant added to final phase to produce chroma-blue component of signal.
Default value is 0.
kv
Set the constant added to final phase to produce chroma-red component of signal.
Default value is 0.
44.15.1 Commands
This source supports the some above options as commands.
44.15.2 Examples
Generate horizontal color sine sweep:
zoneplate=ku=512:kv=0:kt2=0:kx2=256:s=wvga:xo=-426:kt=11
Generate vertical color sine sweep:
zoneplate=ku=512:kv=0:kt2=0:ky2=156:s=wvga:yo=-240:kt=11
Generate circular zone-plate:
zoneplate=ku=512:kv=100:kt2=0:ky2=256:kx2=556:s=wvga:yo=0:kt=11
45 Video Sinks
Below is a description of the currently available video sinks.
45.1 buffersink
Buffer video frames, and make them available to the end of the filter
graph.
This sink is mainly intended for programmatic use, in particular
through the interface defined in libavfilter/buffersink.h
or the options system.
It accepts a pointer to an AVBufferSinkContext structure, which
defines the incoming buffers’ formats, to be passed as the opaque
parameter to avfilter_init_filter for initialization.
45.2 nullsink
Null video sink: do absolutely nothing with the input video. It is
mainly useful as a template and for use in analysis / debugging
tools.
46 Multimedia Filters
Below is a description of the currently available multimedia filters.
46.1 a3dscope
Convert input audio to 3d scope video output.
The filter accepts the following options:
rate, r
Set frame rate, expressed as number of frames per second. Default
value is "25".
size, s
Specify the video size for the output. For the syntax of this option, check the
(ffmpeg-utils)"Video size" section in the ffmpeg-utils manual.
Default value is hd720.
fov
Set the camera field of view. Default is 90 degrees.
Allowed range is from 40 to 150.
roll
Set the camera roll.
pitch
Set the camera pitch.
yaw
Set the camera yaw.
xzoom
Set the camera zoom on X-axis.
yzoom
Set the camera zoom on Y-axis.
zzoom
Set the camera zoom on Z-axis.
xpos
Set the camera position on X-axis.
ypos
Set the camera position on Y-axis.
zpos
Set the camera position on Z-axis.
length
Set the length of displayed audio waves in number of frames.
46.1.1 Commands
Filter supports the some above options as commands.
46.2 abitscope
Convert input audio to a video output, displaying the audio bit scope.
The filter accepts the following options:
rate, r
Set frame rate, expressed as number of frames per second. Default
value is "25".
size, s
Specify the video size for the output. For the syntax of this option, check the
(ffmpeg-utils)"Video size" section in the ffmpeg-utils manual.
Default value is 1024x256.
colors
Specify list of colors separated by space or by ’|’ which will be used to
draw channels. Unrecognized or missing colors will be replaced
by white color.
mode, m
Set output mode. Can be bars or trace. Default is bars.
46.3 adrawgraph
Draw a graph using input audio metadata.
See drawgraph
46.4 agraphmonitor
See graphmonitor.
46.5 ahistogram
Convert input audio to a video output, displaying the volume histogram.
The filter accepts the following options:
dmode
Specify how histogram is calculated.
It accepts the following values:
‘single’
Use single histogram for all channels.
‘separate’
Use separate histogram for each channel.
Default is single.
rate, r
Set frame rate, expressed as number of frames per second. Default
value is "25".
size, s
Specify the video size for the output. For the syntax of this option, check the
(ffmpeg-utils)"Video size" section in the ffmpeg-utils manual.
Default value is hd720.
scale
Set display scale.
It accepts the following values:
‘log’
logarithmic
‘sqrt’
square root
‘cbrt’
cubic root
‘lin’
linear
‘rlog’
reverse logarithmic
Default is log.
ascale
Set amplitude scale.
It accepts the following values:
‘log’
logarithmic
‘lin’
linear
Default is log.
acount
Set how much frames to accumulate in histogram.
Default is 1. Setting this to -1 accumulates all frames.
rheight
Set histogram ratio of window height.
slide
Set sonogram sliding.
It accepts the following values:
‘replace’
replace old rows with new ones.
‘scroll’
scroll from top to bottom.
Default is replace.
hmode
Set histogram mode.
It accepts the following values:
‘abs’
Use absolute values of samples.
‘sign’
Use untouched values of samples.
Default is abs.
46.6 aphasemeter
Measures phase of input audio, which is exported as metadata lavfi.aphasemeter.phase,
representing mean phase of current audio frame. A video output can also be produced and is
enabled by default. The audio is passed through as first output.
Audio will be rematrixed to stereo if it has a different channel layout. Phase value is in
range [-1, 1] where -1 means left and right channels are completely out of phase
and 1 means channels are in phase.
The filter accepts the following options, all related to its video output:
rate, r
Set the output frame rate. Default value is 25.
size, s
Set the video size for the output. For the syntax of this option, check the
(ffmpeg-utils)"Video size" section in the ffmpeg-utils manual.
Default value is 800x400.
rc
gc
bc
Specify the red, green, blue contrast. Default values are 2,
7 and 1.
Allowed range is [0, 255].
mpc
Set color which will be used for drawing median phase. If color is
none which is default, no median phase value will be drawn.
video
Enable video output. Default is enabled.
46.6.1 phasing detection
The filter also detects out of phase and mono sequences in stereo streams.
It logs the sequence start, end and duration when it lasts longer or as long as the minimum set.
The filter accepts the following options for this detection:
phasing
Enable mono and out of phase detection. Default is disabled.
tolerance, t
Set phase tolerance for mono detection, in amplitude ratio. Default is 0.
Allowed range is [0, 1].
angle, a
Set angle threshold for out of phase detection, in degree. Default is 170.
Allowed range is [90, 180].
duration, d
Set mono or out of phase duration until notification, expressed in seconds. Default is 2.
46.6.2 Examples
Complete example with ffmpeg to detect 1 second of mono with 0.001 phase tolerance:
ffmpeg -i stereo.wav -af aphasemeter=video=0:phasing=1:duration=1:tolerance=0.001 -f null -
46.7 avectorscope
Convert input audio to a video output, representing the audio vector
scope.
The filter is used to measure the difference between channels of stereo
audio stream. A monaural signal, consisting of identical left and right
signal, results in straight vertical line. Any stereo separation is visible
as a deviation from this line, creating a Lissajous figure.
If the straight (or deviation from it) but horizontal line appears this
indicates that the left and right channels are out of phase.
The filter accepts the following options:
mode, m
Set the vectorscope mode.
Available values are:
‘lissajous’
Lissajous rotated by 45 degrees.
‘lissajous_xy’
Same as above but not rotated.
‘polar’
Shape resembling half of circle.
Default value is ‘lissajous’.
size, s
Set the video size for the output. For the syntax of this option, check the
(ffmpeg-utils)"Video size" section in the ffmpeg-utils manual.
Default value is 400x400.
rate, r
Set the output frame rate. Default value is 25.
rc
gc
bc
ac
Specify the red, green, blue and alpha contrast. Default values are 40,
160, 80 and 255.
Allowed range is [0, 255].
rf
gf
bf
af
Specify the red, green, blue and alpha fade. Default values are 15,
10, 5 and 5.
Allowed range is [0, 255].
zoom
Set the zoom factor. Default value is 1. Allowed range is [0, 10].
Values lower than 1 will auto adjust zoom factor to maximal possible value.
draw
Set the vectorscope drawing mode.
Available values are:
‘dot’
Draw dot for each sample.
‘line’
Draw line between previous and current sample.
‘aaline’
Draw anti-aliased line between previous and current sample.
Default value is ‘dot’.
scale
Specify amplitude scale of audio samples.
Available values are:
‘lin’
Linear.
‘sqrt’
Square root.
‘cbrt’
Cubic root.
‘log’
Logarithmic.
swap
Swap left channel axis with right channel axis.
mirror
Mirror axis.
‘none’
No mirror.
‘x’
Mirror only x axis.
‘y’
Mirror only y axis.
‘xy’
Mirror both axis.
46.7.1 Examples
Complete example using ffplay:
ffplay -f lavfi 'amovie=input.mp3, asplit [a][out1];
[a] avectorscope=zoom=1.3:rc=2:gc=200:bc=10:rf=1:gf=8:bf=7 [out0]'
46.7.2 Commands
This filter supports the all above options as commands except options size and rate.
46.8 bench, abench
Benchmark part of a filtergraph.
The filter accepts the following options:
action
Start or stop a timer.
Available values are:
‘start’
Get the current time, set it as frame metadata (using the key
lavfi.bench.start_time), and forward the frame to the next filter.
‘stop’
Get the current time and fetch the lavfi.bench.start_time metadata from
the input frame metadata to get the time difference. Time difference, average,
maximum and minimum time (respectively t, avg, max and
min) are then printed. The timestamps are expressed in seconds.
46.8.1 Examples
Benchmark selectivecolor filter:
bench=start,selectivecolor=reds=-.2 .12 -.49,bench=stop
46.9 concat
Concatenate audio and video streams, joining them together one after the
other.
The filter works on segments of synchronized video and audio streams. All
segments must have the same number of streams of each type, and that will
also be the number of streams at output.
The filter accepts the following options:
n
Set the number of segments. Default is 2.
v
Set the number of output video streams, that is also the number of video
streams in each segment. Default is 1.
a
Set the number of output audio streams, that is also the number of audio
streams in each segment. Default is 0.
unsafe
Activate unsafe mode: do not fail if segments have a different format.
The filter has v+a outputs: first v video outputs, then
a audio outputs.
There are nx(v+a) inputs: first the inputs for the first
segment, in the same order as the outputs, then the inputs for the second
segment, etc.
Related streams do not always have exactly the same duration, for various
reasons including codec frame size or sloppy authoring. For that reason,
related synchronized streams (e.g. a video and its audio track) should be
concatenated at once. The concat filter will use the duration of the longest
stream in each segment (except the last one), and if necessary pad shorter
audio streams with silence.
For this filter to work correctly, all segments must start at timestamp 0.
All corresponding streams must have the same parameters in all segments; the
filtering system will automatically select a common pixel format for video
streams, and a common sample format, sample rate and channel layout for
audio streams, but other settings, such as resolution, must be converted
explicitly by the user.
Different frame rates are acceptable but will result in variable frame rate
at output; be sure to configure the output file to handle it.
46.9.1 Examples
Concatenate an opening, an episode and an ending, all in bilingual version
(video in stream 0, audio in streams 1 and 2):
ffmpeg -i opening.mkv -i episode.mkv -i ending.mkv -filter_complex \
'[0:0] [0:1] [0:2] [1:0] [1:1] [1:2] [2:0] [2:1] [2:2]
concat=n=3:v=1:a=2 [v] [a1] [a2]' \
-map '[v]' -map '[a1]' -map '[a2]' output.mkv
Concatenate two parts, handling audio and video separately, using the
(a)movie sources, and adjusting the resolution:
movie=part1.mp4, scale=512:288 [v1] ; amovie=part1.mp4 [a1] ;
movie=part2.mp4, scale=512:288 [v2] ; amovie=part2.mp4 [a2] ;
[v1] [v2] concat [outv] ; [a1] [a2] concat=v=0:a=1 [outa]
Note that a desync will happen at the stitch if the audio and video streams
do not have exactly the same duration in the first file.
46.9.2 Commands
This filter supports the following commands:
next
Close the current segment and step to the next one
46.10 ebur128
EBU R128 scanner filter. This filter takes an audio stream and analyzes its loudness
level. By default, it logs a message at a frequency of 10Hz with the
Momentary loudness (identified by M), Short-term loudness (S),
Integrated loudness (I) and Loudness Range (LRA).
The filter can only analyze streams which have
sample format is double-precision floating point. The input stream will be converted to
this specification, if needed. Users may need to insert aformat and/or aresample filters
after this filter to obtain the original parameters.
The filter also has a video output (see the video option) with a real
time graph to observe the loudness evolution. The graphic contains the logged
message mentioned above, so it is not printed anymore when this option is set,
unless the verbose logging is set. The main graphing area contains the
short-term loudness (3 seconds of analysis), and the gauge on the right is for
the momentary loudness (400 milliseconds), but can optionally be configured
to instead display short-term loudness (see gauge).
The green area marks a  +/- 1LU target range around the target loudness
(-23LUFS by default, unless modified through target).
More information about the Loudness Recommendation EBU R128 on
http://tech.ebu.ch/loudness.
The filter accepts the following options:
video
Activate the video output. The audio stream is passed unchanged whether this
option is set or no. The video stream will be the first output stream if
activated. Default is 0.
size
Set the video size. This option is for video only. For the syntax of this
option, check the
(ffmpeg-utils)"Video size" section in the ffmpeg-utils manual.
Default and minimum resolution is 640x480.
meter
Set the EBU scale meter. Default is 9. Common values are 9 and
18, respectively for EBU scale meter +9 and EBU scale meter +18. Any
other integer value between this range is allowed.
metadata
Set metadata injection. If set to 1, the audio input will be segmented
into 100ms output frames, each of them containing various loudness information
in metadata.  All the metadata keys are prefixed with lavfi.r128..
Default is 0.
framelog
Force the frame logging level.
Available values are:
‘quiet’
logging disabled
‘info’
information logging level
‘verbose’
verbose logging level
By default, the logging level is set to info. If the video or
the metadata options are set, it switches to verbose.
peak
Set peak mode(s).
Available modes can be cumulated (the option is a flag type). Possible
values are:
‘none’
Disable any peak mode (default).
‘sample’
Enable sample-peak mode.
Simple peak mode looking for the higher sample value. It logs a message
for sample-peak (identified by SPK).
‘true’
Enable true-peak mode.
If enabled, the peak lookup is done on an over-sampled version of the input
stream for better peak accuracy. It logs a message for true-peak.
(identified by TPK) and true-peak per frame (identified by FTPK).
This mode requires a build with libswresample.
dualmono
Treat mono input files as "dual mono". If a mono file is intended for playback
on a stereo system, its EBU R128 measurement will be perceptually incorrect.
If set to true, this option will compensate for this effect.
Multi-channel input files are not affected by this option.
panlaw
Set a specific pan law to be used for the measurement of dual mono files.
This parameter is optional, and has a default value of -3.01dB.
target
Set a specific target level (in LUFS) used as relative zero in the visualization.
This parameter is optional and has a default value of -23LUFS as specified
by EBU R128. However, material published online may prefer a level of -16LUFS
(e.g. for use with podcasts or video platforms).
gauge
Set the value displayed by the gauge. Valid values are momentary and s
shortterm. By default the momentary value will be used, but in certain
scenarios it may be more useful to observe the short term value instead (e.g.
live mixing).
scale
Sets the display scale for the loudness. Valid parameters are absolute
(in LUFS) or relative (LU) relative to the target. This only affects the
video output, not the summary or continuous log output.
integrated
Read-only exported value for measured integrated loudness, in LUFS.
range
Read-only exported value for measured loudness range, in LU.
lra_low
Read-only exported value for measured LRA low, in LUFS.
lra_high
Read-only exported value for measured LRA high, in LUFS.
sample_peak
Read-only exported value for measured sample peak, in dBFS.
true_peak
Read-only exported value for measured true peak, in dBFS.
46.10.1 Examples
Real-time graph using ffplay, with a EBU scale meter +18:
ffplay -f lavfi -i "amovie=input.mp3,ebur128=video=1:meter=18 [out0][out1]"
Run an analysis with ffmpeg:
ffmpeg -nostats -i input.mp3 -filter_complex ebur128 -f null -
46.11 interleave, ainterleave
Temporally interleave frames from several inputs.
interleave works with video inputs, ainterleave with audio.
These filters read frames from several inputs and send the oldest
queued frame to the output.
Input streams must have well defined, monotonically increasing frame
timestamp values.
In order to submit one frame to output, these filters need to enqueue
at least one frame for each input, so they cannot work in case one
input is not yet terminated and will not receive incoming frames.
For example consider the case when one input is a select filter
which always drops input frames. The interleave filter will keep
reading from that input, but it will never be able to send new frames
to output until the input sends an end-of-stream signal.
Also, depending on inputs synchronization, the filters will drop
frames in case one input receives more frames than the other ones, and
the queue is already filled.
These filters accept the following options:
nb_inputs, n
Set the number of different inputs, it is 2 by default.
duration
How to determine the end-of-stream.
longest
The duration of the longest input. (default)
shortest
The duration of the shortest input.
first
The duration of the first input.
46.11.1 Examples
Interleave frames belonging to different streams using ffmpeg:
ffmpeg -i bambi.avi -i pr0n.mkv -filter_complex "[0:v][1:v] interleave" out.avi
Add flickering blur effect:
select='if(gt(random(0), 0.2), 1, 2)':n=2 [tmp], boxblur=2:2, [tmp] interleave
46.12 latency, alatency
Measure filtering latency.
Report previous filter filtering latency, delay in number of audio samples for audio filters
or number of video frames for video filters.
On end of input stream, filter will report min and max measured latency for previous running filter
in filtergraph.
46.13 metadata, ametadata
Manipulate frame metadata.
This filter accepts the following options:
mode
Set mode of operation of the filter.
Can be one of the following:
‘select’
If both value and key is set, select frames
which have such metadata. If only key is set, select
every frame that has such key in metadata.
‘add’
Add new metadata key and value. If key is already available
do nothing.
‘modify’
Modify value of already present key.
‘delete’
If value is set, delete only keys that have such value.
Otherwise, delete key. If key is not set, delete all metadata values in
the frame.
‘print’
Print key and its value if metadata was found. If key is not set print all
metadata values available in frame.
key
Set key used with all modes. Must be set for all modes except print and delete.
value
Set metadata value which will be used. This option is mandatory for
modify and add mode.
function
Which function to use when comparing metadata value and value.
Can be one of following:
‘same_str’
Values are interpreted as strings, returns true if metadata value is same as value.
‘starts_with’
Values are interpreted as strings, returns true if metadata value starts with
the value option string.
‘less’
Values are interpreted as floats, returns true if metadata value is less than value.
‘equal’
Values are interpreted as floats, returns true if value is equal with metadata value.
‘greater’
Values are interpreted as floats, returns true if metadata value is greater than value.
‘expr’
Values are interpreted as floats, returns true if expression from option expr
evaluates to true.
‘ends_with’
Values are interpreted as strings, returns true if metadata value ends with
the value option string.
expr
Set expression which is used when function is set to expr.
The expression is evaluated through the eval API and can contain the following
constants:
VALUE1, FRAMEVAL
Float representation of value from metadata key.
VALUE2, USERVAL
Float representation of value as supplied by user in value option.
file
If specified in print mode, output is written to the named file. Instead of
plain filename any writable url can be specified. Filename “-” is a shorthand
for standard output. If file option is not set, output is written to the log
with AV_LOG_INFO loglevel.
direct
Reduces buffering in print mode when output is written to a URL set using file.
46.13.1 Examples
Print all metadata values for frames with key lavfi.signalstats.YDIF with values
between 0 and 1.
signalstats,metadata=print:key=lavfi.signalstats.YDIF:value=0:function=expr:expr='between(VALUE1,0,1)'
Print silencedetect output to file metadata.txt.
silencedetect,ametadata=mode=print:file=metadata.txt
Direct all metadata to a pipe with file descriptor 4.
metadata=mode=print:file='pipe\:4'
46.14 perms, aperms
Set read/write permissions for the output frames.
These filters are mainly aimed at developers to test direct path in the
following filter in the filtergraph.
The filters accept the following options:
mode
Select the permissions mode.
It accepts the following values:
‘none’
Do nothing. This is the default.
‘ro’
Set all the output frames read-only.
‘rw’
Set all the output frames directly writable.
‘toggle’
Make the frame read-only if writable, and writable if read-only.
‘random’
Set each output frame read-only or writable randomly.
seed
Set the seed for the random mode, must be an integer included between
0 and UINT32_MAX. If not specified, or if explicitly set to
-1, the filter will try to use a good random seed on a best effort
basis.
Note: in case of auto-inserted filter between the permission filter and the
following one, the permission might not be received as expected in that
following filter. Inserting a format or aformat filter before the
perms/aperms filter can avoid this problem.
46.15 realtime, arealtime
Slow down filtering to match real time approximately.
These filters will pause the filtering for a variable amount of time to
match the output rate with the input timestamps.
They are similar to the re option to ffmpeg.
They accept the following options:
limit
Time limit for the pauses. Any pause longer than that will be considered
a timestamp discontinuity and reset the timer. Default is 2 seconds.
speed
Speed factor for processing. The value must be a float larger than zero.
Values larger than 1.0 will result in faster than realtime processing,
smaller will slow processing down. The limit is automatically adapted
accordingly. Default is 1.0.
A processing speed faster than what is possible without these filters cannot
be achieved.
46.15.1 Commands
Both filters supports the all above options as commands.
46.16 segment, asegment
Split single input stream into multiple streams.
This filter does opposite of concat filters.
segment works on video frames, asegment on audio samples.
This filter accepts the following options:
timestamps
Timestamps of output segments separated by ’|’. The first segment will run
from the beginning of the input stream. The last segment will run until
the end of the input stream
frames, samples
Exact frame/sample count to split the segments.
In all cases, prefixing an each segment with ’+’ will make it relative to the
previous segment.
46.16.1 Examples
Split input audio stream into three output audio streams, starting at start of input audio stream
and storing that in 1st output audio stream, then following at 60th second and storing than in 2nd
output audio stream, and last after 150th second of input audio stream store in 3rd output audio stream:
asegment=timestamps="60|150"
46.17 select, aselect
Select frames to pass in output.
This filter accepts the following options:
expr, e
Set expression, which is evaluated for each input frame.
If the expression is evaluated to zero, the frame is discarded.
If the evaluation result is negative or NaN, the frame is sent to the
first output; otherwise it is sent to the output with index
ceil(val)-1, assuming that the input index starts from 0.
For example a value of 1.2 corresponds to the output with index
ceil(1.2)-1 = 2-1 = 1, that is the second output.
outputs, n
Set the number of outputs. The output to which to send the selected
frame is based on the result of the evaluation. Default value is 1.
The expression can contain the following constants:
n
The (sequential) number of the filtered frame, starting from 0.
selected_n
The (sequential) number of the selected frame, starting from 0.
prev_selected_n
The sequential number of the last selected frame. It’s NAN if undefined.
TB
The timebase of the input timestamps.
pts
The PTS (Presentation TimeStamp) of the filtered frame,
expressed in TB units. It’s NAN if undefined.
t
The PTS of the filtered frame,
expressed in seconds. It’s NAN if undefined.
prev_pts
The PTS of the previously filtered frame. It’s NAN if undefined.
prev_selected_pts
The PTS of the last previously filtered frame. It’s NAN if undefined.
prev_selected_t
The PTS of the last previously selected frame, expressed in seconds. It’s NAN if undefined.
start_pts
The first PTS in the stream which is not NAN. It remains NAN if not found.
start_t
The first PTS, in seconds, in the stream which is not NAN. It remains NAN if not found.
pict_type (video only)
The type of the filtered frame. It can assume one of the following
values:
I
P
B
S
SI
SP
BI
interlace_type (video only)
The frame interlace type. It can assume one of the following values:
PROGRESSIVE
The frame is progressive (not interlaced).
TOPFIRST
The frame is top-field-first.
BOTTOMFIRST
The frame is bottom-field-first.
consumed_sample_n (audio only)
the number of selected samples before the current frame
samples_n (audio only)
the number of samples in the current frame
sample_rate (audio only)
the input sample rate
key
This is 1 if the filtered frame is a key-frame, 0 otherwise.
pos
the position in the file of the filtered frame, -1 if the information
is not available (e.g. for synthetic video); deprecated, do not use
scene (video only)
value between 0 and 1 to indicate a new scene; a low value reflects a low
probability for the current frame to introduce a new scene, while a higher
value means the current frame is more likely to be one (see the example below)
concatdec_select
The concat demuxer can select only part of a concat input file by setting an
inpoint and an outpoint, but the output packets may not be entirely contained
in the selected interval. By using this variable, it is possible to skip frames
generated by the concat demuxer which are not exactly contained in the selected
interval.
This works by comparing the frame pts against the lavf.concat.start_time
and the lavf.concat.duration packet metadata values which are also
present in the decoded frames.
The concatdec_select variable is -1 if the frame pts is at least
start_time and either the duration metadata is missing or the frame pts is less
than start_time + duration, 0 otherwise, and NaN if the start_time metadata is
missing.
That basically means that an input frame is selected if its pts is within the
interval set by the concat demuxer.
iw (video only)
Represents the width of the input video frame.
ih (video only)
Represents the height of the input video frame.
view (video only)
View ID for multi-view video.
The default value of the select expression is "1".
46.17.1 Examples
Select all frames in input:
select
The example above is the same as:
select=1
Skip all frames:
select=0
Select only I-frames:
select='eq(pict_type\,I)'
Select one frame every 100:
select='not(mod(n\,100))'
Select only frames contained in the 10-20 time interval:
select=between(t\,10\,20)
Select only I-frames contained in the 10-20 time interval:
select=between(t\,10\,20)*eq(pict_type\,I)
Select frames with a minimum distance of 10 seconds:
select='isnan(prev_selected_t)+gte(t-prev_selected_t\,10)'
Use aselect to select only audio frames with samples number > 100:
aselect='gt(samples_n\,100)'
Create a mosaic of the first scenes:
ffmpeg -i video.avi -vf select='gt(scene\,0.4)',scale=160:120,tile -frames:v 1 preview.png
Comparing scene against a value between 0.3 and 0.5 is generally a sane
choice.
Send even and odd frames to separate outputs, and compose them:
select=n=2:e='mod(n, 2)+1' [odd][even]; [odd] pad=h=2*ih [tmp]; [tmp][even] overlay=y=h
Select useful frames from an ffconcat file which is using inpoints and
outpoints but where the source files are not intra frame only.
ffmpeg -copyts -vsync 0 -segment_time_metadata 1 -i input.ffconcat -vf select=concatdec_select -af aselect=concatdec_select output.avi
46.18 sendcmd, asendcmd
Send commands to filters in the filtergraph.
These filters read commands to be sent to other filters in the
filtergraph.
sendcmd must be inserted between two video filters,
asendcmd must be inserted between two audio filters, but apart
from that they act the same way.
The specification of commands can be provided in the filter arguments
with the commands option, or in a file specified by the
filename option.
These filters accept the following options:
commands, c
Set the commands to be read and sent to the other filters.
filename, f
Set the filename of the commands to be read and sent to the other
filters.
46.18.1 Commands syntax
A commands description consists of a sequence of interval
specifications, comprising a list of commands to be executed when a
particular event related to that interval occurs. The occurring event
is typically the current frame time entering or leaving a given time
interval.
An interval is specified by the following syntax:
START[-END] COMMANDS;
The time interval is specified by the START and END times.
END is optional and defaults to the maximum time.
The current frame time is considered within the specified interval if
it is included in the interval [START, END), that is when
the time is greater or equal to START and is lesser than
END.
COMMANDS consists of a sequence of one or more command
specifications, separated by ",", relating to that interval.  The
syntax of a command specification is given by:
[FLAGS] TARGET COMMAND ARG
FLAGS is optional and specifies the type of events relating to
the time interval which enable sending the specified command, and must
be a non-null sequence of identifier flags separated by "+" or "|" and
enclosed between "[" and "]".
The following flags are recognized:
enter
The command is sent when the current frame timestamp enters the
specified interval. In other words, the command is sent when the
previous frame timestamp was not in the given interval, and the
current is.
leave
The command is sent when the current frame timestamp leaves the
specified interval. In other words, the command is sent when the
previous frame timestamp was in the given interval, and the
current is not.
expr
The command ARG is interpreted as expression and result of
expression is passed as ARG.
The expression is evaluated through the eval API and can contain the following
constants:
POS
Original position in the file of the frame, or undefined if undefined
for the current frame. Deprecated, do not use.
PTS
The presentation timestamp in input.
N
The count of the input frame for video or audio, starting from 0.
T
The time in seconds of the current frame.
TS
The start time in seconds of the current command interval.
TE
The end time in seconds of the current command interval.
TI
The interpolated time of the current command interval, TI = (T - TS) / (TE - TS).
W
The video frame width.
H
The video frame height.
If FLAGS is not specified, a default value of [enter] is
assumed.
TARGET specifies the target of the command, usually the name of
the filter class or a specific filter instance name.
COMMAND specifies the name of the command for the target filter.
ARG is optional and specifies the optional list of argument for
the given COMMAND.
Between one interval specification and another, whitespaces, or
sequences of characters starting with # until the end of line,
are ignored and can be used to annotate comments.
A simplified BNF description of the commands specification syntax
follows:
COMMAND_FLAG  ::= "enter" | "leave"
COMMAND_FLAGS ::= COMMAND_FLAG [(+|"|")COMMAND_FLAG]
COMMAND       ::= ["[" COMMAND_FLAGS "]"] TARGET COMMAND [ARG]
COMMANDS      ::= COMMAND [,COMMANDS]
INTERVAL      ::= START[-END] COMMANDS
INTERVALS     ::= INTERVAL[;INTERVALS]
46.18.2 Examples
Specify audio tempo change at second 4:
asendcmd=c='4.0 atempo tempo 1.5',atempo
Target a specific filter instance:
asendcmd=c='4.0 atempo@my tempo 1.5',atempo@my
Specify a list of drawtext and hue commands in a file.
# show text in the interval 5-10
5.0-10.0 [enter] drawtext reinit 'fontfile=FreeSerif.ttf:text=hello world',
[leave] drawtext reinit 'fontfile=FreeSerif.ttf:text=';
# desaturate the image in the interval 15-20
15.0-20.0 [enter] hue s 0,
[enter] drawtext reinit 'fontfile=FreeSerif.ttf:text=nocolor',
[leave] hue s 1,
[leave] drawtext reinit 'fontfile=FreeSerif.ttf:text=color';
# apply an exponential saturation fade-out effect, starting from time 25
25 [enter] hue s exp(25-t)
A filtergraph allowing to read and process the above command list
stored in a file test.cmd, can be specified with:
sendcmd=f=test.cmd,drawtext=fontfile=FreeSerif.ttf:text='',hue
46.19 setpts, asetpts
Change the PTS (presentation timestamp) of the input frames.
setpts works on video frames, asetpts on audio frames.
This filter accepts the following options:
expr
The expression which is evaluated for each frame to construct its timestamp.
The expression is evaluated through the eval API and can contain the following
constants:
FRAME_RATE, FR
frame rate, only defined for constant frame-rate video
PTS
The presentation timestamp in input
N
The count of the input frame for video or the number of consumed samples,
not including the current frame for audio, starting from 0.
NB_CONSUMED_SAMPLES
The number of consumed samples, not including the current frame (only
audio)
NB_SAMPLES, S
The number of samples in the current frame (only audio)
SAMPLE_RATE, SR
The audio sample rate.
STARTPTS
The PTS of the first frame.
STARTT
the time in seconds of the first frame
INTERLACED
State whether the current frame is interlaced.
T
the time in seconds of the current frame
POS
original position in the file of the frame, or undefined if undefined
for the current frame; deprecated, do not use
PREV_INPTS
The previous input PTS.
PREV_INT
previous input time in seconds
PREV_OUTPTS
The previous output PTS.
PREV_OUTT
previous output time in seconds
RTCTIME
The wallclock (RTC) time in microseconds. This is deprecated, use time(0)
instead.
RTCSTART
The wallclock (RTC) time at the start of the movie in microseconds.
TB
The timebase of the input timestamps.
T_CHANGE
Time of the first frame after command was applied or time of the first frame if no commands.
46.19.1 Examples
Start counting PTS from zero
setpts=PTS-STARTPTS
Apply fast motion effect:
setpts=0.5*PTS
Apply slow motion effect:
setpts=2.0*PTS
Set fixed rate of 25 frames per second:
setpts=N/(25*TB)
Apply a random jitter effect of +/-100 TB units:
setpts=PTS+randomi(0, -100\,100)
Set fixed rate 25 fps with some jitter:
setpts='1/(25*TB) * (N + 0.05 * sin(N*2*PI/25))'
Apply an offset of 10 seconds to the input PTS:
setpts=PTS+10/TB
Generate timestamps from a "live source" and rebase onto the current timebase:
setpts='(RTCTIME - RTCSTART) / (TB * 1000000)'
Generate timestamps by counting samples:
asetpts=N/SR/TB
46.19.2 Commands
Both filters support all above options as commands.
46.20 setrange
Force color range for the output video frame.
The setrange filter marks the color range property for the
output frames. It does not change the input frame, but only sets the
corresponding property, which affects how the frame is treated by
following filters.
The filter accepts the following options:
range
Available values are:
‘auto’
Keep the same color range property.
‘unspecified, unknown’
Set the color range as unspecified.
‘limited, tv, mpeg’
Set the color range as limited.
‘full, pc, jpeg’
Set the color range as full.
46.21 settb, asettb
Set the timebase to use for the output frames timestamps.
It is mainly useful for testing timebase configuration.
It accepts the following parameters:
expr, tb
The expression which is evaluated into the output timebase.
The value for tb is an arithmetic expression representing a
rational. The expression can contain the constants "AVTB" (the default
timebase), "intb" (the input timebase) and "sr" (the sample rate,
audio only). Default value is "intb".
46.21.1 Examples
Set the timebase to 1/25:
settb=expr=1/25
Set the timebase to 1/10:
settb=expr=0.1
Set the timebase to 1001/1000:
settb=1+0.001
Set the timebase to 2*intb:
settb=2*intb
Set the default timebase value:
settb=AVTB
46.22 showcqt
Convert input audio to a video output representing frequency spectrum
logarithmically using Brown-Puckette constant Q transform algorithm with
direct frequency domain coefficient calculation (but the transform itself
is not really constant Q, instead the Q factor is actually variable/clamped),
with musical tone scale, from E0 to D#10.
The filter accepts the following options:
size, s
Specify the video size for the output. It must be even. For the syntax of this option,
check the (ffmpeg-utils)"Video size" section in the ffmpeg-utils manual.
Default value is 1920x1080.
fps, rate, r
Set the output frame rate. Default value is 25.
bar_h
Set the bargraph height. It must be even. Default value is -1 which
computes the bargraph height automatically.
axis_h
Set the axis height. It must be even. Default value is -1 which computes
the axis height automatically.
sono_h
Set the sonogram height. It must be even. Default value is -1 which
computes the sonogram height automatically.
fullhd
Set the fullhd resolution. This option is deprecated, use size, s
instead. Default value is 1.
sono_v, volume
Specify the sonogram volume expression. It can contain variables:
bar_v
the bar_v evaluated expression
frequency, freq, f
the frequency where it is evaluated
timeclamp, tc
the value of timeclamp option
and functions:
a_weighting(f)
A-weighting of equal loudness
b_weighting(f)
B-weighting of equal loudness
c_weighting(f)
C-weighting of equal loudness.
Default value is 16.
bar_v, volume2
Specify the bargraph volume expression. It can contain variables:
sono_v
the sono_v evaluated expression
frequency, freq, f
the frequency where it is evaluated
timeclamp, tc
the value of timeclamp option
and functions:
a_weighting(f)
A-weighting of equal loudness
b_weighting(f)
B-weighting of equal loudness
c_weighting(f)
C-weighting of equal loudness.
Default value is sono_v.
sono_g, gamma
Specify the sonogram gamma. Lower gamma makes the spectrum more contrast,
higher gamma makes the spectrum having more range. Default value is 3.
Acceptable range is [1, 7].
bar_g, gamma2
Specify the bargraph gamma. Default value is 1. Acceptable range is
[1, 7].
bar_t
Specify the bargraph transparency level. Lower value makes the bargraph sharper.
Default value is 1. Acceptable range is [0, 1].
timeclamp, tc
Specify the transform timeclamp. At low frequency, there is trade-off between
accuracy in time domain and frequency domain. If timeclamp is lower,
event in time domain is represented more accurately (such as fast bass drum),
otherwise event in frequency domain is represented more accurately
(such as bass guitar). Acceptable range is [0.002, 1]. Default value is 0.17.
attack
Set attack time in seconds. The default is 0 (disabled). Otherwise, it
limits future samples by applying asymmetric windowing in time domain, useful
when low latency is required. Accepted range is [0, 1].
basefreq
Specify the transform base frequency. Default value is 20.01523126408007475,
which is frequency 50 cents below E0. Acceptable range is [10, 100000].
endfreq
Specify the transform end frequency. Default value is 20495.59681441799654,
which is frequency 50 cents above D#10. Acceptable range is [10, 100000].
coeffclamp
This option is deprecated and ignored.
tlength
Specify the transform length in time domain. Use this option to control accuracy
trade-off between time domain and frequency domain at every frequency sample.
It can contain variables:
frequency, freq, f
the frequency where it is evaluated
timeclamp, tc
the value of timeclamp option.
Default value is 384*tc/(384+tc*f).
count
Specify the transform count for every video frame. Default value is 6.
Acceptable range is [1, 30].
fcount
Specify the transform count for every single pixel. Default value is 0,
which makes it computed automatically. Acceptable range is [0, 10].
fontfile
Specify font file for use with freetype to draw the axis. If not specified,
use embedded font. Note that drawing with font file or embedded font is not
implemented with custom basefreq and endfreq, use axisfile
option instead.
font
Specify fontconfig pattern. This has lower priority than fontfile. The
: in the pattern may be replaced by | to avoid unnecessary
escaping.
fontcolor
Specify font color expression. This is arithmetic expression that should return
integer value 0xRRGGBB. It can contain variables:
frequency, freq, f
the frequency where it is evaluated
timeclamp, tc
the value of timeclamp option
and functions:
midi(f)
midi number of frequency f, some midi numbers: E0(16), C1(24), C2(36), A4(69)
r(x), g(x), b(x)
red, green, and blue value of intensity x.
Default value is st(0, (midi(f)-59.5)/12);
st(1, if(between(ld(0),0,1), 0.5-0.5*cos(2*PI*ld(0)), 0));
r(1-ld(1)) + b(ld(1)).
axisfile
Specify image file to draw the axis. This option override fontfile and
fontcolor option.
axis, text
Enable/disable drawing text to the axis. If it is set to 0, drawing to
the axis is disabled, ignoring fontfile and axisfile option.
Default value is 1.
csp
Set colorspace. The accepted values are:
‘unspecified’
Unspecified (default)
‘bt709’
BT.709
‘fcc’
FCC
‘bt470bg’
BT.470BG or BT.601-6 625
‘smpte170m’
SMPTE-170M or BT.601-6 525
‘smpte240m’
SMPTE-240M
‘bt2020ncl’
BT.2020 with non-constant luminance
cscheme
Set spectrogram color scheme. This is list of floating point values with format
left_r|left_g|left_b|right_r|right_g|right_b.
The default is 1|0.5|0|0|0.5|1.
46.22.1 Examples
Playing audio while showing the spectrum:
ffplay -f lavfi 'amovie=a.mp3, asplit [a][out1]; [a] showcqt [out0]'
Same as above, but with frame rate 30 fps:
ffplay -f lavfi 'amovie=a.mp3, asplit [a][out1]; [a] showcqt=fps=30:count=5 [out0]'
Playing at 1280x720:
ffplay -f lavfi 'amovie=a.mp3, asplit [a][out1]; [a] showcqt=s=1280x720:count=4 [out0]'
Disable sonogram display:
sono_h=0
A1 and its harmonics: A1, A2, (near)E3, A3:
ffplay -f lavfi 'aevalsrc=0.1*sin(2*PI*55*t)+0.1*sin(4*PI*55*t)+0.1*sin(6*PI*55*t)+0.1*sin(8*PI*55*t),
asplit[a][out1]; [a] showcqt [out0]'
Same as above, but with more accuracy in frequency domain:
ffplay -f lavfi 'aevalsrc=0.1*sin(2*PI*55*t)+0.1*sin(4*PI*55*t)+0.1*sin(6*PI*55*t)+0.1*sin(8*PI*55*t),
asplit[a][out1]; [a] showcqt=timeclamp=0.5 [out0]'
Custom volume:
bar_v=10:sono_v=bar_v*a_weighting(f)
Custom gamma, now spectrum is linear to the amplitude.
bar_g=2:sono_g=2
Custom tlength equation:
tc=0.33:tlength='st(0,0.17); 384*tc / (384 / ld(0) + tc*f /(1-ld(0))) + 384*tc / (tc*f / ld(0) + 384 /(1-ld(0)))'
Custom fontcolor and fontfile, C-note is colored green, others are colored blue:
fontcolor='if(mod(floor(midi(f)+0.5),12), 0x0000FF, g(1))':fontfile=myfont.ttf
Custom font using fontconfig:
font='Courier New,Monospace,mono|bold'
Custom frequency range with custom axis using image file:
axisfile=myaxis.png:basefreq=40:endfreq=10000
46.23 showcwt
Convert input audio to video output representing frequency spectrum
using Continuous Wavelet Transform and Morlet wavelet.
The filter accepts the following options:
size, s
Specify the video size for the output. For the syntax of this option,
check the (ffmpeg-utils)"Video size" section in the ffmpeg-utils manual.
Default value is 640x512.
rate, r
Set the output frame rate. Default value is 25.
scale
Set the frequency scale used. Allowed values are:
linear
log
bark
mel
erbs
sqrt
cbrt
qdrt
fm
Default value is linear.
iscale
Set the intensity scale used. Allowed values are:
linear
log
sqrt
cbrt
qdrt
Default value is log.
min
Set the minimum frequency that will be used in output.
Default is 20 Hz.
max
Set the maximum frequency that will be used in output.
Default is 20000 Hz. The real frequency upper limit
depends on input audio’s sample rate and such will be enforced
on this value when it is set to value greater than Nyquist frequency.
imin
Set the minimum intensity that will be used in output.
imax
Set the maximum intensity that will be used in output.
logb
Set the logarithmic basis for brightness strength when
mapping calculated magnitude values to pixel values.
Allowed range is from 0 to 1.
Default value is 0.0001.
deviation
Set the frequency deviation.
Lower values than 1 are more frequency oriented,
while higher values than 1 are more time oriented.
Allowed range is from 0 to 10.
Default value is 1.
pps
Set the number of pixel output per each second in one row.
Allowed range is from 1 to 1024.
Default value is 64.
mode
Set the output visual mode. Allowed values are:
magnitude
Show magnitude.
phase
Show only phase.
magphase
Show combination of magnitude and phase.
Magnitude is mapped to brightness and phase to color.
channel
Show unique color per channel magnitude.
stereo
Show unique color per stereo difference.
Default value is magnitude.
slide
Set the output slide method. Allowed values are:
replace
scroll
frame
direction
Set the direction method for output slide method. Allowed values are:
lr
Direction from left to right.
rl
Direction from right to left.
ud
Direction from up to down.
du
Direction from down to up.
bar
Set the ratio of bargraph display to display size. Default is 0.
rotation
Set color rotation, must be in [-1.0, 1.0] range.
Default value is 0.
46.24 showfreqs
Convert input audio to video output representing the audio power spectrum.
Audio amplitude is on Y-axis while frequency is on X-axis.
The filter accepts the following options:
size, s
Specify size of video. For the syntax of this option, check the
(ffmpeg-utils)"Video size" section in the ffmpeg-utils manual.
Default is 1024x512.
rate, r
Set video rate. Default is 25.
mode
Set display mode.
This set how each frequency bin will be represented.
It accepts the following values:
‘line’
‘bar’
‘dot’
Default is bar.
ascale
Set amplitude scale.
It accepts the following values:
‘lin’
Linear scale.
‘sqrt’
Square root scale.
‘cbrt’
Cubic root scale.
‘log’
Logarithmic scale.
Default is log.
fscale
Set frequency scale.
It accepts the following values:
‘lin’
Linear scale.
‘log’
Logarithmic scale.
‘rlog’
Reverse logarithmic scale.
Default is lin.
win_size
Set window size. Allowed range is from 16 to 65536.
Default is 2048
win_func
Set windowing function.
It accepts the following values:
‘rect’
‘bartlett’
‘hanning’
‘hamming’
‘blackman’
‘welch’
‘flattop’
‘bharris’
‘bnuttall’
‘bhann’
‘sine’
‘nuttall’
‘lanczos’
‘gauss’
‘tukey’
‘dolph’
‘cauchy’
‘parzen’
‘poisson’
‘bohman’
‘kaiser’
Default is hanning.
overlap
Set window overlap. In range [0, 1]. Default is 1,
which means optimal overlap for selected window function will be picked.
averaging
Set time averaging. Setting this to 0 will display current maximal peaks.
Default is 1, which means time averaging is disabled.
colors
Specify list of colors separated by space or by ’|’ which will be used to
draw channel frequencies. Unrecognized or missing colors will be replaced
by white color.
cmode
Set channel display mode.
It accepts the following values:
‘combined’
‘separate’
Default is combined.
minamp
Set minimum amplitude used in log amplitude scaler.
data
Set data display mode.
It accepts the following values:
‘magnitude’
‘phase’
‘delay’
Default is magnitude.
channels
Set channels to use when processing audio. By default all are processed.
46.25 showspatial
Convert stereo input audio to a video output, representing the spatial relationship
between two channels.
The filter accepts the following options:
size, s
Specify the video size for the output. For the syntax of this option, check the
(ffmpeg-utils)"Video size" section in the ffmpeg-utils manual.
Default value is 512x512.
win_size
Set window size. Allowed range is from 1024 to 65536. Default size is 4096.
win_func
Set window function.
It accepts the following values:
‘rect’
‘bartlett’
‘hann’
‘hanning’
‘hamming’
‘blackman’
‘welch’
‘flattop’
‘bharris’
‘bnuttall’
‘bhann’
‘sine’
‘nuttall’
‘lanczos’
‘gauss’
‘tukey’
‘dolph’
‘cauchy’
‘parzen’
‘poisson’
‘bohman’
‘kaiser’
Default value is hann.
rate, r
Set output framerate.
46.26 showspectrum
Convert input audio to a video output, representing the audio frequency
spectrum.
The filter accepts the following options:
size, s
Specify the video size for the output. For the syntax of this option, check the
(ffmpeg-utils)"Video size" section in the ffmpeg-utils manual.
Default value is 640x512.
slide
Specify how the spectrum should slide along the window.
It accepts the following values:
‘replace’
the samples start again on the left when they reach the right
‘scroll’
the samples scroll from right to left
‘fullframe’
frames are only produced when the samples reach the right
‘rscroll’
the samples scroll from left to right
‘lreplace’
the samples start again on the right when they reach the left
Default value is replace.
mode
Specify display mode.
It accepts the following values:
‘combined’
all channels are displayed in the same row
‘separate’
all channels are displayed in separate rows
Default value is ‘combined’.
color
Specify display color mode.
It accepts the following values:
‘channel’
each channel is displayed in a separate color
‘intensity’
each channel is displayed using the same color scheme
‘rainbow’
each channel is displayed using the rainbow color scheme
‘moreland’
each channel is displayed using the moreland color scheme
‘nebulae’
each channel is displayed using the nebulae color scheme
‘fire’
each channel is displayed using the fire color scheme
‘fiery’
each channel is displayed using the fiery color scheme
‘fruit’
each channel is displayed using the fruit color scheme
‘cool’
each channel is displayed using the cool color scheme
‘magma’
each channel is displayed using the magma color scheme
‘green’
each channel is displayed using the green color scheme
‘viridis’
each channel is displayed using the viridis color scheme
‘plasma’
each channel is displayed using the plasma color scheme
‘cividis’
each channel is displayed using the cividis color scheme
‘terrain’
each channel is displayed using the terrain color scheme
Default value is ‘channel’.
scale
Specify scale used for calculating intensity color values.
It accepts the following values:
‘lin’
linear
‘sqrt’
square root, default
‘cbrt’
cubic root
‘log’
logarithmic
‘4thrt’
4th root
‘5thrt’
5th root
Default value is ‘sqrt’.
fscale
Specify frequency scale.
It accepts the following values:
‘lin’
linear
‘log’
logarithmic
Default value is ‘lin’.
saturation
Set saturation modifier for displayed colors. Negative values provide
alternative color scheme. 0 is no saturation at all.
Saturation must be in [-10.0, 10.0] range.
Default value is 1.
win_func
Set window function.
It accepts the following values:
‘rect’
‘bartlett’
‘hann’
‘hanning’
‘hamming’
‘blackman’
‘welch’
‘flattop’
‘bharris’
‘bnuttall’
‘bhann’
‘sine’
‘nuttall’
‘lanczos’
‘gauss’
‘tukey’
‘dolph’
‘cauchy’
‘parzen’
‘poisson’
‘bohman’
‘kaiser’
Default value is hann.
orientation
Set orientation of time vs frequency axis. Can be vertical or
horizontal. Default is vertical.
overlap
Set ratio of overlap window. Default value is 0.
When value is 1 overlap is set to recommended size for specific
window function currently used.
gain
Set scale gain for calculating intensity color values.
Default value is 1.
data
Set which data to display. Can be magnitude, default or phase,
or unwrapped phase: uphase.
rotation
Set color rotation, must be in [-1.0, 1.0] range.
Default value is 0.
start
Set start frequency from which to display spectrogram. Default is 0.
stop
Set stop frequency to which to display spectrogram. Default is 0.
fps
Set upper frame rate limit. Default is auto, unlimited.
legend
Draw time and frequency axes and legends. Default is disabled.
drange
Set dynamic range used to calculate intensity color values. Default is 120 dBFS.
Allowed range is from 10 to 200.
limit
Set upper limit of input audio samples volume in dBFS. Default is 0 dBFS.
Allowed range is from -100 to 100.
opacity
Set opacity strength when using pixel format output with alpha component.
The usage is very similar to the showwaves filter; see the examples in that
section.
46.26.1 Examples
Large window with logarithmic color scaling:
showspectrum=s=1280x480:scale=log
Complete example for a colored and sliding spectrum per channel using ffplay:
ffplay -f lavfi 'amovie=input.mp3, asplit [a][out1];
[a] showspectrum=mode=separate:color=intensity:slide=1:scale=cbrt [out0]'
46.27 showspectrumpic
Convert input audio to a single video frame, representing the audio frequency
spectrum.
The filter accepts the following options:
size, s
Specify the video size for the output. For the syntax of this option, check the
(ffmpeg-utils)"Video size" section in the ffmpeg-utils manual.
Default value is 4096x2048.
mode
Specify display mode.
It accepts the following values:
‘combined’
all channels are displayed in the same row
‘separate’
all channels are displayed in separate rows
Default value is ‘combined’.
color
Specify display color mode.
It accepts the following values:
‘channel’
each channel is displayed in a separate color
‘intensity’
each channel is displayed using the same color scheme
‘rainbow’
each channel is displayed using the rainbow color scheme
‘moreland’
each channel is displayed using the moreland color scheme
‘nebulae’
each channel is displayed using the nebulae color scheme
‘fire’
each channel is displayed using the fire color scheme
‘fiery’
each channel is displayed using the fiery color scheme
‘fruit’
each channel is displayed using the fruit color scheme
‘cool’
each channel is displayed using the cool color scheme
‘magma’
each channel is displayed using the magma color scheme
‘green’
each channel is displayed using the green color scheme
‘viridis’
each channel is displayed using the viridis color scheme
‘plasma’
each channel is displayed using the plasma color scheme
‘cividis’
each channel is displayed using the cividis color scheme
‘terrain’
each channel is displayed using the terrain color scheme
Default value is ‘intensity’.
scale
Specify scale used for calculating intensity color values.
It accepts the following values:
‘lin’
linear
‘sqrt’
square root, default
‘cbrt’
cubic root
‘log’
logarithmic
‘4thrt’
4th root
‘5thrt’
5th root
Default value is ‘log’.
fscale
Specify frequency scale.
It accepts the following values:
‘lin’
linear
‘log’
logarithmic
Default value is ‘lin’.
saturation
Set saturation modifier for displayed colors. Negative values provide
alternative color scheme. 0 is no saturation at all.
Saturation must be in [-10.0, 10.0] range.
Default value is 1.
win_func
Set window function.
It accepts the following values:
‘rect’
‘bartlett’
‘hann’
‘hanning’
‘hamming’
‘blackman’
‘welch’
‘flattop’
‘bharris’
‘bnuttall’
‘bhann’
‘sine’
‘nuttall’
‘lanczos’
‘gauss’
‘tukey’
‘dolph’
‘cauchy’
‘parzen’
‘poisson’
‘bohman’
‘kaiser’
Default value is hann.
orientation
Set orientation of time vs frequency axis. Can be vertical or
horizontal. Default is vertical.
gain
Set scale gain for calculating intensity color values.
Default value is 1.
legend
Draw time and frequency axes and legends. Default is enabled.
rotation
Set color rotation, must be in [-1.0, 1.0] range.
Default value is 0.
start
Set start frequency from which to display spectrogram. Default is 0.
stop
Set stop frequency to which to display spectrogram. Default is 0.
drange
Set dynamic range used to calculate intensity color values. Default is 120 dBFS.
Allowed range is from 10 to 200.
limit
Set upper limit of input audio samples volume in dBFS. Default is 0 dBFS.
Allowed range is from -100 to 100.
opacity
Set opacity strength when using pixel format output with alpha component.
46.27.1 Examples
Extract an audio spectrogram of a whole audio track
in a 1024x1024 picture using ffmpeg:
ffmpeg -i audio.flac -lavfi showspectrumpic=s=1024x1024 spectrogram.png
46.28 showvolume
Convert input audio volume to a video output.
The filter accepts the following options:
rate, r
Set video rate.
b
Set border width, allowed range is [0, 5]. Default is 1.
w
Set channel width, allowed range is [80, 8192]. Default is 400.
h
Set channel height, allowed range is [1, 900]. Default is 20.
f
Set fade, allowed range is [0, 1]. Default is 0.95.
c
Set volume color expression.
The expression can use the following variables:
VOLUME
Current max volume of channel in dB.
PEAK
Current peak.
CHANNEL
Current channel number, starting from 0.
t
If set, displays channel names. Default is enabled.
v
If set, displays volume values. Default is enabled.
o
Set orientation, can be horizontal: h or vertical: v,
default is h.
s
Set step size, allowed range is [0, 5]. Default is 0, which means
step is disabled.
p
Set background opacity, allowed range is [0, 1]. Default is 0.
m
Set metering mode, can be peak: p or rms: r,
default is p.
ds
Set display scale, can be linear: lin or log: log,
default is lin.
dm
In second.
If set to > 0., display a line for the max level
in the previous seconds.
default is disabled: 0.
dmc
The color of the max line. Use when dm option is set to > 0.
default is: orange
46.29 showwaves
Convert input audio to a video output, representing the samples waves.
The filter accepts the following options:
size, s
Specify the video size for the output. For the syntax of this option, check the
(ffmpeg-utils)"Video size" section in the ffmpeg-utils manual.
Default value is 600x240.
mode
Set display mode.
Available values are:
‘point’
Draw a point for each sample.
‘line’
Draw a vertical line for each sample.
‘p2p’
Draw a point for each sample and a line between them.
‘cline’
Draw a centered vertical line for each sample.
Default value is point.
n
Set the number of samples which are printed on the same column. A
larger value will decrease the frame rate. Must be a positive
integer. This option can be set only if the value for rate
is not explicitly specified.
rate, r
Set the (approximate) output frame rate. This is done by setting the
option n. Default value is "25".
split_channels
Set if channels should be drawn separately or overlap. Default value is 0.
colors
Set colors separated by ’|’ which are going to be used for drawing of each channel.
scale
Set amplitude scale.
Available values are:
‘lin’
Linear.
‘log’
Logarithmic.
‘sqrt’
Square root.
‘cbrt’
Cubic root.
Default is linear.
draw
Set the draw mode. This is mostly useful to set for high n.
Available values are:
‘scale’
Scale pixel values for each drawn sample.
‘full’
Draw every sample directly.
Default value is scale.
46.29.1 Examples
Output the input file audio and the corresponding video representation
at the same time:
amovie=a.mp3,asplit[out0],showwaves[out1]
Create a synthetic signal and show it with showwaves, forcing a
frame rate of 30 frames per second:
aevalsrc=sin(1*2*PI*t)*sin(880*2*PI*t):cos(2*PI*200*t),asplit[out0],showwaves=r=30[out1]
46.30 showwavespic
Convert input audio to a single video frame, representing the samples waves.
The filter accepts the following options:
size, s
Specify the video size for the output. For the syntax of this option, check the
(ffmpeg-utils)"Video size" section in the ffmpeg-utils manual.
Default value is 600x240.
split_channels
Set if channels should be drawn separately or overlap. Default value is 0.
colors
Set colors separated by ’|’ which are going to be used for drawing of each channel.
scale
Set amplitude scale.
Available values are:
‘lin’
Linear.
‘log’
Logarithmic.
‘sqrt’
Square root.
‘cbrt’
Cubic root.
Default is linear.
draw
Set the draw mode.
Available values are:
‘scale’
Scale pixel values for each drawn sample.
‘full’
Draw every sample directly.
Default value is scale.
filter
Set the filter mode.
Available values are:
‘average’
Use average samples values for each drawn sample.
‘peak’
Use peak samples values for each drawn sample.
Default value is average.
46.30.1 Examples
Extract a channel split representation of the wave form of a whole audio track
in a 1024x800 picture using ffmpeg:
ffmpeg -i audio.flac -lavfi showwavespic=split_channels=1:s=1024x800 waveform.png
46.31 sidedata, asidedata
Delete frame side data, or select frames based on it.
This filter accepts the following options:
mode
Set mode of operation of the filter.
Can be one of the following:
‘select’
Select every frame with side data of type.
‘delete’
Delete side data of type. If type is not set, delete all side
data in the frame.
type
Set side data type used with all modes. Must be set for select mode. For
the list of frame side data types, refer to the AVFrameSideDataType enum
in libavutil/frame.h. For example, to choose
AV_FRAME_DATA_PANSCAN side data, you must specify PANSCAN.
46.32 spectrumsynth
Synthesize audio from 2 input video spectrums, first input stream represents
magnitude across time and second represents phase across time.
The filter will transform from frequency domain as displayed in videos back
to time domain as presented in audio output.
This filter is primarily created for reversing processed showspectrum
filter outputs, but can synthesize sound from other spectrograms too.
But in such case results are going to be poor if the phase data is not
available, because in such cases phase data need to be recreated, usually
it’s just recreated from random noise.
For best results use gray only output (channel color mode in
showspectrum filter) and log scale for magnitude video and
lin scale for phase video. To produce phase, for 2nd video, use
data option. Inputs videos should generally use fullframe
slide mode as that saves resources needed for decoding video.
The filter accepts the following options:
sample_rate
Specify sample rate of output audio, the sample rate of audio from which
spectrum was generated may differ.
channels
Set number of channels represented in input video spectrums.
scale
Set scale which was used when generating magnitude input spectrum.
Can be lin or log. Default is log.
slide
Set slide which was used when generating inputs spectrums.
Can be replace, scroll, fullframe or rscroll.
Default is fullframe.
win_func
Set window function used for resynthesis.
overlap
Set window overlap. In range [0, 1]. Default is 1,
which means optimal overlap for selected window function will be picked.
orientation
Set orientation of input videos. Can be vertical or horizontal.
Default is vertical.
46.32.1 Examples
First create magnitude and phase videos from audio, assuming audio is stereo with 44100 sample rate,
then resynthesize videos back to audio with spectrumsynth:
ffmpeg -i input.flac -lavfi showspectrum=mode=separate:scale=log:overlap=0.875:color=channel:slide=fullframe:data=magnitude -an -c:v rawvideo magnitude.nut
ffmpeg -i input.flac -lavfi showspectrum=mode=separate:scale=lin:overlap=0.875:color=channel:slide=fullframe:data=phase -an -c:v rawvideo phase.nut
ffmpeg -i magnitude.nut -i phase.nut -lavfi spectrumsynth=channels=2:sample_rate=44100:win_func=hann:overlap=0.875:slide=fullframe output.flac
46.33 split, asplit
Split input into several identical outputs.
asplit works with audio input, split with video.
The filter accepts a single parameter which specifies the number of outputs. If
unspecified, it defaults to 2.
46.33.1 Examples
Create two separate outputs from the same input:
[in] split [out0][out1]
To create 3 or more outputs, you need to specify the number of
outputs, like in:
[in] asplit=3 [out0][out1][out2]
Create two separate outputs from the same input, one cropped and
one padded:
[in] split [splitout1][splitout2];
[splitout1] crop=100:100:0:0    [cropout];
[splitout2] pad=200:200:100:100 [padout];
Create 5 copies of the input audio with ffmpeg:
ffmpeg -i INPUT -filter_complex asplit=5 OUTPUT
46.34 zmq, azmq
Receive commands sent through a libzmq client, and forward them to
filters in the filtergraph.
zmq and azmq work as a pass-through filters. zmq
must be inserted between two video filters, azmq between two
audio filters. Both are capable to send messages to any filter type.
To enable these filters you need to install the libzmq library and
headers and configure FFmpeg with --enable-libzmq.
For more information about libzmq see:
http://www.zeromq.org/
The zmq and azmq filters work as a libzmq server, which
receives messages sent through a network interface defined by the
bind_address (or the abbreviation "b") option.
Default value of this option is tcp://localhost:5555. You may
want to alter this value to your needs, but do not forget to escape any
’:’ signs (see filtergraph escaping).
The received message must be in the form:
TARGET COMMAND [ARG]
TARGET specifies the target of the command, usually the name of
the filter class or a specific filter instance name. The default
filter instance name uses the pattern ‘Parsed_<filter_name>_<index>’,
but you can override this by using the ‘filter_name@id’ syntax
(see Filtergraph syntax).
COMMAND specifies the name of the command for the target filter.
ARG is optional and specifies the optional argument list for the
given COMMAND.
Upon reception, the message is processed and the corresponding command
is injected into the filtergraph. Depending on the result, the filter
will send a reply to the client, adopting the format:
ERROR_CODE ERROR_REASON
MESSAGE
MESSAGE is optional.
46.34.1 Examples
Look at tools/zmqsend for an example of a zmq client which can
be used to send commands processed by these filters.
Consider the following filtergraph generated by ffplay.
In this example the last overlay filter has an instance name. All other
filters will have default instance names.
ffplay -dumpgraph 1 -f lavfi "
color=s=100x100:c=red  [l];
color=s=100x100:c=blue [r];
nullsrc=s=200x100, zmq [bg];
[bg][l]   overlay     [bg+l];
[bg+l][r] overlay@my=x=100 "
To change the color of the left side of the video, the following
command can be used:
echo Parsed_color_0 c yellow | tools/zmqsend
To change the right side:
echo Parsed_color_1 c pink | tools/zmqsend
To change the position of the right side:
echo overlay@my x 150 | tools/zmqsend
47 Multimedia Sources
Below is a description of the currently available multimedia sources.
47.1 amovie
This is the same as movie source, except it selects an audio
stream by default.
47.2 avsynctest
Generate an Audio/Video Sync Test.
Generated stream periodically shows flash video frame and emits beep in audio.
Useful to inspect A/V sync issues.
It accepts the following options:
size, s
Set output video size. Default value is hd720.
framerate, fr
Set output video frame rate. Default value is 30.
samplerate, sr
Set output audio sample rate. Default value is 44100.
amplitude, a
Set output audio beep amplitude. Default value is 0.7.
period, p
Set output audio beep period in seconds. Default value is 3.
delay, dl
Set output video flash delay in number of frames. Default value is 0.
cycle, c
Enable cycling of video delays, by default is disabled.
duration, d
Set stream output duration. By default duration is unlimited.
fg, bg, ag
Set foreground/background/additional color.
47.2.1 Commands
This source supports the some above options as commands.
47.3 movie
Read audio and/or video stream(s) from a movie container.
It accepts the following parameters:
filename
The name of the resource to read (not necessarily a file; it can also be a
device or a stream accessed through some protocol).
format_name, f
Specifies the format assumed for the movie to read, and can be either
the name of a container or an input device. If not specified, the
format is guessed from movie_name or by probing.
seek_point, sp
Specifies the seek point in seconds. The frames will be output
starting from this seek point. The parameter is evaluated with
av_strtod, so the numerical value may be suffixed by an IS
postfix. The default value is "0".
streams, s
Specifies the streams to read. Several streams can be specified,
separated by "+". The source will then have as many outputs, in the
same order. The syntax is explained in the (ffmpeg)"Stream specifiers"
section in the ffmpeg manual. Two special names, "dv" and "da" specify
respectively the default (best suited) video and audio stream. Default
is "dv", or "da" if the filter is called as "amovie".
stream_index, si
Specifies the index of the video stream to read. If the value is -1,
the most suitable video stream will be automatically selected. The default
value is "-1". Deprecated. If the filter is called "amovie", it will select
audio instead of video.
loop
Specifies how many times to read the stream in sequence.
If the value is 0, the stream will be looped infinitely.
Default value is "1".
Note that when the movie is looped the source timestamps are not
changed, so it will generate non monotonically increasing timestamps.
discontinuity
Specifies the time difference between frames above which the point is
considered a timestamp discontinuity which is removed by adjusting the later
timestamps.
dec_threads
Specifies the number of threads for decoding
format_opts
Specify format options for the opened file. Format options can be specified
as a list of key=value pairs separated by ’:’. The following example
shows how to add protocol_whitelist and protocol_blacklist options:
ffplay -f lavfi
"movie=filename='1.sdp':format_opts='protocol_whitelist=file,rtp,udp\:protocol_blacklist=http'"
It allows overlaying a second video on top of the main input of
a filtergraph, as shown in this graph:
input -----------> deltapts0 --> overlay --> output
^
|
movie --> scale--> deltapts1 -------+
47.3.1 Examples
Skip 3.2 seconds from the start of the AVI file in.avi, and overlay it
on top of the input labelled "in":
movie=in.avi:seek_point=3.2, scale=180:-1, setpts=PTS-STARTPTS [over];
[in] setpts=PTS-STARTPTS [main];
[main][over] overlay=16:16 [out]
Read from a video4linux2 device, and overlay it on top of the input
labelled "in":
movie=/dev/video0:f=video4linux2, scale=180:-1, setpts=PTS-STARTPTS [over];
[in] setpts=PTS-STARTPTS [main];
[main][over] overlay=16:16 [out]
Read the first video stream and the audio stream with id 0x81 from
dvd.vob; the video is connected to the pad named "video" and the audio is
connected to the pad named "audio":
movie=dvd.vob:s=v:0+#0x81 [video] [audio]
47.3.2 Commands
Both movie and amovie support the following commands:
seek
Perform seek using "av_seek_frame".
The syntax is: seek stream_index|timestamp|flags
stream_index: If stream_index is -1, a default
stream is selected, and timestamp is automatically converted
from AV_TIME_BASE units to the stream specific time_base.
timestamp: Timestamp in AVStream.time_base units
or, if no stream is specified, in AV_TIME_BASE units.
flags: Flags which select direction and seeking mode.
get_duration
Get movie duration in AV_TIME_BASE units.