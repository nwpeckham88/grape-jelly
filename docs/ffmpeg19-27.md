19 Format Options
19.1 Format stream specifiers
20 Demuxers
20.1 aa
20.2 aac
20.3 apng
20.4 asf
20.5 concat
20.5.1 Syntax
20.5.2 Options
20.5.3 Examples
20.6 dash
20.6.1 Options
20.7 dvdvideo
20.7.1 Background
20.7.2 Options
20.7.3 Examples
20.8 ea
20.8.1 Options
20.9 imf
20.10 flv, live_flv, kux
20.11 gif
20.12 hls
20.13 image2
20.13.1 Examples
20.14 libgme
20.15 libmodplug
20.16 libopenmpt
20.17 mov/mp4/3gp
20.17.1 Options
20.17.2 Audible AAX
20.18 mpegts
20.19 mpjpeg
20.20 rawvideo
20.21 rcwt
20.21.1 Examples
20.22 sbg
20.23 tedcaptions
20.24 vapoursynth
20.25 w64
20.26 wav
21 Muxers
21.1 Raw muxers
21.1.1 Examples
21.2 Raw PCM muxers
21.3 MPEG-1/MPEG-2 program stream muxers
21.3.1 Options
21.4 MOV/MPEG-4/ISOMBFF muxers
21.4.1 Fragmentation
21.4.2 Options
21.4.3 Examples
21.5 a64
21.6 ac4
21.6.1 Options
21.7 adts
21.7.1 Options
21.8 aea
21.9 aiff
21.9.1 Options
21.10 alp
21.10.1 Options
21.11 amr
21.12 amv
21.13 apm
21.14 apng
21.14.1 Options
21.14.2 Examples
21.15 argo_asf
21.15.1 Options
21.16 argo_cvg
21.16.1 Options
21.17 asf, asf_stream
21.17.1 Options
21.18 ass
21.18.1 Options
21.19 ast
21.19.1 Options
21.20 au
21.21 avi
21.21.1 Options
21.22 avif
21.22.1 Options
21.23 avm2
21.24 bit
21.25 caf
21.26 codec2
21.27 chromaprint
21.27.1 Options
21.28 crc
21.28.1 Examples
21.29 dash
21.29.1 Options
21.29.2 Example
21.30 daud
21.30.1 Example
21.31 dv
21.31.1 Example
21.32 ffmetadata
21.32.1 Example
21.33 fifo
21.33.1 Options
21.33.2 Example
21.34 film_cpk
21.35 filmstrip
21.36 fits
21.37 flac
21.37.1 Options
21.37.2 Example
21.38 flv
21.38.1 Options
21.39 framecrc
21.39.1 Examples
21.40 framehash
21.40.1 Examples
21.41 framemd5
21.41.1 Examples
21.42 gif
21.42.1 Options
21.42.2 Example
21.43 gxf
21.44 hash
21.44.1 Examples
21.45 hds
21.45.1 Options
21.45.2 Example
21.46 hls
21.46.1 Options
21.47 iamf
21.48 ico
21.49 ilbc
21.50 image2, image2pipe
21.50.1 Options
21.50.2 Examples
21.51 ircam
21.52 ivf
21.53 jacosub
21.54 kvag
21.55 lc3
21.56 lrc
21.56.1 Metadata
21.57 matroska
21.57.1 Metadata
21.57.2 Options
21.58 md5
21.58.1 Examples
21.59 microdvd
21.60 mmf
21.61 mp3
21.62 mpegts
21.62.1 Options
21.62.2 Example
21.63 mxf, mxf_d10, mxf_opatom
21.63.1 Options
21.64 null
21.65 nut
21.66 ogg
21.67 rcwt
21.67.1 Examples
21.68 segment, stream_segment, ssegment
21.68.1 Options
21.68.2 Examples
21.69 smoothstreaming
21.70 streamhash
21.70.1 Examples
21.71 tee
21.71.1 Options
21.71.2 Examples
21.72 webm_chunk
21.72.1 Options
21.72.2 Example
21.73 webm_dash_manifest
21.73.1 Options
21.73.2 Example
22 Metadata
23 Protocol Options
24 Protocols
24.1 amqp
24.2 async
24.3 bluray
24.4 cache
24.5 concat
24.6 concatf
24.7 crypto
24.8 data
24.9 fd
24.10 file
24.11 ftp
24.12 gopher
24.13 gophers
24.14 hls
24.15 http
24.15.1 HTTP Cookies
24.16 Icecast
24.17 ipfs
24.18 mmst
24.19 mmsh
24.20 md5
24.21 pipe
24.22 prompeg
24.23 rist
24.24 rtmp
24.25 rtmpe
24.26 rtmps
24.27 rtmpt
24.28 rtmpte
24.29 rtmpts
24.30 libsmbclient
24.31 libssh
24.32 librtmp rtmp, rtmpe, rtmps, rtmpt, rtmpte
24.33 rtp
24.34 rtsp
24.34.1 Muxer
24.34.2 Demuxer
24.34.3 Examples
24.35 sap
24.35.1 Muxer
24.35.2 Demuxer
24.36 sctp
24.37 srt
24.38 srtp
24.39 subfile
24.40 tee
24.41 tcp
24.42 tls
24.43 udp
24.43.1 Examples
24.44 unix
24.45 zmq
25 Device Options
26 Input Devices
26.1 alsa
26.1.1 Options
26.2 android_camera
26.2.1 Options
26.3 avfoundation
26.3.1 Options
26.3.2 Examples
26.4 bktr
26.4.1 Options
26.5 decklink
26.5.1 Options
26.5.2 Examples
26.6 dshow
26.6.1 Options
26.6.2 Examples
26.7 fbdev
26.7.1 Options
26.8 gdigrab
26.8.1 Options
26.9 iec61883
26.9.1 Options
26.9.2 Examples
26.10 jack
26.10.1 Options
26.11 kmsgrab
26.11.1 Options
26.11.2 Examples
26.12 lavfi
26.12.1 Options
26.12.2 Examples
26.13 libcdio
26.13.1 Options
26.14 libdc1394
26.14.1 Options
26.15 openal
26.15.1 Options
26.15.2 Examples
26.16 oss
26.16.1 Options
26.17 pulse
26.17.1 Options
26.17.2 Examples
26.18 sndio
26.18.1 Options
26.19 video4linux2, v4l2
26.19.1 Options
26.20 vfwcap
26.20.1 Options
26.21 x11grab
26.21.1 Options
27 Output Devices
27.1 alsa
27.1.1 Examples
27.2 AudioToolbox
27.2.1 Options
27.2.2 Examples
27.3 caca
27.3.1 Options
27.3.2 Examples
27.4 decklink
27.4.1 Options
27.4.2 Examples
27.5 fbdev
27.5.1 Options
27.5.2 Examples
27.6 opengl
27.6.1 Options
27.6.2 Examples
27.7 oss
27.8 pulse
27.8.1 Options
27.8.2 Examples
27.9 sdl
27.9.1 Options
27.9.2 Interactive commands
27.9.3 Examples
27.10 sndio
27.11 v4l2
27.12 xv
27.12.1 Options
27.12.2 Examples




19 Format Options
The libavformat library provides some generic global options, which
can be set on all the muxers and demuxers. In addition each muxer or
demuxer may support so-called private options, which are specific for
that component.
Options may be set by specifying -option value in the
FFmpeg tools, or by setting the value explicitly in the
AVFormatContext options or using the libavutil/opt.h API
for programmatic use.
The list of supported options follows:
avioflags flags (input/output)
Possible values:
‘direct’
Reduce buffering.
probesize integer (input)
Set probing size in bytes, i.e. the size of the data to analyze to get
stream information. A higher value will enable detecting more
information in case it is dispersed into the stream, but will increase
latency. Must be an integer not lesser than 32. It is 5000000 by default.
max_probe_packets integer (input)
Set the maximum number of buffered packets when probing a codec.
Default is 2500 packets.
packetsize integer (output)
Set packet size.
fflags flags
Set format flags. Some are implemented for a limited number of formats.
Possible values for input files:
‘discardcorrupt’
Discard corrupted packets.
‘fastseek’
Enable fast, but inaccurate seeks for some formats.
‘genpts’
Generate missing PTS if DTS is present.
‘igndts’
Ignore DTS if PTS is also set. In case the PTS is set, the DTS value
is set to NOPTS. This is ignored when the nofillin flag is set.
‘ignidx’
Ignore index.
‘nobuffer’
Reduce the latency introduced by buffering during initial input streams analysis.
‘nofillin’
Do not fill in missing values in packet fields that can be exactly calculated.
‘noparse’
Disable AVParsers, this needs +nofillin too.
‘sortdts’
Try to interleave output packets by DTS. At present, available only for AVIs with an index.
Possible values for output files:
‘autobsf’
Automatically apply bitstream filters as required by the output format. Enabled by default.
‘bitexact’
Only write platform-, build- and time-independent data.
This ensures that file and data checksums are reproducible and match between
platforms. Its primary use is for regression testing.
‘flush_packets’
Write out packets immediately.
‘shortest’
Stop muxing at the end of the shortest stream.
It may be needed to increase max_interleave_delta to avoid flushing the longer
streams before EOF.
seek2any integer (input)
Allow seeking to non-keyframes on demuxer level when supported if set to 1.
Default is 0.
analyzeduration integer (input)
Specify how many microseconds are analyzed to probe the input. A
higher value will enable detecting more accurate information, but will
increase latency. It defaults to 5,000,000 microseconds = 5 seconds.
cryptokey hexadecimal string (input)
Set decryption key.
indexmem integer (input)
Set max memory used for timestamp index (per stream).
rtbufsize integer (input)
Set max memory used for buffering real-time frames.
fdebug flags (input/output)
Print specific debug info.
Possible values:
‘ts’
max_delay integer (input/output)
Set maximum muxing or demuxing delay in microseconds.
fpsprobesize integer (input)
Set number of frames used to probe fps.
audio_preload integer (output)
Set microseconds by which audio packets should be interleaved earlier.
chunk_duration integer (output)
Set microseconds for each chunk.
chunk_size integer (output)
Set size in bytes for each chunk.
err_detect, f_err_detect flags (input)
Set error detection flags. f_err_detect is deprecated and
should be used only via the ffmpeg tool.
Possible values:
‘crccheck’
Verify embedded CRCs.
‘bitstream’
Detect bitstream specification deviations.
‘buffer’
Detect improper bitstream length.
‘explode’
Abort decoding on minor error detection.
‘careful’
Consider things that violate the spec and have not been seen in the
wild as errors.
‘compliant’
Consider all spec non compliancies as errors.
‘aggressive’
Consider things that a sane encoder should not do as an error.
max_interleave_delta integer (output)
Set maximum buffering duration for interleaving. The duration is
expressed in microseconds, and defaults to 10000000 (10 seconds).
To ensure all the streams are interleaved correctly, libavformat will
wait until it has at least one packet for each stream before actually
writing any packets to the output file. When some streams are
"sparse" (i.e. there are large gaps between successive packets), this
can result in excessive buffering.
This field specifies the maximum difference between the timestamps of the
first and the last packet in the muxing queue, above which libavformat
will output a packet regardless of whether it has queued a packet for all
the streams.
If set to 0, libavformat will continue buffering packets until it has
a packet for each stream, regardless of the maximum timestamp
difference between the buffered packets.
use_wallclock_as_timestamps integer (input)
Use wallclock as timestamps if set to 1. Default is 0.
avoid_negative_ts integer (output)
Possible values:
‘make_non_negative’
Shift timestamps to make them non-negative.
Also note that this affects only leading negative timestamps, and not
non-monotonic negative timestamps.
‘make_zero’
Shift timestamps so that the first timestamp is 0.
‘auto (default)’
Enables shifting when required by the target format.
‘disabled’
Disables shifting of timestamp.
When shifting is enabled, all output timestamps are shifted by the
same amount. Audio, video, and subtitles desynching and relative
timestamp differences are preserved compared to how they would have
been without shifting.
skip_initial_bytes integer (input)
Set number of bytes to skip before reading header and frames if set to 1.
Default is 0.
correct_ts_overflow integer (input)
Correct single timestamp overflows if set to 1. Default is 1.
flush_packets integer (output)
Flush the underlying I/O stream after each packet. Default is -1 (auto), which
means that the underlying protocol will decide, 1 enables it, and has the
effect of reducing the latency, 0 disables it and may increase IO throughput in
some cases.
output_ts_offset offset (output)
Set the output time offset.
offset must be a time duration specification,
see (ffmpeg-utils)the Time duration section in the ffmpeg-utils(1) manual.
The offset is added by the muxer to the output timestamps.
Specifying a positive offset means that the corresponding streams are
delayed bt the time duration specified in offset. Default value
is 0 (meaning that no offset is applied).
format_whitelist list (input)
"," separated list of allowed demuxers. By default all are allowed.
dump_separator string (input)
Separator used to separate the fields printed on the command line about the
Stream parameters.
For example, to separate the fields with newlines and indentation:
ffprobe -dump_separator "
"  -i ~/videos/matrixbench_mpeg2.mpg
max_streams integer (input)
Specifies the maximum number of streams. This can be used to reject files that
would require too many resources due to a large number of streams.
skip_estimate_duration_from_pts bool (input)
Skip estimation of input duration if it requires an additional probing for PTS at end of file.
At present, applicable for MPEG-PS and MPEG-TS.
duration_probesize integer (input)
Set probing size, in bytes, for input duration estimation when it actually requires
an additional probing for PTS at end of file (at present: MPEG-PS and MPEG-TS).
It is aimed at users interested in better durations probing for itself, or indirectly
because using the concat demuxer, for example.
The typical use case is an MPEG-TS CBR with a high bitrate, high video buffering and
ending cleaning with similar PTS for video and audio: in such a scenario, the large
physical gap between the last video packet and the last audio packet makes it necessary
to read many bytes in order to get the video stream duration.
Another use case is where the default probing behaviour only reaches a single video frame which is
not the last one of the stream due to frame reordering, so the duration is not accurate.
Setting this option has a performance impact even for small files because the probing
size is fixed.
Default behaviour is a general purpose trade-off, largely adaptive, but the probing size
will not be extended to get streams durations at all costs.
Must be an integer not lesser than 1, or 0 for default behaviour.
strict, f_strict integer (input/output)
Specify how strictly to follow the standards. f_strict is deprecated and
should be used only via the ffmpeg tool.
Possible values:
‘very’
strictly conform to an older more strict version of the spec or reference software
‘strict’
strictly conform to all the things in the spec no matter what consequences
‘normal’
‘unofficial’
allow unofficial extensions
‘experimental’
allow non standardized experimental things, experimental
(unfinished/work in progress/not well tested) decoders and encoders.
Note: experimental decoders can pose a security risk, do not use this for
decoding untrusted input.
19.1 Format stream specifiers
Format stream specifiers allow selection of one or more streams that
match specific properties.
The exact semantics of stream specifiers is defined by the
avformat_match_stream_specifier() function declared in the
libavformat/avformat.h header and documented in the
(ffmpeg)Stream specifiers section in the ffmpeg(1) manual.
20 Demuxers
Demuxers are configured elements in FFmpeg that can read the
multimedia streams from a particular type of file.
When you configure your FFmpeg build, all the supported demuxers
are enabled by default. You can list all available ones using the
configure option --list-demuxers.
You can disable all the demuxers using the configure option
--disable-demuxers, and selectively enable a single demuxer with
the option --enable-demuxer=DEMUXER, or disable it
with the option --disable-demuxer=DEMUXER.
The option -demuxers of the ff* tools will display the list of
enabled demuxers. Use -formats to view a combined list of
enabled demuxers and muxers.
The description of some of the currently available demuxers follows.
20.1 aa
Audible Format 2, 3, and 4 demuxer.
This demuxer is used to demux Audible Format 2, 3, and 4 (.aa) files.
20.2 aac
Raw Audio Data Transport Stream AAC demuxer.
This demuxer is used to demux an ADTS input containing a single AAC stream
alongwith any ID3v1/2 or APE tags in it.
20.3 apng
Animated Portable Network Graphics demuxer.
This demuxer is used to demux APNG files.
All headers, but the PNG signature, up to (but not including) the first
fcTL chunk are transmitted as extradata.
Frames are then split as being all the chunks between two fcTL ones, or
between the last fcTL and IEND chunks.
-ignore_loop bool
Ignore the loop variable in the file if set. Default is enabled.
-max_fps int
Maximum framerate in frames per second. Default of 0 imposes no limit.
-default_fps int
Default framerate in frames per second when none is specified in the file
(0 meaning as fast as possible). Default is 15.
20.4 asf
Advanced Systems Format demuxer.
This demuxer is used to demux ASF files and MMS network streams.
-no_resync_search bool
Do not try to resynchronize by looking for a certain optional start code.
20.5 concat
Virtual concatenation script demuxer.
This demuxer reads a list of files and other directives from a text file and
demuxes them one after the other, as if all their packets had been muxed
together.
The timestamps in the files are adjusted so that the first file starts at 0
and each next file starts where the previous one finishes. Note that it is
done globally and may cause gaps if all streams do not have exactly the same
length.
All files must have the same streams (same codecs, same time base, etc.).
The duration of each file is used to adjust the timestamps of the next file:
if the duration is incorrect (because it was computed using the bit-rate or
because the file is truncated, for example), it can cause artifacts. The
duration directive can be used to override the duration stored in
each file.
20.5.1 Syntax
The script is a text file in extended-ASCII, with one directive per line.
Empty lines, leading spaces and lines starting with ’#’ are ignored. The
following directive is recognized:
file path
Path to a file to read; special characters and spaces must be escaped with
backslash or single quotes.
All subsequent file-related directives apply to that file.
ffconcat version 1.0
Identify the script type and version.
To make FFmpeg recognize the format automatically, this directive must
appear exactly as is (no extra space or byte-order-mark) on the very first
line of the script.
duration dur
Duration of the file. This information can be specified from the file;
specifying it here may be more efficient or help if the information from the
file is not available or accurate.
If the duration is set for all files, then it is possible to seek in the
whole concatenated video.
inpoint timestamp
In point of the file. When the demuxer opens the file it instantly seeks to the
specified timestamp. Seeking is done so that all streams can be presented
successfully at In point.
This directive works best with intra frame codecs, because for non-intra frame
ones you will usually get extra packets before the actual In point and the
decoded content will most likely contain frames before In point too.
For each file, packets before the file In point will have timestamps less than
the calculated start timestamp of the file (negative in case of the first
file), and the duration of the files (if not specified by the duration
directive) will be reduced based on their specified In point.
Because of potential packets before the specified In point, packet timestamps
may overlap between two concatenated files.
outpoint timestamp
Out point of the file. When the demuxer reaches the specified decoding
timestamp in any of the streams, it handles it as an end of file condition and
skips the current and all the remaining packets from all streams.
Out point is exclusive, which means that the demuxer will not output packets
with a decoding timestamp greater or equal to Out point.
This directive works best with intra frame codecs and formats where all streams
are tightly interleaved. For non-intra frame codecs you will usually get
additional packets with presentation timestamp after Out point therefore the
decoded content will most likely contain frames after Out point too. If your
streams are not tightly interleaved you may not get all the packets from all
streams before Out point and you may only will be able to decode the earliest
stream until Out point.
The duration of the files (if not specified by the duration
directive) will be reduced based on their specified Out point.
file_packet_metadata key=value
Metadata of the packets of the file. The specified metadata will be set for
each file packet. You can specify this directive multiple times to add multiple
metadata entries.
This directive is deprecated, use file_packet_meta instead.
file_packet_meta key value
Metadata of the packets of the file. The specified metadata will be set for
each file packet. You can specify this directive multiple times to add multiple
metadata entries.
option key value
Option to access, open and probe the file.
Can be present multiple times.
stream
Introduce a stream in the virtual file.
All subsequent stream-related directives apply to the last introduced
stream.
Some streams properties must be set in order to allow identifying the
matching streams in the subfiles.
If no streams are defined in the script, the streams from the first file are
copied.
exact_stream_id id
Set the id of the stream.
If this directive is given, the string with the corresponding id in the
subfiles will be used.
This is especially useful for MPEG-PS (VOB) files, where the order of the
streams is not reliable.
stream_meta key value
Metadata for the stream.
Can be present multiple times.
stream_codec value
Codec for the stream.
stream_extradata hex_string
Extradata for the string, encoded in hexadecimal.
chapter id start end
Add a chapter. id is an unique identifier, possibly small and
consecutive.
20.5.2 Options
This demuxer accepts the following option:
safe
If set to 1, reject unsafe file paths and directives.
A file path is considered safe if it
does not contain a protocol specification and is relative and all components
only contain characters from the portable character set (letters, digits,
period, underscore and hyphen) and have no period at the beginning of a
component.
If set to 0, any file name is accepted.
The default is 1.
auto_convert
If set to 1, try to perform automatic conversions on packet data to make the
streams concatenable.
The default is 1.
Currently, the only conversion is adding the h264_mp4toannexb bitstream
filter to H.264 streams in MP4 format. This is necessary in particular if
there are resolution changes.
segment_time_metadata
If set to 1, every packet will contain the lavf.concat.start_time and the
lavf.concat.duration packet metadata values which are the start_time and
the duration of the respective file segments in the concatenated output
expressed in microseconds. The duration metadata is only set if it is known
based on the concat file.
The default is 0.
20.5.3 Examples
Use absolute filenames and include some comments:
# my first filename
file /mnt/share/file-1.wav
# my second filename including whitespace
file '/mnt/share/file 2.wav'
# my third filename including whitespace plus single quote
file '/mnt/share/file 3'\''.wav'
Allow for input format auto-probing, use safe filenames and set the duration of
the first file:
ffconcat version 1.0
file file-1.wav
duration 20.0
file subdir/file-2.wav
20.6 dash
Dynamic Adaptive Streaming over HTTP demuxer.
This demuxer presents all AVStreams found in the manifest.
By setting the discard flags on AVStreams the caller can decide
which streams to actually receive.
Each stream mirrors the id and bandwidth properties from the
<Representation> as metadata keys named "id" and "variant_bitrate" respectively.
20.6.1 Options
This demuxer accepts the following option:
cenc_decryption_key
16-byte key, in hex, to decrypt files encrypted using ISO Common Encryption (CENC/AES-128 CTR; ISO/IEC 23001-7).
20.7 dvdvideo
DVD-Video demuxer, powered by libdvdnav and libdvdread.
Can directly ingest DVD titles, specifically sequential PGCs, into
a conversion pipeline. Menu assets, such as background video or audio,
can also be demuxed given the menu’s coordinates (at best effort).
Block devices (DVD drives), ISO files, and directory structures are accepted.
Activate with -f dvdvideo in front of one of these inputs.
This demuxer does NOT have decryption code of any kind. You are on your own
working with encrypted DVDs, and should not expect support on the matter.
Underlying playback is handled by libdvdnav, and structure parsing by libdvdread.
FFmpeg must be built with GPL library support available as well as the
configure switches --enable-libdvdnav and --enable-libdvdread.
You will need to provide either the desired "title number" or exact PGC/PG coordinates.
Many open-source DVD players and tools can aid in providing this information.
If not specified, the demuxer will default to title 1 which works for many discs.
However, due to the flexibility of the format, it is recommended to check manually.
There are many discs that are authored strangely or with invalid headers.
If the input is a real DVD drive, please note that there are some drives which may
silently fail on reading bad sectors from the disc, returning random bits instead
which is effectively corrupt data. This is especially prominent on aging or rotting discs.
A second pass and integrity checks would be needed to detect the corruption.
This is not an FFmpeg issue.
20.7.1 Background
DVD-Video is not a directly accessible, linear container format in the
traditional sense. Instead, it allows for complex and programmatic playback of
carefully muxed MPEG-PS streams that are stored in headerless VOB files.
To the end-user, these streams are known simply as "titles", but the actual
logical playback sequence is defined by one or more "PGCs", or Program Group Chains,
within the title. The PGC is in turn comprised of multiple "PGs", or Programs",
which are the actual video segments (and for a typical video feature, sequentially
ordered). The PGC structure, along with stream layout and metadata, are stored in
IFO files that need to be parsed. PGCs can be thought of as playlists in easier terms.
An actual DVD player relies on user GUI interaction via menus and an internal VM
to drive the direction of demuxing. Generally, the user would either navigate (via menus)
or automatically be redirected to the PGC of their choice. During this process and
the subsequent playback, the DVD player’s internal VM also maintains a state and
executes instructions that can create jumps to different sectors during playback.
This is why libdvdnav is involved, as a linear read of the MPEG-PS blobs on the
disc (VOBs) is not enough to produce the right sequence in many cases.
There are many other DVD structures (a long subject) that will not be discussed here.
NAV packets, in particular, are handled by this demuxer to build accurate timing
but not emitted as a stream. For a good high-level understanding, refer to:
https://code.videolan.org/videolan/libdvdnav/-/blob/master/doc/dvd_structures
20.7.2 Options
This demuxer accepts the following options:
title int
The title number to play. Must be set if pgc and pg are not set.
Not applicable to menus.
Default is 0 (auto), which currently only selects the first available title (title 1)
and notifies the user about the implications.
chapter_start int
The chapter, or PTT (part-of-title), number to start at. Not applicable to menus.
Default is 1.
chapter_end int
The chapter, or PTT (part-of-title), number to end at. Not applicable to menus.
Default is 0, which is a special value to signal end at the last possible chapter.
angle int
The video angle number, referring to what is essentially an additional
video stream that is composed from alternate frames interleaved in the VOBs.
Not applicable to menus.
Default is 1.
region int
The region code to use for playback. Some discs may use this to default playback
at a particular angle in different regions. This option will not affect the region code
of a real DVD drive, if used as an input. Not applicable to menus.
Default is 0, "world".
menu bool
Demux menu assets instead of navigating a title. Requires exact coordinates
of the menu (menu_lu, menu_vts, pgc, pg).
Default is false.
menu_lu int
The menu language to demux. In DVD, menus are grouped by language.
Default is 1, the first language unit.
menu_vts int
The VTS where the menu lives, or 0 if it is a VMG menu (root-level).
Default is 1, menu of the first VTS.
pgc int
The entry PGC to start playback, in conjunction with pg.
Alternative to setting title.
Chapter markers are not supported at this time.
Must be explicitly set for menus.
Default is 0, automatically resolve from value of title.
pg int
The entry PG to start playback, in conjunction with pgc.
Alternative to setting title.
Chapter markers are not supported at this time.
Default is 1, the first PG of the PGC.
preindex bool
Enable this to have accurate chapter (PTT) markers and duration measurement,
which requires a slow second pass read in order to index the chapter marker
timestamps from NAV packets. This is non-ideal extra work for real optical drives.
It is recommended and faster to use this option with a backup of the DVD structure
stored on a hard drive. Not compatible with pgc and pg.
Default is 0, false.
trim bool
Skip padding cells (i.e. cells shorter than 1 second) from the beginning.
There exist many discs with filler segments at the beginning of the PGC,
often with junk data intended for controlling a real DVD player’s
buffering speed and with no other material data value.
Not applicable to menus.
Default is 1, true.
20.7.3 Examples
Open title 3 from a given DVD structure:
ffmpeg -f dvdvideo -title 3 -i <path to DVD> ...
Open chapters 3-6 from title 1 from a given DVD structure:
ffmpeg -f dvdvideo -chapter_start 3 -chapter_end 6 -title 1 -i <path to DVD> ...
Open only chapter 5 from title 1 from a given DVD structure:
ffmpeg -f dvdvideo -chapter_start 5 -chapter_end 5 -title 1 -i <path to DVD> ...
Demux menu with language 1 from VTS 1, PGC 1, starting at PG 1:
ffmpeg -f dvdvideo -menu 1 -menu_lu 1 -menu_vts 1 -pgc 1 -pg 1 -i <path to DVD> ...
20.8 ea
Electronic Arts Multimedia format demuxer.
This format is used by various Electronic Arts games.
20.8.1 Options
merge_alpha bool
Normally the VP6 alpha channel (if exists) is returned as a secondary video
stream, by setting this option you can make the demuxer return a single video
stream which contains the alpha channel in addition to the ordinary video.
20.9 imf
Interoperable Master Format demuxer.
This demuxer presents audio and video streams found in an IMF Composition, as
specified in SMPTE ST 2067-2.
ffmpeg [-assetmaps <path of ASSETMAP1>,<path of ASSETMAP2>,...] -i <path of CPL> ...
If -assetmaps is not specified, the demuxer looks for a file called
ASSETMAP.xml in the same directory as the CPL.
20.10 flv, live_flv, kux
Adobe Flash Video Format demuxer.
This demuxer is used to demux FLV files and RTMP network streams. In case of live network streams, if you force format, you may use live_flv option instead of flv to survive timestamp discontinuities.
KUX is a flv variant used on the Youku platform.
ffmpeg -f flv -i myfile.flv ...
ffmpeg -f live_flv -i rtmp://<any.server>/anything/key ....
-flv_metadata bool
Allocate the streams according to the onMetaData array content.
-flv_ignore_prevtag bool
Ignore the size of previous tag value.
-flv_full_metadata bool
Output all context of the onMetadata.
20.11 gif
Animated GIF demuxer.
It accepts the following options:
min_delay
Set the minimum valid delay between frames in hundredths of seconds.
Range is 0 to 6000. Default value is 2.
max_gif_delay
Set the maximum valid delay between frames in hundredth of seconds.
Range is 0 to 65535. Default value is 65535 (nearly eleven minutes),
the maximum value allowed by the specification.
default_delay
Set the default delay between frames in hundredths of seconds.
Range is 0 to 6000. Default value is 10.
ignore_loop
GIF files can contain information to loop a certain number of times (or
infinitely). If ignore_loop is set to 1, then the loop setting
from the input will be ignored and looping will not occur. If set to 0,
then looping will occur and will cycle the number of times according to
the GIF. Default value is 1.
For example, with the overlay filter, place an infinitely looping GIF
over another video:
ffmpeg -i input.mp4 -ignore_loop 0 -i input.gif -filter_complex overlay=shortest=1 out.mkv
Note that in the above example the shortest option for overlay filter is
used to end the output video at the length of the shortest input file,
which in this case is input.mp4 as the GIF in this example loops
infinitely.
20.12 hls
HLS demuxer
Apple HTTP Live Streaming demuxer.
This demuxer presents all AVStreams from all variant streams.
The id field is set to the bitrate variant index number. By setting
the discard flags on AVStreams (by pressing ’a’ or ’v’ in ffplay),
the caller can decide which variant streams to actually receive.
The total bitrate of the variant that the stream belongs to is
available in a metadata key named "variant_bitrate".
It accepts the following options:
live_start_index
segment index to start live streams at (negative values are from the end).
prefer_x_start
prefer to use #EXT-X-START if it’s in playlist instead of live_start_index.
allowed_extensions
’,’ separated list of file extensions that hls is allowed to access.
max_reload
Maximum number of times a insufficient list is attempted to be reloaded.
Default value is 1000.
m3u8_hold_counters
The maximum number of times to load m3u8 when it refreshes without new segments.
Default value is 1000.
http_persistent
Use persistent HTTP connections. Applicable only for HTTP streams.
Enabled by default.
http_multiple
Use multiple HTTP connections for downloading HTTP segments.
Enabled by default for HTTP/1.1 servers.
http_seekable
Use HTTP partial requests for downloading HTTP segments.
0 = disable, 1 = enable, -1 = auto, Default is auto.
seg_format_options
Set options for the demuxer of media segments using a list of key=value pairs separated by :.
seg_max_retry
Maximum number of times to reload a segment on error, useful when segment skip on network error is not desired.
Default value is 0.
20.13 image2
Image file demuxer.
This demuxer reads from a list of image files specified by a pattern.
The syntax and meaning of the pattern is specified by the
option pattern_type.
The pattern may contain a suffix which is used to automatically
determine the format of the images contained in the files.
The size, the pixel format, and the format of each image must be the
same for all the files in the sequence.
This demuxer accepts the following options:
framerate
Set the frame rate for the video stream. It defaults to 25.
loop
If set to 1, loop over the input. Default value is 0.
pattern_type
Select the pattern type used to interpret the provided filename.
pattern_type accepts one of the following values.
none
Disable pattern matching, therefore the video will only contain the specified
image. You should use this option if you do not want to create sequences from
multiple images and your filenames may contain special pattern characters.
sequence
Select a sequence pattern type, used to specify a sequence of files
indexed by sequential numbers.
A sequence pattern may contain the string "%d" or "%0Nd", which
specifies the position of the characters representing a sequential
number in each filename matched by the pattern. If the form
"%d0Nd" is used, the string representing the number in each
filename is 0-padded and N is the total number of 0-padded
digits representing the number. The literal character ’%’ can be
specified in the pattern with the string "%%".
If the sequence pattern contains "%d" or "%0Nd", the first filename of
the file list specified by the pattern must contain a number
inclusively contained between start_number and
start_number+start_number_range-1, and all the following
numbers must be sequential.
For example the pattern "img-%03d.bmp" will match a sequence of
filenames of the form img-001.bmp, img-002.bmp, ...,
img-010.bmp, etc.; the pattern "i%%m%%g-%d.jpg" will match a
sequence of filenames of the form i%m%g-1.jpg,
i%m%g-2.jpg, ..., i%m%g-10.jpg, etc.
Note that the pattern must not necessarily contain "%d" or
"%0Nd", for example to convert a single image file
img.jpeg you can employ the command:
ffmpeg -i img.jpeg img.png
glob
Select a glob wildcard pattern type.
The pattern is interpreted like a glob() pattern. This is only
selectable if libavformat was compiled with globbing support.
glob_sequence (deprecated, will be removed)
Select a mixed glob wildcard/sequence pattern.
If your version of libavformat was compiled with globbing support, and
the provided pattern contains at least one glob meta character among
%*?[]{} that is preceded by an unescaped "%", the pattern is
interpreted like a glob() pattern, otherwise it is interpreted
like a sequence pattern.
All glob special characters %*?[]{} must be prefixed
with "%". To escape a literal "%" you shall use "%%".
For example the pattern foo-%*.jpeg will match all the
filenames prefixed by "foo-" and terminating with ".jpeg", and
foo-%?%?%?.jpeg will match all the filenames prefixed with
"foo-", followed by a sequence of three characters, and terminating
with ".jpeg".
This pattern type is deprecated in favor of glob and
sequence.
Default value is glob_sequence.
pixel_format
Set the pixel format of the images to read. If not specified the pixel
format is guessed from the first image file in the sequence.
start_number
Set the index of the file matched by the image file pattern to start
to read from. Default value is 0.
start_number_range
Set the index interval range to check when looking for the first image
file in the sequence, starting from start_number. Default value
is 5.
ts_from_file
If set to 1, will set frame timestamp to modification time of image file. Note
that monotonity of timestamps is not provided: images go in the same order as
without this option. Default value is 0.
If set to 2, will set frame timestamp to the modification time of the image file in
nanosecond precision.
video_size
Set the video size of the images to read. If not specified the video
size is guessed from the first image file in the sequence.
export_path_metadata
If set to 1, will add two extra fields to the metadata found in input, making them
also available for other filters (see drawtext filter for examples). Default
value is 0. The extra fields are described below:
lavf.image2dec.source_path
Corresponds to the full path to the input file being read.
lavf.image2dec.source_basename
Corresponds to the name of the file being read.
20.13.1 Examples
Use ffmpeg for creating a video from the images in the file
sequence img-001.jpeg, img-002.jpeg, ..., assuming an
input frame rate of 10 frames per second:
ffmpeg -framerate 10 -i 'img-%03d.jpeg' out.mkv
As above, but start by reading from a file with index 100 in the sequence:
ffmpeg -framerate 10 -start_number 100 -i 'img-%03d.jpeg' out.mkv
Read images matching the "*.png" glob pattern , that is all the files
terminating with the ".png" suffix:
ffmpeg -framerate 10 -pattern_type glob -i "*.png" out.mkv
20.14 libgme
The Game Music Emu library is a collection of video game music file emulators.
See https://bitbucket.org/mpyne/game-music-emu/overview for more information.
It accepts the following options:
track_index
Set the index of which track to demux. The demuxer can only export one track.
Track indexes start at 0. Default is to pick the first track. Number of tracks
is exported as tracks metadata entry.
sample_rate
Set the sampling rate of the exported track. Range is 1000 to 999999. Default is 44100.
max_size (bytes)
The demuxer buffers the entire file into memory. Adjust this value to set the maximum buffer size,
which in turn, acts as a ceiling for the size of files that can be read.
Default is 50 MiB.
20.15 libmodplug
ModPlug based module demuxer
See https://github.com/Konstanty/libmodplug
It will export one 2-channel 16-bit 44.1 kHz audio stream.
Optionally, a pal8 16-color video stream can be exported with or without printed metadata.
It accepts the following options:
noise_reduction
Apply a simple low-pass filter. Can be 1 (on) or 0 (off). Default is 0.
reverb_depth
Set amount of reverb. Range 0-100. Default is 0.
reverb_delay
Set delay in ms, clamped to 40-250 ms. Default is 0.
bass_amount
Apply bass expansion a.k.a. XBass or megabass. Range is 0 (quiet) to 100 (loud). Default is 0.
bass_range
Set cutoff i.e. upper-bound for bass frequencies. Range is 10-100 Hz. Default is 0.
surround_depth
Apply a Dolby Pro-Logic surround effect. Range is 0 (quiet) to 100 (heavy). Default is 0.
surround_delay
Set surround delay in ms, clamped to 5-40 ms. Default is 0.
max_size
The demuxer buffers the entire file into memory. Adjust this value to set the maximum buffer size,
which in turn, acts as a ceiling for the size of files that can be read. Range is 0 to 100 MiB.
0 removes buffer size limit (not recommended). Default is 5 MiB.
video_stream_expr
String which is evaluated using the eval API to assign colors to the generated video stream.
Variables which can be used are x, y, w, h, t, speed,
tempo, order, pattern and row.
video_stream
Generate video stream. Can be 1 (on) or 0 (off). Default is 0.
video_stream_w
Set video frame width in ’chars’ where one char indicates 8 pixels. Range is 20-512. Default is 30.
video_stream_h
Set video frame height in ’chars’ where one char indicates 8 pixels. Range is 20-512. Default is 30.
video_stream_ptxt
Print metadata on video stream. Includes speed, tempo, order, pattern,
row and ts (time in ms). Can be 1 (on) or 0 (off). Default is 1.
20.16 libopenmpt
libopenmpt based module demuxer
See https://lib.openmpt.org/libopenmpt/ for more information.
Some files have multiple subsongs (tracks) this can be set with the subsong
option.
It accepts the following options:
subsong
Set the subsong index. This can be either  ’all’, ’auto’, or the index of the
subsong. Subsong indexes start at 0. The default is ’auto’.
The default value is to let libopenmpt choose.
layout
Set the channel layout. Valid values are 1, 2, and 4 channel layouts.
The default value is STEREO.
sample_rate
Set the sample rate for libopenmpt to output.
Range is from 1000 to INT_MAX. The value default is 48000.
20.17 mov/mp4/3gp
Demuxer for Quicktime File Format & ISO/IEC Base Media File Format (ISO/IEC 14496-12 or MPEG-4 Part 12, ISO/IEC 15444-12 or JPEG 2000 Part 12).
Registered extensions: mov, mp4, m4a, 3gp, 3g2, mj2, psp, m4b, ism, ismv, isma, f4v
20.17.1 Options
This demuxer accepts the following options:
enable_drefs
Enable loading of external tracks, disabled by default.
Enabling this can theoretically leak information in some use cases.
use_absolute_path
Allows loading of external tracks via absolute paths, disabled by default.
Enabling this poses a security risk. It should only be enabled if the source
is known to be non-malicious.
seek_streams_individually
When seeking, identify the closest point in each stream individually and demux packets in
that stream from identified point. This can lead to a different sequence of packets compared
to demuxing linearly from the beginning. Default is true.
ignore_editlist
Ignore any edit list atoms. The demuxer, by default, modifies the stream index to reflect the
timeline described by the edit list. Default is false.
advanced_editlist
Modify the stream index to reflect the timeline described by the edit list. ignore_editlist
must be set to false for this option to be effective.
If both ignore_editlist and this option are set to false, then only the
start of the stream index is modified to reflect initial dwell time or starting timestamp
described by the edit list. Default is true.
ignore_chapters
Don’t parse chapters. This includes GoPro ’HiLight’ tags/moments. Note that chapters are
only parsed when input is seekable. Default is false.
use_mfra_for
For seekable fragmented input, set fragment’s starting timestamp from media fragment random access box, if present.
Following options are available:
‘auto’
Auto-detect whether to set mfra timestamps as PTS or DTS (default)
‘dts’
Set mfra timestamps as DTS
‘pts’
Set mfra timestamps as PTS
‘0’
Don’t use mfra box to set timestamps
use_tfdt
For fragmented input, set fragment’s starting timestamp to baseMediaDecodeTime from the tfdt box.
Default is enabled, which will prefer to use the tfdt box to set DTS. Disable to use the earliest_presentation_time from the sidx box.
In either case, the timestamp from the mfra box will be used if it’s available and use_mfra_for is
set to pts or dts.
export_all
Export unrecognized boxes within the udta box as metadata entries. The first four
characters of the box type are set as the key. Default is false.
export_xmp
Export entire contents of XMP_ box and uuid box as a string with key xmp. Note that
if export_all is set and this option isn’t, the contents of XMP_ box are still exported
but with key XMP_. Default is false.
activation_bytes
4-byte key required to decrypt Audible AAX and AAX+ files. See Audible AAX subsection below.
audible_fixed_key
Fixed key used for handling Audible AAX/AAX+ files. It has been pre-set so should not be necessary to
specify.
decryption_key
16-byte key, in hex, to decrypt files encrypted using ISO Common Encryption (CENC/AES-128 CTR; ISO/IEC 23001-7).
max_stts_delta
Very high sample deltas written in a trak’s stts box may occasionally be intended but usually they are written in
error or used to store a negative value for dts correction when treated as signed 32-bit integers. This option lets
the user set an upper limit, beyond which the delta is clamped to 1. Values greater than the limit if negative when
cast to int32 are used to adjust onward dts.
Unit is the track time scale. Range is 0 to UINT_MAX. Default is UINT_MAX - 48000*10 which allows up to
a 10 second dts correction for 48 kHz audio streams while accommodating 99.9% of uint32 range.
interleaved_read
Interleave packets from multiple tracks at demuxer level. For badly interleaved files, this prevents playback issues
caused by large gaps between packets in different tracks, as MOV/MP4 do not have packet placement requirements.
However, this can cause excessive seeking on very badly interleaved files, due to seeking between tracks, so disabling
it may prevent I/O issues, at the expense of playback.
20.17.2 Audible AAX
Audible AAX files are encrypted M4B files, and they can be decrypted by specifying a 4 byte activation secret.
ffmpeg -activation_bytes 1CEB00DA -i test.aax -vn -c:a copy output.mp4
20.18 mpegts
MPEG-2 transport stream demuxer.
This demuxer accepts the following options:
resync_size
Set size limit for looking up a new synchronization. Default value is
65536.
skip_unknown_pmt
Skip PMTs for programs not defined in the PAT. Default value is 0.
fix_teletext_pts
Override teletext packet PTS and DTS values with the timestamps calculated
from the PCR of the first program which the teletext stream is part of and is
not discarded. Default value is 1, set this option to 0 if you want your
teletext packet PTS and DTS values untouched.
ts_packetsize
Output option carrying the raw packet size in bytes.
Show the detected raw packet size, cannot be set by the user.
scan_all_pmts
Scan and combine all PMTs. The value is an integer with value from -1
to 1 (-1 means automatic setting, 1 means enabled, 0 means
disabled). Default value is -1.
merge_pmt_versions
Re-use existing streams when a PMT’s version is updated and elementary
streams move to different PIDs. Default value is 0.
max_packet_size
Set maximum size, in bytes, of packet emitted by the demuxer. Payloads above this size
are split across multiple packets. Range is 1 to INT_MAX/2. Default is 204800 bytes.
20.19 mpjpeg
MJPEG encapsulated in multi-part MIME demuxer.
This demuxer allows reading of MJPEG, where each frame is represented as a part of
multipart/x-mixed-replace stream.
strict_mime_boundary
Default implementation applies a relaxed standard to multi-part MIME boundary detection,
to prevent regression with numerous existing endpoints not generating a proper MIME
MJPEG stream. Turning this option on by setting it to 1 will result in a stricter check
of the boundary value.
20.20 rawvideo
Raw video demuxer.
This demuxer allows one to read raw video data. Since there is no header
specifying the assumed video parameters, the user must specify them
in order to be able to decode the data correctly.
This demuxer accepts the following options:
framerate
Set input video frame rate. Default value is 25.
pixel_format
Set the input video pixel format. Default value is yuv420p.
video_size
Set the input video size. This value must be specified explicitly.
For example to read a rawvideo file input.raw with
ffplay, assuming a pixel format of rgb24, a video
size of 320x240, and a frame rate of 10 images per second, use
the command:
ffplay -f rawvideo -pixel_format rgb24 -video_size 320x240 -framerate 10 input.raw
20.21 rcwt
RCWT (Raw Captions With Time) is a format native to ccextractor, a commonly
used open source tool for processing 608/708 Closed Captions (CC) sources.
For more information on the format, see (ffmpeg-formats)rcwtenc.
This demuxer implements the specification as of March 2024, which has
been stable and unchanged since April 2014.
20.21.1 Examples
Render CC to ASS using the built-in decoder:
ffmpeg -i CC.rcwt.bin CC.ass
Note that if your output appears to be empty, you may have to manually
set the decoder’s data_field option to pick the desired CC substream.
Convert an RCWT backup to Scenarist (SCC) format:
ffmpeg -i CC.rcwt.bin -c:s copy CC.scc
Note that the SCC format does not support all of the possible CC extensions
that can be stored in RCWT (such as EIA-708).
20.22 sbg
SBaGen script demuxer.
This demuxer reads the script language used by SBaGen
http://uazu.net/sbagen/ to generate binaural beats sessions. A SBG
script looks like that:
-SE
a: 300-2.5/3 440+4.5/0
b: 300-2.5/0 440+4.5/3
off: -
NOW      == a
+0:07:00 == b
+0:14:00 == a
+0:21:00 == b
+0:30:00    off
A SBG script can mix absolute and relative timestamps. If the script uses
either only absolute timestamps (including the script start time) or only
relative ones, then its layout is fixed, and the conversion is
straightforward. On the other hand, if the script mixes both kind of
timestamps, then the NOW reference for relative timestamps will be
taken from the current time of day at the time the script is read, and the
script layout will be frozen according to that reference. That means that if
the script is directly played, the actual times will match the absolute
timestamps up to the sound controller’s clock accuracy, but if the user
somehow pauses the playback or seeks, all times will be shifted accordingly.
20.23 tedcaptions
JSON captions used for TED Talks.
TED does not provide links to the captions, but they can be guessed from the
page. The file tools/bookmarklets.html from the FFmpeg source tree
contains a bookmarklet to expose them.
This demuxer accepts the following option:
start_time
Set the start time of the TED talk, in milliseconds. The default is 15000
(15s). It is used to sync the captions with the downloadable videos, because
they include a 15s intro.
Example: convert the captions to a format most players understand:
ffmpeg -i http://www.ted.com/talks/subtitles/id/1/lang/en talk1-en.srt
20.24 vapoursynth
Vapoursynth wrapper.
Due to security concerns, Vapoursynth scripts will not
be autodetected so the input format has to be forced. For ff* CLI tools,
add -f vapoursynth before the input -i yourscript.vpy.
This demuxer accepts the following option:
max_script_size
The demuxer buffers the entire script into memory. Adjust this value to set the maximum buffer size,
which in turn, acts as a ceiling for the size of scripts that can be read.
Default is 1 MiB.
20.25 w64
Sony Wave64 Audio demuxer.
This demuxer accepts the following options:
max_size
See the same option for the wav demuxer.
20.26 wav
RIFF Wave Audio demuxer.
This demuxer accepts the following options:
max_size
Specify the maximum packet size in bytes for the demuxed packets. By default
this is set to 0, which means that a sensible value is chosen based on the
input format.
21 Muxers
Muxers are configured elements in FFmpeg which allow writing
multimedia streams to a particular type of file.
When you configure your FFmpeg build, all the supported muxers
are enabled by default. You can list all available muxers using the
configure option --list-muxers.
You can disable all the muxers with the configure option
--disable-muxers and selectively enable / disable single muxers
with the options --enable-muxer=MUXER /
--disable-muxer=MUXER.
The option -muxers of the ff* tools will display the list of
enabled muxers. Use -formats to view a combined list of
enabled demuxers and muxers.
A description of some of the currently available muxers follows.
21.1 Raw muxers
This section covers raw muxers. They accept a single stream matching
the designated codec. They do not store timestamps or metadata. The
recognized extension is the same as the muxer name unless indicated
otherwise.
It comprises the following muxers. The media type and the eventual
extensions used to automatically selects the muxer from the output
extensions are also shown.
‘ac3 audio’
Dolby Digital, also known as AC-3.
‘adx audio’
CRI Middleware ADX audio.
This muxer will write out the total sample count near the start of the
first packet when the output is seekable and the count can be stored
in 32 bits.
‘aptx audio’
aptX (Audio Processing Technology for Bluetooth)
‘aptx_hd audio (aptxdh)’
aptX HD (Audio Processing Technology for Bluetooth) audio
‘avs2 video (avs, avs2)’
AVS2-P2 (Audio Video Standard - Second generation - Part 2) /
IEEE 1857.4 video
‘avs3 video (avs3)’
AVS3-P2 (Audio Video Standard - Third generation - Part 2) /
IEEE 1857.10 video
‘cavsvideo video (cavs)’
Chinese AVS (Audio Video Standard - First generation)
‘codec2raw audio’
Codec 2 audio.
No extension is registered so format name has to be supplied e.g. with
the ffmpeg CLI tool -f codec2raw.
‘data any’
Generic data muxer.
This muxer accepts a single stream with any codec of any type. The
input stream has to be selected using the -map option with the
ffmpeg CLI tool.
No extension is registered so format name has to be supplied e.g. with
the ffmpeg CLI tool -f data.
‘dfpwm audio (dfpwm)’
Raw DFPWM1a (Dynamic Filter Pulse With Modulation) audio muxer.
‘dirac video (drc, vc2)’
BBC Dirac video.
The Dirac Pro codec is a subset and is standardized as SMPTE VC-2.
‘dnxhd video (dnxhd, dnxhr)’
Avid DNxHD video.
It is standardized as SMPTE VC-3. Accepts DNxHR streams.
‘dts audio’
DTS Coherent Acoustics (DCA) audio
‘eac3 audio’
Dolby Digital Plus, also known as Enhanced AC-3
‘evc video (evc)’
MPEG-5 Essential Video Coding (EVC) / EVC / MPEG-5 Part 1 EVC video
‘g722 audio’
ITU-T G.722 audio
‘g723_1 audio (tco, rco)’
ITU-T G.723.1 audio
‘g726 audio’
ITU-T G.726 big-endian ("left-justified") audio.
No extension is registered so format name has to be supplied e.g. with
the ffmpeg CLI tool -f g726.
‘g726le audio’
ITU-T G.726 little-endian ("right-justified") audio.
No extension is registered so format name has to be supplied e.g. with
the ffmpeg CLI tool -f g726le.
‘gsm audio’
Global System for Mobile Communications audio
‘h261 video’
ITU-T H.261 video
‘h263 video’
ITU-T H.263 / H.263-1996, H.263+ / H.263-1998 / H.263 version 2 video
‘h264 video (h264, 264)’
ITU-T H.264 / MPEG-4 Part 10 AVC video. Bitstream shall be converted
to Annex B syntax if it’s in length-prefixed mode.
‘hevc video (hevc, h265, 265)’
ITU-T H.265 / MPEG-H Part 2 HEVC video. Bitstream shall be converted
to Annex B syntax if it’s in length-prefixed mode.
‘m4v video’
MPEG-4 Part 2 video
‘mjpeg video (mjpg, mjpeg)’
Motion JPEG video
‘mlp audio’
Meridian Lossless Packing, also known as Packed PCM
‘mp2 audio (mp2, m2a, mpa)’
MPEG-1 Audio Layer II audio
‘mpeg1video video (mpg, mpeg, m1v)’
MPEG-1 Part 2 video.
‘mpeg2video video (m2v)’
ITU-T H.262 / MPEG-2 Part 2 video
‘obu video’
AV1 low overhead Open Bitstream Units muxer.
Temporal delimiter OBUs will be inserted in all temporal units of the
stream.
‘rawvideo video (yuv, rgb)’
Raw uncompressed video.
‘sbc audio (sbc, msbc)’
Bluetooth SIG low-complexity subband codec audio
‘truehd audio (thd)’
Dolby TrueHD audio
‘vc1 video’
SMPTE 421M / VC-1 video
21.1.1 Examples
Store raw video frames with the ‘rawvideo’ muxer using ffmpeg:
ffmpeg -f lavfi -i testsrc -t 10 -s hd1080p testsrc.yuv
Since the rawvideo muxer do not store the information related to size
and format, this information must be provided when demuxing the file:
ffplay -video_size 1920x1080 -pixel_format rgb24 -f rawvideo testsrc.rgb
21.2 Raw PCM muxers
This section covers raw PCM (Pulse-Code Modulation) audio muxers.
They accept a single stream matching the designated codec. They do not
store timestamps or metadata. The recognized extension is the same as
the muxer name.
It comprises the following muxers. The optional additional extension
used to automatically select the muxer from the output extension is
also shown in parentheses.
‘alaw (al)’
PCM A-law
‘f32be’
PCM 32-bit floating-point big-endian
‘f32le’
PCM 32-bit floating-point little-endian
‘f64be’
PCM 64-bit floating-point big-endian
‘f64le’
PCM 64-bit floating-point little-endian
‘mulaw (ul)’
PCM mu-law
‘s16be’
PCM signed 16-bit big-endian
‘s16le’
PCM signed 16-bit little-endian
‘s24be’
PCM signed 24-bit big-endian
‘s24le’
PCM signed 24-bit little-endian
‘s32be’
PCM signed 32-bit big-endian
‘s32le’
PCM signed 32-bit little-endian
‘s8 (sb)’
PCM signed 8-bit
‘u16be’
PCM unsigned 16-bit big-endian
‘u16le’
PCM unsigned 16-bit little-endian
‘u24be’
PCM unsigned 24-bit big-endian
‘u24le’
PCM unsigned 24-bit little-endian
‘u32be’
PCM unsigned 32-bit big-endian
‘u32le’
PCM unsigned 32-bit little-endian
‘u8 (ub)’
PCM unsigned 8-bit
‘vidc’
PCM Archimedes VIDC
21.3 MPEG-1/MPEG-2 program stream muxers
This section covers formats belonging to the MPEG-1 and MPEG-2 Systems
family.
The MPEG-1 Systems format (also known as ISO/IEEC 11172-1 or MPEG-1
program stream) has been adopted for the format of media track stored
in VCD (Video Compact Disc).
The MPEG-2 Systems standard (also known as ISO/IEEC 13818-1) covers
two containers formats, one known as transport stream and one known as
program stream; only the latter is covered here.
The MPEG-2 program stream format (also known as VOB due to the
corresponding file extension) is an extension of MPEG-1 program
stream: in addition to support different codecs for the audio and
video streams, it also stores subtitles and navigation metadata.
MPEG-2 program stream has been adopted for storing media streams in
SVCD and DVD storage devices.
This section comprises the following muxers.
‘mpeg (mpg,mpeg)’
MPEG-1 Systems / MPEG-1 program stream muxer.
‘vcd’
MPEG-1 Systems / MPEG-1 program stream (VCD) muxer.
This muxer can be used to generate tracks in the format accepted by
the VCD (Video Compact Disc) storage devices.
It is the same as the ‘mpeg’ muxer with a few differences.
‘vob’
MPEG-2 program stream (VOB) muxer.
‘dvd’
MPEG-2 program stream (DVD VOB) muxer.
This muxer can be used to generate tracks in the format accepted by
the DVD (Digital Versatile Disc) storage devices.
This is the same as the ‘vob’ muxer with a few differences.
‘svcd (vob)’
MPEG-2 program stream (SVCD VOB) muxer.
This muxer can be used to generate tracks in the format accepted by
the SVCD (Super Video Compact Disc) storage devices.
This is the same as the ‘vob’ muxer with a few differences.
21.3.1 Options
muxrate rate
Set user-defined mux rate expressed as a number of bits/s. If not
specied the automatically computed mux rate is employed. Default value
is 0.
preload delay
Set initial demux-decode delay in microseconds. Default value is
500000.
21.4 MOV/MPEG-4/ISOMBFF muxers
This section covers formats belonging to the QuickTime / MOV family,
including the MPEG-4 Part 14 format and ISO base media file format
(ISOBMFF). These formats share a common structure based on the ISO
base media file format (ISOBMFF).
The MOV format was originally developed for use with Apple QuickTime.
It was later used as the basis for the MPEG-4 Part 1 (later Part 14)
format, also known as ISO/IEC 14496-1. That format was then
generalized into ISOBMFF, also named MPEG-4 Part 12 format, ISO/IEC
14496-12, or ISO/IEC 15444-12.
It comprises the following muxers.
‘3gp’
Third Generation Partnership Project (3GPP) format for 3G UMTS
multimedia services
‘3g2’
Third Generation Partnership Project 2 (3GP2 or 3GPP2) format for 3G
CDMA2000 multimedia services, similar to ‘3gp’ with extensions
and limitations
‘f4v’
Adobe Flash Video format
‘ipod’
MPEG-4 audio file format, as MOV/MP4 but limited to contain only audio
streams, typically played with the Apple ipod device
‘ismv’
Microsoft IIS (Internet Information Services) Smooth Streaming
Audio/Video (ISMV or ISMA) format. This is based on MPEG-4 Part 14
format with a few incompatible variants, used to stream media files
for the Microsoft IIS server.
‘mov’
QuickTime player format identified by the .mov extension
‘mp4’
MP4 or MPEG-4 Part 14 format
‘psp’
PlayStation Portable MP4/MPEG-4 Part 14 format variant. This is based
on MPEG-4 Part 14 format with a few incompatible variants, used to
play files on PlayStation devices.
21.4.1 Fragmentation
The ‘mov’, ‘mp4’, and ‘ismv’ muxers support
fragmentation. Normally, a MOV/MP4 file has all the metadata about all
packets stored in one location.
This data is usually written at the end of the file, but it can be
moved to the start for better playback by adding +faststart to
the -movflags, or using the qt-faststart tool).
A fragmented file consists of a number of fragments, where packets and
metadata about these packets are stored together. Writing a fragmented
file has the advantage that the file is decodable even if the writing
is interrupted (while a normal MOV/MP4 is undecodable if it is not
properly finished), and it requires less memory when writing very long
files (since writing normal MOV/MP4 files stores info about every
single packet in memory until the file is closed). The downside is
that it is less compatible with other applications.
Fragmentation is enabled by setting one of the options that define
how to cut the file into fragments:
frag_duration
frag_size
min_frag_duration
movflags +frag_keyframe
movflags +frag_custom
If more than one condition is specified, fragments are cut when one of
the specified conditions is fulfilled. The exception to this is the
option min_frag_duration, which has to be fulfilled for any
of the other conditions to apply.
21.4.2 Options
brand brand_string
Override major brand.
empty_hdlr_name bool
Enable to skip writing the name inside a hdlr box.
Default is false.
encryption_key key
set the media encryption key in hexadecimal format
encryption_kid kid
set the media encryption key identifier in hexadecimal format
encryption_scheme scheme
configure the encryption scheme, allowed values are ‘none’, and
‘cenc-aes-ctr’
frag_duration duration
Create fragments that are duration microseconds long.
frag_interleave  number
Interleave samples within fragments (max number of consecutive
samples, lower is tighter interleaving, but with more overhead. It is
set to 0 by default.
frag_size size
create fragments that contain up to size bytes of payload data
iods_audio_profile profile
specify iods number for the audio profile atom (from -1 to 255),
default is -1
iods_video_profile profile
specify iods number for the video profile atom (from -1 to 255),
default is -1
ism_lookahead num_entries
specify number of lookahead entries for ISM files (from 0 to 255),
default is 0
min_frag_duration duration
do not create fragments that are shorter than duration microseconds long
moov_size bytes
Reserves space for the moov atom at the beginning of the file instead of placing the
moov atom at the end. If the space reserved is insufficient, muxing will fail.
mov_gamma gamma
specify gamma value for gama atom (as a decimal number from 0 to 10),
default is 0.0, must be set together with + movflags
movflags flags
Set various muxing switches. The following flags can be used:
‘cmaf’
write CMAF (Common Media Application Format) compatible fragmented
MP4 output
‘dash’
write DASH (Dynamic Adaptive Streaming over HTTP) compatible fragmented
MP4 output
‘default_base_moof’
Similarly to the ‘omit_tfhd_offset’ flag, this flag avoids
writing the absolute base_data_offset field in tfhd atoms, but does so
by using the new default-base-is-moof flag instead. This flag is new
from 14496-12:2012. This may make the fragments easier to parse in
certain circumstances (avoiding basing track fragment location
calculations on the implicit end of the previous track fragment).
‘delay_moov’
delay writing the initial moov until the first fragment is cut, or
until the first fragment flush
‘disable_chpl’
Disable Nero chapter markers (chpl atom). Normally, both Nero chapters
and a QuickTime chapter track are written to the file. With this
option set, only the QuickTime chapter track will be written. Nero
chapters can cause failures when the file is reprocessed with certain
tagging programs, like mp3Tag 2.61a and iTunes 11.3, most likely other
versions are affected as well.
‘faststart’
Run a second pass moving the index (moov atom) to the beginning of the
file. This operation can take a while, and will not work in various
situations such as fragmented output, thus it is not enabled by
default.
‘frag_custom’
Allow the caller to manually choose when to cut fragments, by calling
av_write_frame(ctx, NULL) to write a fragment with the packets
written so far. (This is only useful with other applications
integrating libavformat, not from ffmpeg.)
‘frag_discont’
signal that the next fragment is discontinuous from earlier ones
‘frag_every_frame’
fragment at every frame
‘frag_keyframe’
start a new fragment at each video keyframe
‘global_sidx’
write a global sidx index at the start of the file
‘isml’
create a live smooth streaming feed (for pushing to a publishing point)
‘negative_cts_offsets’
Enables utilization of version 1 of the CTTS box, in which the CTS offsets can
be negative. This enables the initial sample to have DTS/CTS of zero, and
reduces the need for edit lists for some cases such as video tracks with
B-frames. Additionally, eases conformance with the DASH-IF interoperability
guidelines.
This option is implicitly set when writing ‘ismv’ (Smooth
Streaming) files.
‘omit_tfhd_offset’
Do not write any absolute base_data_offset in tfhd atoms. This avoids
tying fragments to absolute byte positions in the file/streams.
‘prefer_icc’
If writing colr atom prioritise usage of ICC profile if it exists in
stream packet side data.
‘rtphint’
add RTP hinting tracks to the output file
‘separate_moof’
Write a separate moof (movie fragment) atom for each track. Normally,
packets for all tracks are written in a moof atom (which is slightly
more efficient), but with this option set, the muxer writes one
moof/mdat pair for each track, making it easier to separate tracks.
‘skip_sidx’
Skip writing of sidx atom. When bitrate overhead due to sidx atom is
high, this option could be used for cases where sidx atom is not
mandatory. When the ‘global_sidx’ flag is enabled, this option
is ignored.
‘skip_trailer’
skip writing the mfra/tfra/mfro trailer for fragmented files
‘use_metadata_tags’
use mdta atom for metadata
‘write_colr’
write colr atom even if the color info is unspecified. This flag is
experimental, may be renamed or changed, do not use from scripts.
‘write_gama’
write deprecated gama atom
‘hybrid_fragmented’
For recoverability - write the output file as a fragmented file.
This allows the intermediate file to be read while being written
(in particular, if the writing process is aborted uncleanly). When
writing is finished, the file is converted to a regular, non-fragmented
file, which is more compatible and allows easier and quicker seeking.
If writing is aborted, the intermediate file can manually be
remuxed to get a regular, non-fragmented file of what had been
written into the unfinished file.
movie_timescale scale
Set the timescale written in the movie header box (mvhd).
Range is 1 to INT_MAX. Default is 1000.
rtpflags flags
Add RTP hinting tracks to the output file.
The following flags can be used:
‘h264_mode0’
use mode 0 for H.264 in RTP
‘latm’
use MP4A-LATM packetization instead of MPEG4-GENERIC for AAC
‘rfc2190’
use RFC 2190 packetization instead of RFC 4629 for H.263
‘send_bye’
send RTCP BYE packets when finishing
‘skip_rtcp’
do not send RTCP sender reports
skip_iods bool
skip writing iods atom (default value is true)
use_editlist bool
use edit list (default value is auto)
use_stream_ids_as_track_ids bool
use stream ids as track ids (default value is false)
video_track_timescale scale
Set the timescale used for video tracks. Range is 0 to INT_MAX. If
set to 0, the timescale is automatically set based on the
native stream time base. Default is 0.
write_btrt bool
Force or disable writing bitrate box inside stsd box of a track. The
box contains decoding buffer size (in bytes), maximum bitrate and
average bitrate for the track. The box will be skipped if none of
these values can be computed.  Default is -1 or auto,
which will write the box only in MP4 mode.
write_prft option
Write producer time reference box (PRFT) with a specified time source for the
NTP field in the PRFT box. Set value as ‘wallclock’ to specify timesource
as wallclock time and ‘pts’ to specify timesource as input packets’ PTS
values.
write_tmcd bool
Specify on to force writing a timecode track, off to disable it
and auto to write a timecode track only for mov and mp4 output (default).
Setting value to ‘pts’ is applicable only for a live encoding use case,
where PTS values are set as as wallclock time at the source. For example, an
encoding use case with decklink capture source where video_pts and
audio_pts are set to ‘abs_wallclock’.
21.4.3 Examples
Push Smooth Streaming content in real time to a publishing point on
IIS with the ‘ismv’ muxer using ffmpeg:
ffmpeg -re <normal input/transcoding options> -movflags isml+frag_keyframe -f ismv http://server/publishingpoint.isml/Streams(Encoder1)
21.5 a64
A64 Commodore 64 video muxer.
This muxer accepts a single a64_multi or a64_multi5
codec video stream.
21.6 ac4
Raw AC-4 audio muxer.
This muxer accepts a single ac4 audio stream.
21.6.1 Options
write_crc bool
when enabled, write a CRC checksum for each packet to the output,
default is false
21.7 adts
Audio Data Transport Stream muxer.
It accepts a single AAC stream.
21.7.1 Options
write_id3v2 bool
Enable to write ID3v2.4 tags at the start of the stream. Default is
disabled.
write_apetag bool
Enable to write APE tags at the end of the stream. Default is
disabled.
write_mpeg2 bool
Enable to set MPEG version bit in the ADTS frame header to 1 which
indicates MPEG-2. Default is 0, which indicates MPEG-4.
21.8 aea
MD STUDIO audio muxer.
This muxer accepts a single ATRAC1 audio stream with either one or two channels
and a sample rate of 44100Hz.
As AEA supports storing the track title, this muxer will also write
the title from stream’s metadata to the container.
21.9 aiff
Audio Interchange File Format muxer.
21.9.1 Options
write_id3v2 bool
Enable ID3v2 tags writing when set to 1. Default is 0 (disabled).
id3v2_version bool
Select ID3v2 version to write. Currently only version 3 and 4 (aka.
ID3v2.3 and ID3v2.4) are supported. The default is version 4.
21.10 alp
High Voltage Software’s Lego Racers game audio muxer.
It accepts a single ADPCM_IMA_ALP stream with no more than 2 channels
and a sample rate not greater than 44100 Hz.
Extensions: tun, pcm
21.10.1 Options
type type
Set file type.
type accepts the following values:
‘tun’
Set file type as music. Must have a sample rate of 22050 Hz.
‘pcm’
Set file type as sfx.
‘auto’
Set file type as per output file extension. .pcm results in
type pcm else type tun is set. (default)
21.11 amr
3GPP AMR (Adaptive Multi-Rate) audio muxer.
It accepts a single audio stream containing an AMR NB stream.
21.12 amv
AMV (Actions Media Video) format muxer.
21.13 apm
Ubisoft Rayman 2 APM audio muxer.
It accepts a single ADPCM IMA APM audio stream.
21.14 apng
Animated Portable Network Graphics muxer.
It accepts a single APNG video stream.
21.14.1 Options
final_delay delay
Force a delay expressed in seconds after the last frame of each
repetition. Default value is 0.0.
plays repetitions
specify how many times to play the content, 0 causes an infinte
loop, with 1 there is no loop
21.14.2 Examples
Use ffmpeg to generate an APNG output with 2 repetitions,
and with a delay of half a second after the first repetition:
ffmpeg -i INPUT -final_delay 0.5 -plays 2 out.apng
21.15 argo_asf
Argonaut Games ASF audio muxer.
It accepts a single ADPCM audio stream.
21.15.1 Options
version_major version
override file major version, specified as an integer, default value is
2
version_minor version
override file minor version, specified as an integer, default value is
1
name name
Embed file name into file, if not specified use the output file
name. The name is truncated to 8 characters.
21.16 argo_cvg
Argonaut Games CVG audio muxer.
It accepts a single one-channel ADPCM 22050Hz audio stream.
The loop and reverb options set the corresponding
flags in the header which can be later retrieved to process the audio
stream accordingly.
21.16.1 Options
skip_rate_check bool
skip sample rate check (default is false)
loop bool
set loop flag (default is false)
reverb boolean
set reverb flag (default is true)
21.17 asf, asf_stream
Advanced / Active Systems (or Streaming) Format audio muxer.
The ‘asf_stream’ variant should be selected for streaming.
Note that Windows Media Audio (wma) and Windows Media Video (wmv) use this
muxer too.
21.17.1 Options
packet_size size
Set the muxer packet size as a number of bytes. By tuning this setting
you may reduce data fragmentation or muxer overhead depending on your
source. Default value is 3200, minimum is 100, maximum
is 64Ki.
21.18 ass
ASS/SSA (SubStation Alpha) subtitles muxer.
It accepts a single ASS subtitles stream.
21.18.1 Options
ignore_readorder bool
Write dialogue events immediately, even if they are out-of-order,
default is false, otherwise they are cached until the expected
time event is found.
21.19 ast
AST (Audio Stream) muxer.
This format is used to play audio on some Nintendo Wii games.
It accepts a single audio stream.
The loopstart and loopend options can be used to
define a section of the file to loop for players honoring such
options.
21.19.1 Options
loopstart start
Specify loop start position expressesd in milliseconds, from -1
to INT_MAX, in case -1 is set then no loop is specified
(default -1) and the loopend value is ignored.
loopend end
Specify loop end position expressed in milliseconds, from 0 to
INT_MAX, default is 0, in case 0 is set it
assumes the total stream duration.
21.20 au
SUN AU audio muxer.
It accepts a single audio stream.
21.21 avi
Audio Video Interleaved muxer.
AVI is a proprietary format developed by Microsoft, and later formally specified
through the Open DML specification.
Because of differences in players implementations, it might be required to set
some options to make sure that the generated output can be correctly played by
the target player.
21.21.1 Options
flipped_raw_rgb bool
If set to true, store positive height for raw RGB bitmaps, which
indicates bitmap is stored bottom-up. Note that this option does not flip the
bitmap which has to be done manually beforehand, e.g. by using the ‘vflip’
filter. Default is false and indicates bitmap is stored top down.
reserve_index_space size
Reserve the specified amount of bytes for the OpenDML master index of each
stream within the file header. By default additional master indexes are
embedded within the data packets if there is no space left in the first master
index and are linked together as a chain of indexes. This index structure can
cause problems for some use cases, e.g. third-party software strictly relying
on the OpenDML index specification or when file seeking is slow. Reserving
enough index space in the file header avoids these problems.
The required index space depends on the output file size and should be about 16
bytes per gigabyte. When this option is omitted or set to zero the necessary
index space is guessed.
Default value is 0.
write_channel_mask bool
Write the channel layout mask into the audio stream header.
This option is enabled by default. Disabling the channel mask can be useful in
specific scenarios, e.g. when merging multiple audio streams into one for
compatibility with software that only supports a single audio stream in AVI
(see (ffmpeg-filters)the "amerge" section in the ffmpeg-filters manual).
21.22 avif
AV1 (Alliance for Open Media Video codec 1) image format muxer.
This muxers stores images encoded using the AV1 codec.
It accepts one or two video streams. In case two video streams are
provided, the second one shall contain a single plane storing the
alpha mask.
In case more than one image is provided, the generated output is
considered an animated AVIF and the number of loops can be specified
with the loop option.
This is based on the specification by Alliance for Open Media at url
https://aomediacodec.github.io/av1-avif.
21.22.1 Options
loop count
number of times to loop an animated AVIF, 0 specify an infinite
loop, default is 0
movie_timescale timescale
Set the timescale written in the movie header box (mvhd).
Range is 1 to INT_MAX. Default is 1000.
21.23 avm2
ShockWave Flash (SWF) / ActionScript Virtual Machine 2 (AVM2) format muxer.
It accepts one audio stream, one video stream, or both.
21.24 bit
G.729 (.bit) file format muxer.
It accepts a single G.729 audio stream.
21.25 caf
Apple CAF (Core Audio Format) muxer.
It accepts a single audio stream.
21.26 codec2
Codec2 audio audio muxer.
It accepts a single codec2 audio stream.
21.27 chromaprint
Chromaprint fingerprinter muxers.
To enable compilation of this filter you need to configure FFmpeg with
--enable-chromaprint.
This muxer feeds audio data to the Chromaprint library, which
generates a fingerprint for the provided audio data. See:
https://acoustid.org/chromaprint
It takes a single signed native-endian 16-bit raw audio stream of at
most 2 channels.
21.27.1 Options
algorithm version
Select version of algorithm to fingerprint with. Range is 0 to
4. Version 3 enables silence detection. Default is 1.
fp_format format
Format to output the fingerprint as. Accepts the following options:
‘base64’
Base64 compressed fingerprint (default)
‘compressed’
Binary compressed fingerprint
‘raw’
Binary raw fingerprint
silence_threshold threshold
Threshold for detecting silence. Range is from -1 to
32767, where -1 disables silence detection. Silence
detection can only be used with version 3 of the algorithm.
Silence detection must be disabled for use with the AcoustID
service. Default is -1.
21.28 crc
CRC (Cyclic Redundancy Check) muxer.
This muxer computes and prints the Adler-32 CRC of all the input audio
and video frames. By default audio frames are converted to signed
16-bit raw audio and video frames to raw video before computing the
CRC.
The output of the muxer consists of a single line of the form:
CRC=0xCRC, where CRC is a hexadecimal number 0-padded to
8 digits containing the CRC for all the decoded input frames.
See also the framecrc muxer.
21.28.1 Examples
Use ffmpeg to compute the CRC of the input, and store it in
the file out.crc:
ffmpeg -i INPUT -f crc out.crc
Use ffmpeg to print the CRC to stdout with the command:
ffmpeg -i INPUT -f crc -
You can select the output format of each frame with ffmpeg by
specifying the audio and video codec and format. For example, to
compute the CRC of the input audio converted to PCM unsigned 8-bit
and the input video converted to MPEG-2 video, use the command:
ffmpeg -i INPUT -c:a pcm_u8 -c:v mpeg2video -f crc -
21.29 dash
Dynamic Adaptive Streaming over HTTP (DASH) muxer.
This muxer creates segments and manifest files according to the
MPEG-DASH standard ISO/IEC 23009-1:2014 and following standard
updates.
For more information see:
ISO DASH Specification: http://standards.iso.org/ittf/PubliclyAvailableStandards/c065274_ISO_IEC_23009-1_2014.zip
WebM DASH Specification: https://sites.google.com/a/webmproject.org/wiki/adaptive-streaming/webm-dash-specification
This muxer creates an MPD (Media Presentation Description) manifest
file and segment files for each stream. Segment files are placed in
the same directory of the MPD manifest file.
The segment filename might contain pre-defined identifiers used in the
manifest SegmentTemplate section as defined in section
5.3.9.4.4 of the standard.
Available identifiers are $RepresentationID$, $Number$,
$Bandwidth$, and $Time$. In addition to the standard
identifiers, an ffmpeg-specific $ext$ identifier is also
supported. When specified, ffmpeg will replace $ext$
in the file name with muxing format’s extensions such as mp4,
webm etc.
21.29.1 Options
adaptation_sets adaptation_sets
Assign streams to adaptation sets, specified in the MPD manifest
AdaptationSets section.
An adaptation set contains a set of one or more streams accessed as a
single subset, e.g. corresponding streams encoded at different size
selectable by the user depending on the available bandwidth, or to
different audio streams with a different language.
Each adaptation set is specified with the syntax:
id=index,streams=streams
where index must be a numerical index, and streams is a
sequence of ,-separated stream indices. Multiple adaptation
sets can be specified, separated by spaces.
To map all video (or audio) streams to an adaptation set, v (or
a) can be used as stream identifier instead of IDs.
When no assignment is defined, this defaults to an adaptation set for
each stream.
The following optional fields can also be specified:
descriptor
Define the descriptor as defined by ISO/IEC 23009-1:2014/Amd.2:2015.
For example:
<SupplementalProperty schemeIdUri=\"urn:mpeg:dash:srd:2014\" value=\"0,0,0,1,1,2,2\"/>
The descriptor string should be a self-closing XML tag.
frag_duration
Override the global fragment duration specified with the
frag_duration option.
frag_type
Override the global fragment type specified with the
frag_type option.
seg_duration
Override the global segment duration specified with the
seg_duration option.
trick_id
Mark an adaptation set as containing streams meant to be used for
Trick Mode for the referenced adaptation set.
A few examples of possible values for the adaptation_sets
option follow:
id=0,seg_duration=2,frag_duration=1,frag_type=duration,streams=v id=1,seg_duration=2,frag_type=none,streams=a
id=0,seg_duration=2,frag_type=none,streams=0 id=1,seg_duration=10,frag_type=none,trick_id=0,streams=1
dash_segment_type type
Set DASH segment files type.
Possible values:
‘auto’
The dash segment files format will be selected based on the stream
codec. This is the default mode.
‘mp4’
the dash segment files will be in ISOBMFF/MP4 format
‘webm’
the dash segment files will be in WebM format
extra_window_size size
Set the maximum number of segments kept outside of the manifest before
removing from disk.
format_options options_list
Set container format (mp4/webm) options using a :-separated list of
key=value parameters. Values containing : special characters must be
escaped.
frag_duration duration
Set the length in seconds of fragments within segments, fractional
value can also be set.
frag_type type
Set the type of interval for fragmentation.
Possible values:
‘auto’
set one fragment per segment
‘every_frame’
fragment at every frame
‘duration’
fragment at specific time intervals
‘pframes’
fragment at keyframes and following P-Frame reordering (Video only,
experimental)
global_sidx bool
Write global SIDX atom. Applicable only for single file, mp4
output, non-streaming mode.
hls_master_name file_name
HLS master playlist name. Default is master.m3u8.
hls_playlist bool
Generate HLS playlist files. The master playlist is generated with
filename specified by the hls_master_name option. One media
playlist file is generated for each stream with filenames
media_0.m3u8, media_1.m3u8, etc.
http_opts http_opts
Specify a list of :-separated key=value options to pass to the
underlying HTTP protocol. Applicable only for HTTP output.
http_persistent bool
Use persistent HTTP connections. Applicable only for HTTP output.
http_user_agent user_agent
Override User-Agent field in HTTP header. Applicable only for HTTP
output.
ignore_io_errors bool
Ignore IO errors during open and write. Useful for long-duration runs
with network output. This is disabled by default.
index_correction bool
Enable or disable segment index correction logic. Applicable only when
use_template is enabled and use_timeline is
disabled. This is disabled by default.
When enabled, the logic monitors the flow of segment indexes. If a
streams’s segment index value is not at the expected real time
position, then the logic corrects that index value.
Typically this logic is needed in live streaming use cases. The
network bandwidth fluctuations are common during long run
streaming. Each fluctuation can cause the segment indexes fall behind
the expected real time position.
init_seg_name init_name
DASH-templated name to use for the initialization segment. Default is
init-stream$RepresentationID$.$ext$. $ext$ is replaced
with the file name extension specific for the segment format.
ldash bool
Enable Low-latency Dash by constraining the presence and values of
some elements. This is disabled by default.
lhls bool
Enable Low-latency HLS (LHLS). Add #EXT-X-PREFETCH tag with
current segment’s URI. hls.js player folks are trying to standardize
an open LHLS spec. The draft spec is available at
https://github.com/video-dev/hlsjs-rfcs/blob/lhls-spec/proposals/0001-lhls.md.
This option tries to comply with the above open spec. It enables
streaming and hls_playlist options automatically.
This is an experimental feature.
Note: This is not Apple’s version LHLS. See
https://datatracker.ietf.org/doc/html/draft-pantos-hls-rfc8216bis
master_m3u8_publish_rate segment_intervals_count
Publish master playlist repeatedly every after specified number of
segment intervals.
max_playback_rate rate
Set the maximum playback rate indicated as appropriate for the
purposes of automatically adjusting playback latency and buffer
occupancy during normal playback by clients.
media_seg_name segment_name
DASH-templated name to use for the media segments. Default is
chunk-stream$RepresentationID$-$Number%05d$.$ext$. $ext$
is replaced with the file name extension specific for the segment
format.
method method
Use the given HTTP method to create output files. Generally set to PUT
or POST.
min_playback_rate rate
Set the minimum playback rate indicated as appropriate for the
purposes of automatically adjusting playback latency and buffer
occupancy during normal playback by clients.
mpd_profile flags
Set one or more MPD manifest profiles.
Possible values:
‘dash’
MPEG-DASH ISO Base media file format live profile
‘dvb_dash’
DVB-DASH profile
Default value is dash.
remove_at_exit bool
Enable or disable removal of all segments when finished. This is
disabled by default.
seg_duration duration
Set the segment length in seconds (fractional value can be set). The
value is treated as average segment duration when the
use_template option is enabled and the use_timeline
option is disabled and as minimum segment duration for all the other
use cases.
Default value is 5.
single_file bool
Enable or disable storing all segments in one file, accessed using
byte ranges. This is disabled by default.
The name of the single file can be specified with the
single_file_name option, if not specified assume the basename
of the manifest file with the output format extension.
single_file_name file_name
DASH-templated name to use for the manifest baseURL
element. Imply that the single_file option is set to
true. In the template, $ext$ is replaced with the file
name extension specific for the segment format.
streaming bool
Enable or disable chunk streaming mode of output. In chunk streaming
mode, each frame will be a moof fragment which forms a
chunk. This is disabled by default.
target_latency target_latency
Set an intended target latency in seconds for serving (fractional
value can be set). Applicable only when the streaming and
write_prft options are enabled. This is an informative fields
clients can use to measure the latency of the service.
timeout timeout
Set timeout for socket I/O operations expressed in seconds (fractional
value can be set). Applicable only for HTTP output.
update_period period
Set the MPD update period, for dynamic content. The unit is
second. If set to 0, the period is automatically computed.
Default value is 0.
use_template bool
Enable or disable use of SegmentTemplate instead of
SegmentList in the manifest. This is enabled by default.
use_timeline bool
Enable or disable use of SegmentTimeline within the
SegmentTemplate manifest section. This is enabled by default.
utc_timing_url url
URL of the page that will return the UTC timestamp in ISO
format, for example https://time.akamai.com/?iso
window_size size
Set the maximum number of segments kept in the manifest, discard the
oldest one. This is useful for live streaming.
If the value is 0, all segments are kept in the
manifest. Default value is 0.
write_prft write_prft
Write Producer Reference Time elements on supported streams. This also
enables writing prft boxes in the underlying muxer. Applicable only
when the utc_url option is enabled. It is set to auto by
default, in which case the muxer will attempt to enable it only in
modes that require it.
21.29.2 Example
Generate a DASH output reading from an input source in realtime using
ffmpeg.
Two multimedia streams are generated from the input file, both
containing a video stream encoded through ‘libx264’, and an audio
stream encoded with ‘libfdk_aac’. The first multimedia stream
contains video with a bitrate of 800k and audio at the default rate,
the second with video scaled to 320x170 pixels at 300k and audio
resampled at 22005 Hz.
The window_size option keeps only the latest 5 segments with
the default duration of 5 seconds.
ffmpeg -re -i <input> -map 0 -map 0 -c:a libfdk_aac -c:v libx264 \
-b:v:0 800k -profile:v:0 main \
-b:v:1 300k -s:v:1 320x170 -profile:v:1 baseline -ar:a:1 22050 \
-bf 1 -keyint_min 120 -g 120 -sc_threshold 0 -b_strategy 0 \
-use_timeline 1 -use_template 1 -window_size 5 \
-adaptation_sets "id=0,streams=v id=1,streams=a" \
-f dash /path/to/out.mpd
21.30 daud
D-Cinema audio muxer.
It accepts a single 6-channels audio stream resampled at 96000 Hz
encoded with the ‘pcm_24daud’ codec.
21.30.1 Example
Use ffmpeg to mux input audio to a ‘5.1’ channel layout
resampled at 96000Hz:
ffmpeg -i INPUT -af aresample=96000,pan=5.1 slow.302
For ffmpeg versions before 7.0 you might have to use the ‘asetnsamples’
filter to limit the muxed packet size, because this format does not support
muxing packets larger than 65535 bytes (3640 samples). For newer ffmpeg
versions audio is automatically packetized to 36000 byte (2000 sample) packets.
21.31 dv
DV (Digital Video) muxer.
It accepts exactly one ‘dvvideo’ video stream and at most two
‘pcm_s16’ audio streams. More constraints are defined by the
property of the video, which must correspond to a DV video supported
profile, and on the framerate.
21.31.1 Example
Use ffmpeg to convert the input:
ffmpeg -i INPUT -s:v 720x480 -pix_fmt yuv411p -r 29.97 -ac 2 -ar 48000 -y out.dv
21.32 ffmetadata
FFmpeg metadata muxer.
This muxer writes the streams metadata in the ‘ffmetadata’
format.
See (ffmpeg-formats)the Metadata chapter for
information about the format.
21.32.1 Example
Use ffmpeg to extract metadata from an input file to a metadata.ffmeta
file in ‘ffmetadata’ format:
ffmpeg -i INPUT -f ffmetadata metadata.ffmeta
21.33 fifo
FIFO (First-In First-Out) muxer.
The ‘fifo’ pseudo-muxer allows the separation of encoding and
muxing by using a first-in-first-out queue and running the actual muxer
in a separate thread.
This is especially useful in combination with
the tee muxer and can be used to send data to several
destinations with different reliability/writing speed/latency.
The target muxer is either selected from the output name or specified
through the fifo_format option.
The behavior of the ‘fifo’ muxer if the queue fills up or if the
output fails (e.g. if a packet cannot be written to the output) is
selectable:
Output can be transparently restarted with configurable delay between
retries based on real time or time of the processed stream.
Encoding can be blocked during temporary failure, or continue transparently
dropping packets in case the FIFO queue fills up.
API users should be aware that callback functions
(interrupt_callback, io_open and io_close) used
within its AVFormatContext must be thread-safe.
21.33.1 Options
attempt_recovery bool
If failure occurs, attempt to recover the output. This is especially
useful when used with network output, since it makes it possible to
restart streaming transparently. By default this option is set to
false.
drop_pkts_on_overflow bool
If set to true, in case the fifo queue fills up, packets will
be dropped rather than blocking the encoder. This makes it possible to
continue streaming without delaying the input, at the cost of omitting
part of the stream. By default this option is set to false, so in
such cases the encoder will be blocked until the muxer processes some
of the packets and none of them is lost.
fifo_format format_name
Specify the format name. Useful if it cannot be guessed from the
output name suffix.
format_opts options
Specify format options for the underlying muxer. Muxer options can be
specified as a list of key=value pairs separated by ’:’.
max_recovery_attempts count
Set maximum number of successive unsuccessful recovery attempts after
which the output fails permanently. By default this option is set to
0 (unlimited).
queue_size size
Specify size of the queue as a number of packets. Default value is
60.
recover_any_error bool
If set to true, recovery will be attempted regardless of type
of the error causing the failure. By default this option is set to
false and in case of certain (usually permanent) errors the
recovery is not attempted even when the attempt_recovery
option is set to true.
recovery_wait_streamtime bool
If set to false, the real time is used when waiting for the
recovery attempt (i.e. the recovery will be attempted after the time
specified by the recovery_wait_time option).
If set to true, the time of the processed stream is taken into
account instead (i.e. the recovery will be attempted after discarding
the packets corresponding to the recovery_wait_time option).
By default this option is set to false.
recovery_wait_time duration
Specify waiting time in seconds before the next recovery attempt after
previous unsuccessful recovery attempt. Default value is 5.
restart_with_keyframe bool
Specify whether to wait for the keyframe after recovering from
queue overflow or failure. This option is set to false by default.
timeshift duration
Buffer the specified amount of packets and delay writing the
output. Note that the value of the queue_size option must be
big enough to store the packets for timeshift. At the end of the input
the fifo buffer is flushed at realtime speed.
21.33.2 Example
Use ffmpeg to stream to an RTMP server, continue processing
the stream at real-time rate even in case of temporary failure
(network outage) and attempt to recover streaming every second
indefinitely:
ffmpeg -re -i ... -c:v libx264 -c:a aac -f fifo -fifo_format flv \
-drop_pkts_on_overflow 1 -attempt_recovery 1 -recovery_wait_time 1 \
-map 0:v -map 0:a rtmp://example.com/live/stream_name
21.34 film_cpk
Sega film (.cpk) muxer.
This format was used as internal format for several Sega games.
For more information regarding the Sega film file format, visit
http://wiki.multimedia.cx/index.php?title=Sega_FILM.
It accepts at maximum one ‘cinepak’ or raw video stream, and at
maximum one audio stream.
21.35 filmstrip
Adobe Filmstrip muxer.
This format is used by several Adobe tools to store a generated filmstrip export. It
accepts a single raw video stream.
21.36 fits
Flexible Image Transport System (FITS) muxer.
This image format is used to store astronomical data.
For more information regarding the format, visit
https://fits.gsfc.nasa.gov.
21.37 flac
Raw FLAC audio muxer.
This muxer accepts exactly one FLAC audio stream. Additionally, it is possible to add
images with disposition ‘attached_pic’.
21.37.1 Options
write_header bool
write the file header if set to true, default is true
21.37.2 Example
Use ffmpeg to store the audio stream from an input file,
together with several pictures used with ‘attached_pic’
disposition:
ffmpeg -i INPUT -i pic1.png -i pic2.jpg -map 0:a -map 1 -map 2 -disposition:v attached_pic OUTPUT
21.38 flv
Adobe Flash Video Format muxer.
21.38.1 Options
flvflags flags
Possible values:
‘aac_seq_header_detect’
Place AAC sequence header based on audio stream data.
‘no_sequence_end’
Disable sequence end tag.
‘no_metadata’
Disable metadata tag.
‘no_duration_filesize’
Disable duration and filesize in metadata when they are equal to zero
at the end of stream. (Be used to non-seekable living stream).
‘add_keyframe_index’
Used to facilitate seeking; particularly for HTTP pseudo streaming.
21.39 framecrc
Per-packet CRC (Cyclic Redundancy Check) testing format.
This muxer computes and prints the Adler-32 CRC for each audio
and video packet. By default audio frames are converted to signed
16-bit raw audio and video frames to raw video before computing the
CRC.
The output of the muxer consists of a line for each audio and video
packet of the form:
stream_index, packet_dts, packet_pts, packet_duration, packet_size, 0xCRC
CRC is a hexadecimal number 0-padded to 8 digits containing the
CRC of the packet.
21.39.1 Examples
For example to compute the CRC of the audio and video frames in
INPUT, converted to raw audio and video packets, and store it
in the file out.crc:
ffmpeg -i INPUT -f framecrc out.crc
To print the information to stdout, use the command:
ffmpeg -i INPUT -f framecrc -
With ffmpeg, you can select the output format to which the
audio and video frames are encoded before computing the CRC for each
packet by specifying the audio and video codec. For example, to
compute the CRC of each decoded input audio frame converted to PCM
unsigned 8-bit and of each decoded input video frame converted to
MPEG-2 video, use the command:
ffmpeg -i INPUT -c:a pcm_u8 -c:v mpeg2video -f framecrc -
See also the crc muxer.
21.40 framehash
Per-packet hash testing format.
This muxer computes and prints a cryptographic hash for each audio
and video packet. This can be used for packet-by-packet equality
checks without having to individually do a binary comparison on each.
By default audio frames are converted to signed 16-bit raw audio and
video frames to raw video before computing the hash, but the output
of explicit conversions to other codecs can also be used. It uses the
SHA-256 cryptographic hash function by default, but supports several
other algorithms.
The output of the muxer consists of a line for each audio and video
packet of the form:
stream_index, packet_dts, packet_pts, packet_duration, packet_size, hash
hash is a hexadecimal number representing the computed hash
for the packet.
hash algorithm
Use the cryptographic hash function specified by the string algorithm.
Supported values include MD5, murmur3, RIPEMD128,
RIPEMD160, RIPEMD256, RIPEMD320, SHA160,
SHA224, SHA256 (default), SHA512/224, SHA512/256,
SHA384, SHA512, CRC32 and adler32.
21.40.1 Examples
To compute the SHA-256 hash of the audio and video frames in INPUT,
converted to raw audio and video packets, and store it in the file
out.sha256:
ffmpeg -i INPUT -f framehash out.sha256
To print the information to stdout, using the MD5 hash function, use
the command:
ffmpeg -i INPUT -f framehash -hash md5 -
See also the hash muxer.
21.41 framemd5
Per-packet MD5 testing format.
This is a variant of the framehash muxer. Unlike that muxer,
it defaults to using the MD5 hash function.
21.41.1 Examples
To compute the MD5 hash of the audio and video frames in INPUT,
converted to raw audio and video packets, and store it in the file
out.md5:
ffmpeg -i INPUT -f framemd5 out.md5
To print the information to stdout, use the command:
ffmpeg -i INPUT -f framemd5 -
See also the framehash and md5 muxers.
21.42 gif
Animated GIF muxer.
Note that the GIF format has a very large time base: the delay between two frames can
therefore not be smaller than one centi second.
21.42.1 Options
loop bool
Set the number of times to loop the output. Use -1 for no loop, 0
for looping indefinitely (default).
final_delay delay
Force the delay (expressed in centiseconds) after the last frame. Each frame
ends with a delay until the next frame. The default is -1, which is a
special value to tell the muxer to re-use the previous delay. In case of a
loop, you might want to customize this value to mark a pause for instance.
21.42.2 Example
Encode a gif looping 10 times, with a 5 seconds delay between
the loops:
ffmpeg -i INPUT -loop 10 -final_delay 500 out.gif
Note 1: if you wish to extract the frames into separate GIF files, you need to
force the image2 muxer:
ffmpeg -i INPUT -c:v gif -f image2 "out%d.gif"
21.43 gxf
General eXchange Format (GXF) muxer.
GXF was developed by Grass Valley Group, then standardized by SMPTE as SMPTE
360M and was extended in SMPTE RDD 14-2007 to include high-definition video
resolutions.
It accepts at most one video stream with codec ‘mjpeg’, or
‘mpeg1video’, or ‘mpeg2video’, or ‘dvvideo’ with resolution
‘512x480’ or ‘608x576’, and several audio streams with rate 48000Hz
and codec ‘pcm16_le’.
21.44 hash
Hash testing format.
This muxer computes and prints a cryptographic hash of all the input
audio and video frames. This can be used for equality checks without
having to do a complete binary comparison.
By default audio frames are converted to signed 16-bit raw audio and
video frames to raw video before computing the hash, but the output
of explicit conversions to other codecs can also be used. Timestamps
are ignored. It uses the SHA-256 cryptographic hash function by default,
but supports several other algorithms.
The output of the muxer consists of a single line of the form:
algo=hash, where algo is a short string representing
the hash function used, and hash is a hexadecimal number
representing the computed hash.
hash algorithm
Use the cryptographic hash function specified by the string algorithm.
Supported values include MD5, murmur3, RIPEMD128,
RIPEMD160, RIPEMD256, RIPEMD320, SHA160,
SHA224, SHA256 (default), SHA512/224, SHA512/256,
SHA384, SHA512, CRC32 and adler32.
21.44.1 Examples
To compute the SHA-256 hash of the input converted to raw audio and
video, and store it in the file out.sha256:
ffmpeg -i INPUT -f hash out.sha256
To print an MD5 hash to stdout use the command:
ffmpeg -i INPUT -f hash -hash md5 -
See also the framehash muxer.
21.45 hds
HTTP Dynamic Streaming (HDS) muxer.
HTTP dynamic streaming, or HDS, is an adaptive bitrate streaming method
developed by Adobe. HDS delivers MP4 video content over HTTP connections. HDS
can be used for on-demand streaming or live streaming.
This muxer creates an .f4m (Adobe Flash Media Manifest File) manifest, an .abst
(Adobe Bootstrap File) for each stream, and segment files in a directory
specified as the output.
These needs to be accessed by an HDS player throuhg HTTPS for it to be able to
perform playback on the generated stream.
21.45.1 Options
extra_window_size int
number of fragments kept outside of the manifest before removing from disk
min_frag_duration microseconds
minimum fragment duration (in microseconds), default value is 1 second
(10000000)
remove_at_exit bool
remove all fragments when finished when set to true
window_size int
number of fragments kept in the manifest, if set to a value different from
0. By default all segments are kept in the output directory.
21.45.2 Example
Use ffmpeg to generate HDS files to the output.hds directory in
real-time rate:
ffmpeg -re -i INPUT -f hds -b:v 200k output.hds
21.46 hls
Apple HTTP Live Streaming muxer that segments MPEG-TS according to
the HTTP Live Streaming (HLS) specification.
It creates a playlist file, and one or more segment files. The output filename
specifies the playlist filename.
By default, the muxer creates a file for each segment produced. These files
have the same name as the playlist, followed by a sequential number and a
.ts extension.
Make sure to require a closed GOP when encoding and to set the GOP
size to fit your segment time constraint.
For example, to convert an input file with ffmpeg:
ffmpeg -i in.mkv -c:v h264 -flags +cgop -g 30 -hls_time 1 out.m3u8
This example will produce the playlist, out.m3u8, and segment files:
out0.ts, out1.ts, out2.ts, etc.
See also the segment muxer, which provides a more generic and
flexible implementation of a segmenter, and can be used to perform HLS
segmentation.
21.46.1 Options
hls_init_time duration
Set the initial target segment length. Default value is 0.
duration must be a time duration specification,
see (ffmpeg-utils)the Time duration section in the ffmpeg-utils(1) manual.
Segment will be cut on the next key frame after this time has passed on the
first m3u8 list. After the initial playlist is filled, ffmpeg will cut
segments at duration equal to hls_time.
hls_time duration
Set the target segment length. Default value is 2.
duration must be a time duration specification,
see (ffmpeg-utils)the Time duration section in the ffmpeg-utils(1) manual.
Segment will be cut on the next key frame after this time has passed.
hls_list_size size
Set the maximum number of playlist entries. If set to 0 the list file
will contain all the segments. Default value is 5.
hls_delete_threshold size
Set the number of unreferenced segments to keep on disk before hls_flags delete_segments
deletes them. Increase this to allow continue clients to download segments which
were recently referenced in the playlist. Default value is 1, meaning segments older than
hls_list_size+1 will be deleted.
hls_start_number_source source
Start the playlist sequence number (#EXT-X-MEDIA-SEQUENCE) according to the specified source.
Unless hls_flags single_file is set, it also specifies source of starting sequence numbers of
segment and subtitle filenames. In any case, if hls_flags append_list
is set and read playlist sequence number is greater than the specified start sequence number,
then that value will be used as start value.
It accepts the following values:
generic (default)
Set the start numbers according to the start_number option value.
epoch
Set the start number as the seconds since epoch (1970-01-01 00:00:00).
epoch_us
Set the start number as the microseconds since epoch (1970-01-01 00:00:00).
datetime
Set the start number based on the current date/time as YYYYmmddHHMMSS. e.g. 20161231235759.
start_number number
Start the playlist sequence number (#EXT-X-MEDIA-SEQUENCE) from the specified number
when hls_start_number_source value is generic. (This is the default case.)
Unless hls_flags single_file is set, it also specifies starting sequence numbers of segment and subtitle filenames.
Default value is 0.
hls_allow_cache bool
Explicitly set whether the client MAY (1) or MUST NOT (0) cache media segments.
hls_base_url baseurl
Append baseurl to every entry in the playlist.
Useful to generate playlists with absolute paths.
Note that the playlist sequence number must be unique for each segment
and it is not to be confused with the segment filename sequence number
which can be cyclic, for example if the wrap option is
specified.
hls_segment_filename filename
Set the segment filename. Unless the hls_flags option is set with
‘single_file’, filename is used as a string format with the
segment number appended.
For example:
ffmpeg -i in.nut -hls_segment_filename 'file%03d.ts' out.m3u8
will produce the playlist, out.m3u8, and segment files:
file000.ts, file001.ts, file002.ts, etc.
filename may contain a full path or relative path specification,
but only the file name part without any path will be contained in the m3u8 segment list.
Should a relative path be specified, the path of the created segment
files will be relative to the current working directory.
When strftime_mkdir is set, the whole expanded value of filename will be written into the m3u8 segment list.
When var_stream_map is set with two or more variant streams, the
filename pattern must contain the string "%v", and this string will be
expanded to the position of variant stream index in the generated segment file
names.
For example:
ffmpeg -i in.ts -b:v:0 1000k -b:v:1 256k -b:a:0 64k -b:a:1 32k \
-map 0:v -map 0:a -map 0:v -map 0:a -f hls -var_stream_map "v:0,a:0 v:1,a:1" \
-hls_segment_filename 'file_%v_%03d.ts' out_%v.m3u8
will produce the playlists segment file sets:
file_0_000.ts, file_0_001.ts, file_0_002.ts, etc. and
file_1_000.ts, file_1_001.ts, file_1_002.ts, etc.
The string "%v" may be present in the filename or in the last directory name
containing the file, but only in one of them. (Additionally, %v may appear multiple times in the last
sub-directory or filename.) If the string %v is present in the directory name, then
sub-directories are created after expanding the directory name pattern. This
enables creation of segments corresponding to different variant streams in
subdirectories.
For example:
ffmpeg -i in.ts -b:v:0 1000k -b:v:1 256k -b:a:0 64k -b:a:1 32k \
-map 0:v -map 0:a -map 0:v -map 0:a -f hls -var_stream_map "v:0,a:0 v:1,a:1" \
-hls_segment_filename 'vs%v/file_%03d.ts' vs%v/out.m3u8
will produce the playlists segment file sets:
vs0/file_000.ts, vs0/file_001.ts, vs0/file_002.ts, etc. and
vs1/file_000.ts, vs1/file_001.ts, vs1/file_002.ts, etc.
strftime bool
Use strftime() on filename to expand the segment filename with
localtime. The segment number is also available in this mode, but to use it,
you need to set ‘second_level_segment_index’ in the hls_flag and
%%d will be the specifier.
For example:
ffmpeg -i in.nut -strftime 1 -hls_segment_filename 'file-%Y%m%d-%s.ts' out.m3u8
will produce the playlist, out.m3u8, and segment files:
file-20160215-1455569023.ts, file-20160215-1455569024.ts, etc.
Note: On some systems/environments, the %s specifier is not
available. See strftime() documentation.
For example:
ffmpeg -i in.nut -strftime 1 -hls_flags second_level_segment_index -hls_segment_filename 'file-%Y%m%d-%%04d.ts' out.m3u8
will produce the playlist, out.m3u8, and segment files:
file-20160215-0001.ts, file-20160215-0002.ts, etc.
strftime_mkdir bool
Used together with strftime, it will create all subdirectories which
are present in the expanded values of option hls_segment_filename.
For example:
ffmpeg -i in.nut -strftime 1 -strftime_mkdir 1 -hls_segment_filename '%Y%m%d/file-%Y%m%d-%s.ts' out.m3u8
will create a directory 201560215 (if it does not exist), and then
produce the playlist, out.m3u8, and segment files:
20160215/file-20160215-1455569023.ts,
20160215/file-20160215-1455569024.ts, etc.
For example:
ffmpeg -i in.nut -strftime 1 -strftime_mkdir 1 -hls_segment_filename '%Y/%m/%d/file-%Y%m%d-%s.ts' out.m3u8
will create a directory hierarchy 2016/02/15 (if any of them do not
exist), and then produce the playlist, out.m3u8, and segment files:
2016/02/15/file-20160215-1455569023.ts,
2016/02/15/file-20160215-1455569024.ts, etc.
hls_segment_options options_list
Set output format options using a :-separated list of key=value
parameters. Values containing : special characters must be
escaped.
hls_key_info_file key_info_file
Use the information in key_info_file for segment encryption. The first
line of key_info_file specifies the key URI written to the playlist. The
key URL is used to access the encryption key during playback. The second line
specifies the path to the key file used to obtain the key during the encryption
process. The key file is read as a single packed array of 16 octets in binary
format. The optional third line specifies the initialization vector (IV) as a
hexadecimal string to be used instead of the segment sequence number (default)
for encryption. Changes to key_info_file will result in segment
encryption with the new key/IV and an entry in the playlist for the new key
URI/IV if hls_flags periodic_rekey is enabled.
Key info file format:
key URI
key file path
IV (optional)
Example key URIs:
http://server/file.key
/path/to/file.key
file.key
Example key file paths:
file.key
/path/to/file.key
Example IV:
0123456789ABCDEF0123456789ABCDEF
Key info file example:
http://server/file.key
/path/to/file.key
0123456789ABCDEF0123456789ABCDEF
Example shell script:
#!/bin/sh
BASE_URL=${1:-'.'}
openssl rand 16 > file.key
echo $BASE_URL/file.key > file.keyinfo
echo file.key >> file.keyinfo
echo $(openssl rand -hex 16) >> file.keyinfo
ffmpeg -f lavfi -re -i testsrc -c:v h264 -hls_flags delete_segments \
-hls_key_info_file file.keyinfo out.m3u8
hls_enc bool
Enable (1) or disable (0) the AES128 encryption.
When enabled every segment generated is encrypted and the encryption key
is saved as playlist name.key.
hls_enc_key key
Specify a 16-octet key to encrypt the segments, by default it is randomly
generated.
hls_enc_key_url keyurl
If set, keyurl is prepended instead of baseurl to the key filename
in the playlist.
hls_enc_iv iv
Specify the 16-octet initialization vector for every segment instead of the
autogenerated ones.
hls_segment_type flags
Possible values:
‘mpegts’
Output segment files in MPEG-2 Transport Stream format. This is
compatible with all HLS versions.
‘fmp4’
Output segment files in fragmented MP4 format, similar to MPEG-DASH.
fmp4 files may be used in HLS version 7 and above.
hls_fmp4_init_filename filename
Set filename for the fragment files header file, default filename is init.mp4.
When strftime is enabled, filename is expanded to the segment filename with localtime.
For example:
ffmpeg -i in.nut -hls_segment_type fmp4 -strftime 1 -hls_fmp4_init_filename "%s_init.mp4" out.m3u8
will produce init like this 1602678741_init.mp4.
hls_fmp4_init_resend bool
Resend init file after m3u8 file refresh every time, default is 0.
When var_stream_map is set with two or more variant streams, the
filename pattern must contain the string "%v", this string specifies
the position of variant stream index in the generated init file names.
The string "%v" may be present in the filename or in the last directory name
containing the file. If the string is present in the directory name, then
sub-directories are created after expanding the directory name pattern. This
enables creation of init files corresponding to different variant streams in
subdirectories.
hls_flags flags
Possible values:
‘single_file’
If this flag is set, the muxer will store all segments in a single MPEG-TS
file, and will use byte ranges in the playlist. HLS playlists generated with
this way will have the version number 4.
For example:
ffmpeg -i in.nut -hls_flags single_file out.m3u8
will produce the playlist, out.m3u8, and a single segment file,
out.ts.
‘delete_segments’
Segment files removed from the playlist are deleted after a period of time
equal to the duration of the segment plus the duration of the playlist.
‘append_list’
Append new segments into the end of old segment list,
and remove the #EXT-X-ENDLIST from the old segment list.
‘round_durations’
Round the duration info in the playlist file segment info to integer
values, instead of using floating point.
If there are no other features requiring higher HLS versions be used,
then this will allow ffmpeg to output a HLS version 2 m3u8.
‘discont_start’
Add the #EXT-X-DISCONTINUITY tag to the playlist, before the
first segment’s information.
‘omit_endlist’
Do not append the EXT-X-ENDLIST tag at the end of the playlist.
‘periodic_rekey’
The file specified by hls_key_info_file will be checked periodically and
detect updates to the encryption info. Be sure to replace this file atomically,
including the file containing the AES encryption key.
‘independent_segments’
Add the #EXT-X-INDEPENDENT-SEGMENTS tag to playlists that has video segments
and when all the segments of that playlist are guaranteed to start with a key frame.
‘iframes_only’
Add the #EXT-X-I-FRAMES-ONLY tag to playlists that has video segments
and can play only I-frames in the #EXT-X-BYTERANGE mode.
‘split_by_time’
Allow segments to start on frames other than key frames. This improves
behavior on some players when the time between key frames is inconsistent,
but may make things worse on others, and can cause some oddities during
seeking. This flag should be used with the hls_time option.
‘program_date_time’
Generate EXT-X-PROGRAM-DATE-TIME tags.
‘second_level_segment_index’
Make it possible to use segment indexes as %%d in the
hls_segment_filename option expression besides date/time values when
strftime option is on. To get fixed width numbers with trailing zeroes, %%0xd format
is available where x is the required width.
‘second_level_segment_size’
Make it possible to use segment sizes (counted in bytes) as %%s in
hls_segment_filename option expression besides date/time values when
strftime is on. To get fixed width numbers with trailing zeroes, %%0xs format
is available where x is the required width.
‘second_level_segment_duration’
Make it possible to use segment duration (calculated in microseconds) as %%t in
hls_segment_filename option expression besides date/time values when
strftime is on. To get fixed width numbers with trailing zeroes, %%0xt format
is available where x is the required width.
For example:
ffmpeg -i sample.mpeg \
-f hls -hls_time 3 -hls_list_size 5 \
-hls_flags second_level_segment_index+second_level_segment_size+second_level_segment_duration \
-strftime 1 -strftime_mkdir 1 -hls_segment_filename "segment_%Y%m%d%H%M%S_%%04d_%%08s_%%013t.ts" stream.m3u8
will produce segments like this:
segment_20170102194334_0003_00122200_0000003000000.ts, segment_20170102194334_0004_00120072_0000003000000.ts etc.
‘temp_file’
Write segment data to filename.tmp and rename to filename only once the
segment is complete.
A webserver serving up segments can be configured to reject requests to *.tmp to
prevent access to in-progress segments before they have been added to the m3u8
playlist.
This flag also affects how m3u8 playlist files are created. If this flag is set,
all playlist files will be written into a temporary file and renamed after they
are complete, similarly as segments are handled. But playlists with file
protocol and with hls_playlist_type type other than ‘vod’ are
always written into a temporary file regardless of this flag.
Master playlist files specified with master_pl_name, if any, with
file protocol, are always written into temporary file regardless of this
flag if master_pl_publish_rate value is other than zero.
hls_playlist_type type
If type is ‘event’, emit #EXT-X-PLAYLIST-TYPE:EVENT in the m3u8
header. This forces hls_list_size to 0; the playlist can only be
appended to.
If type is ‘vod’, emit #EXT-X-PLAYLIST-TYPE:VOD in the m3u8
header. This forces hls_list_size to 0; the playlist must not change.
method method
Use the given HTTP method to create the hls files.
For example:
ffmpeg -re -i in.ts -f hls -method PUT http://example.com/live/out.m3u8
will upload all the mpegts segment files to the HTTP server using the HTTP PUT
method, and update the m3u8 files every refresh times using the same
method. Note that the HTTP server must support the given method for uploading
files.
http_user_agent agent
Override User-Agent field in HTTP header. Applicable only for HTTP output.
var_stream_map stream_map
Specify a map string defining how to group the audio, video and subtitle streams
into different variant streams. The variant stream groups are separated by
space.
Expected string format is like this "a:0,v:0 a:1,v:1 ....". Here a:, v:, s: are
the keys to specify audio, video and subtitle streams respectively.
Allowed values are 0 to 9 (limited just based on practical usage).
When there are two or more variant streams, the output filename pattern must
contain the string "%v": this string specifies the position of variant stream
index in the output media playlist filenames. The string "%v" may be present in
the filename or in the last directory name containing the file. If the string is
present in the directory name, then sub-directories are created after expanding
the directory name pattern. This enables creation of variant streams in
subdirectories.
A few examples follow.
Create two hls variant streams. The first variant stream will contain video
stream of bitrate 1000k and audio stream of bitrate 64k and the second variant
stream will contain video stream of bitrate 256k and audio stream of bitrate
32k. Here, two media playlist with file names out_0.m3u8 and
out_1.m3u8 will be created.
ffmpeg -re -i in.ts -b:v:0 1000k -b:v:1 256k -b:a:0 64k -b:a:1 32k \
-map 0:v -map 0:a -map 0:v -map 0:a -f hls -var_stream_map "v:0,a:0 v:1,a:1" \
http://example.com/live/out_%v.m3u8
If you want something meaningful text instead of indexes in result names, you
may specify names for each or some of the variants. The following example will
create two hls variant streams as in the previous one. But here, the two media
playlist with file names out_my_hd.m3u8 and out_my_sd.m3u8 will be
created.
ffmpeg -re -i in.ts -b:v:0 1000k -b:v:1 256k -b:a:0 64k -b:a:1 32k \
-map 0:v -map 0:a -map 0:v -map 0:a -f hls -var_stream_map "v:0,a:0,name:my_hd v:1,a:1,name:my_sd" \
http://example.com/live/out_%v.m3u8
Create three hls variant streams. The first variant stream will be a video only
stream with video bitrate 1000k, the second variant stream will be an audio only
stream with bitrate 64k and the third variant stream will be a video only stream
with bitrate 256k. Here, three media playlist with file names out_0.m3u8,
out_1.m3u8 and out_2.m3u8 will be created.
ffmpeg -re -i in.ts -b:v:0 1000k -b:v:1 256k -b:a:0 64k \
-map 0:v -map 0:a -map 0:v -f hls -var_stream_map "v:0 a:0 v:1" \
http://example.com/live/out_%v.m3u8
Create the variant streams in subdirectories. Here, the first media playlist is
created at http://example.com/live/vs_0/out.m3u8 and the second one at
http://example.com/live/vs_1/out.m3u8.
ffmpeg -re -i in.ts -b:v:0 1000k -b:v:1 256k -b:a:0 64k -b:a:1 32k \
-map 0:v -map 0:a -map 0:v -map 0:a -f hls -var_stream_map "v:0,a:0 v:1,a:1" \
http://example.com/live/vs_%v/out.m3u8
Create two audio only and two video only variant streams. In addition to the
#EXT-X-STREAM-INF tag for each variant stream in the master playlist, the
#EXT-X-MEDIA tag is also added for the two audio only variant streams and
they are mapped to the two video only variant streams with audio group names
’aud_low’ and ’aud_high’.
By default, a single hls variant containing all the encoded streams is created.
ffmpeg -re -i in.ts -b:a:0 32k -b:a:1 64k -b:v:0 1000k -b:v:1 3000k  \
-map 0:a -map 0:a -map 0:v -map 0:v -f hls \
-var_stream_map "a:0,agroup:aud_low a:1,agroup:aud_high v:0,agroup:aud_low v:1,agroup:aud_high" \
-master_pl_name master.m3u8 \
http://example.com/live/out_%v.m3u8
Create two audio only and one video only variant streams. In addition to the
#EXT-X-STREAM-INF tag for each variant stream in the master playlist, the
#EXT-X-MEDIA tag is also added for the two audio only variant streams and
they are mapped to the one video only variant streams with audio group name
’aud_low’, and the audio group have default stat is NO or YES.
By default, a single hls variant containing all the encoded streams is created.
ffmpeg -re -i in.ts -b:a:0 32k -b:a:1 64k -b:v:0 1000k \
-map 0:a -map 0:a -map 0:v -f hls \
-var_stream_map "a:0,agroup:aud_low,default:yes a:1,agroup:aud_low v:0,agroup:aud_low" \
-master_pl_name master.m3u8 \
http://example.com/live/out_%v.m3u8
Create two audio only and one video only variant streams. In addition to the
#EXT-X-STREAM-INF tag for each variant stream in the master playlist, the
#EXT-X-MEDIA tag is also added for the two audio only variant streams and
they are mapped to the one video only variant streams with audio group name
’aud_low’, and the audio group have default stat is NO or YES, and one audio
have and language is named ENG, the other audio language is named CHN. By
default, a single hls variant containing all the encoded streams is created.
ffmpeg -re -i in.ts -b:a:0 32k -b:a:1 64k -b:v:0 1000k \
-map 0:a -map 0:a -map 0:v -f hls \
-var_stream_map "a:0,agroup:aud_low,default:yes,language:ENG a:1,agroup:aud_low,language:CHN v:0,agroup:aud_low" \
-master_pl_name master.m3u8 \
http://example.com/live/out_%v.m3u8
Create a single variant stream. Add the #EXT-X-MEDIA tag with
TYPE=SUBTITLES in the master playlist with webvtt subtitle group name
’subtitle’ and optional subtitle name, e.g. ’English’. Make sure the input
file has one text subtitle stream at least.
ffmpeg -y -i input_with_subtitle.mkv \
-b:v:0 5250k -c:v h264 -pix_fmt yuv420p -profile:v main -level 4.1 \
-b:a:0 256k \
-c:s webvtt -c:a mp2 -ar 48000 -ac 2 -map 0:v -map 0:a:0 -map 0:s:0 \
-f hls -var_stream_map "v:0,a:0,s:0,sgroup:subtitle,sname:English" \
-master_pl_name master.m3u8 -t 300 -hls_time 10 -hls_init_time 4 -hls_list_size \
10 -master_pl_publish_rate 10 -hls_flags \
delete_segments+discont_start+split_by_time ./tmp/video.m3u8
cc_stream_map cc_stream_map
Map string which specifies different closed captions groups and their
attributes. The closed captions stream groups are separated by space.
Expected string format is like this
"ccgroup:<group name>,instreamid:<INSTREAM-ID>,language:<language code> ....".
’ccgroup’ and ’instreamid’ are mandatory attributes. ’language’ is an optional
attribute.
The closed captions groups configured using this option are mapped to different
variant streams by providing the same ’ccgroup’ name in the
var_stream_map string.
For example:
ffmpeg -re -i in.ts -b:v:0 1000k -b:v:1 256k -b:a:0 64k -b:a:1 32k \
-a53cc:0 1 -a53cc:1 1 \
-map 0:v -map 0:a -map 0:v -map 0:a -f hls \
-cc_stream_map "ccgroup:cc,instreamid:CC1,language:en ccgroup:cc,instreamid:CC2,language:sp" \
-var_stream_map "v:0,a:0,ccgroup:cc v:1,a:1,ccgroup:cc" \
-master_pl_name master.m3u8 \
http://example.com/live/out_%v.m3u8
will add two #EXT-X-MEDIA tags with TYPE=CLOSED-CAPTIONS in the
master playlist for the INSTREAM-IDs ’CC1’ and ’CC2’. Also, it will add
CLOSED-CAPTIONS attribute with group name ’cc’ for the two output variant
streams.
If var_stream_map is not set, then the first available ccgroup in
cc_stream_map is mapped to the output variant stream.
For example:
ffmpeg -re -i in.ts -b:v 1000k -b:a 64k -a53cc 1 -f hls \
-cc_stream_map "ccgroup:cc,instreamid:CC1,language:en" \
-master_pl_name master.m3u8 \
http://example.com/live/out.m3u8
this will add #EXT-X-MEDIA tag with TYPE=CLOSED-CAPTIONS in the
master playlist with group name ’cc’, language ’en’ (english) and INSTREAM-ID
’CC1’. Also, it will add CLOSED-CAPTIONS attribute with group name ’cc’
for the output variant stream.
master_pl_name name
Create HLS master playlist with the given name.
For example:
ffmpeg -re -i in.ts -f hls -master_pl_name master.m3u8 http://example.com/live/out.m3u8
creates an HLS master playlist with name master.m3u8 which is published
at http://example.com/live/.
master_pl_publish_rate count
Publish master play list repeatedly every after specified number of segment intervals.
For example:
ffmpeg -re -i in.ts -f hls -master_pl_name master.m3u8 \
-hls_time 2 -master_pl_publish_rate 30 http://example.com/live/out.m3u8
creates an HLS master playlist with name master.m3u8 and keeps
publishing it repeatedly every after 30 segments i.e. every after 60s.
http_persistent bool
Use persistent HTTP connections. Applicable only for HTTP output.
timeout timeout
Set timeout for socket I/O operations. Applicable only for HTTP output.
ignore_io_errors bool
Ignore IO errors during open, write and delete. Useful for long-duration runs with network output.
headers headers
Set custom HTTP headers, can override built in default headers. Applicable only for HTTP output.
21.47 iamf
Immersive Audio Model and Formats (IAMF) muxer.
IAMF is used to provide immersive audio content for presentation on a wide range
of devices in both streaming and offline applications. These applications
include internet audio streaming, multicasting/broadcasting services, file
download, gaming, communication, virtual and augmented reality, and others. In
these applications, audio may be played back on a wide range of devices, e.g.,
headphones, mobile phones, tablets, TVs, sound bars, home theater systems, and
big screens.
This format was promoted and desgined by Alliance for Open Media.
For more information about this format, see https://aomedia.org/iamf/.
21.48 ico
ICO file muxer.
Microsoft’s icon file format (ICO) has some strict limitations that should be noted:
Size cannot exceed 256 pixels in any dimension
Only BMP and PNG images can be stored
If a BMP image is used, it must be one of the following pixel formats:
BMP Bit Depth      FFmpeg Pixel Format
1bit               pal8
4bit               pal8
8bit               pal8
16bit              rgb555le
24bit              bgr24
32bit              bgra
If a BMP image is used, it must use the BITMAPINFOHEADER DIB header
If a PNG image is used, it must use the rgba pixel format
21.49 ilbc
Internet Low Bitrate Codec (iLBC) raw muxer.
It accepts a single ‘ilbc’ audio stream.
21.50 image2, image2pipe
Image file muxer.
The ‘image2’ muxer writes video frames to image files.
The output filenames are specified by a pattern, which can be used to
produce sequentially numbered series of files.
The pattern may contain the string "%d" or "%0Nd", this string
specifies the position of the characters representing a numbering in
the filenames. If the form "%0Nd" is used, the string
representing the number in each filename is 0-padded to N
digits. The literal character ’%’ can be specified in the pattern with
the string "%%".
If the pattern contains "%d" or "%0Nd", the first filename of
the file list specified will contain the number 1, all the following
numbers will be sequential.
The pattern may contain a suffix which is used to automatically
determine the format of the image files to write.
For example the pattern "img-%03d.bmp" will specify a sequence of
filenames of the form img-001.bmp, img-002.bmp, ...,
img-010.bmp, etc.
The pattern "img%%-%d.jpg" will specify a sequence of filenames of the
form img%-1.jpg, img%-2.jpg, ..., img%-10.jpg,
etc.
The image muxer supports the .Y.U.V image file format. This format is
special in that each image frame consists of three files, for
each of the YUV420P components. To read or write this image file format,
specify the name of the ’.Y’ file. The muxer will automatically open the
’.U’ and ’.V’ files as required.
The ‘image2pipe’ muxer accepts the same options as the ‘image2’ muxer,
but ignores the pattern verification and expansion, as it is supposed to write
to the command output rather than to an actual stored file.
21.50.1 Options
frame_pts bool
If set to 1, expand the filename with the packet PTS (presentation time stamp).
Default value is 0.
start_number count
Start the sequence from the specified number. Default value is 1.
update bool
If set to 1, the filename will always be interpreted as just a
filename, not a pattern, and the corresponding file will be continuously
overwritten with new images. Default value is 0.
strftime bool
If set to 1, expand the filename with date and time information from
strftime(). Default value is 0.
atomic_writing bool
Write output to a temporary file, which is renamed to target filename once
writing is completed. Default is disabled.
protocol_opts options_list
Set protocol options as a :-separated list of key=value parameters. Values
containing the : special character must be escaped.
21.50.2 Examples
Use ffmpeg for creating a sequence of files img-001.jpeg,
img-002.jpeg, ..., taking one image every second from the input video:
ffmpeg -i in.avi -vsync cfr -r 1 -f image2 'img-%03d.jpeg'
Note that with ffmpeg, if the format is not specified with the
-f option and the output filename specifies an image file
format, the image2 muxer is automatically selected, so the previous
command can be written as:
ffmpeg -i in.avi -vsync cfr -r 1 'img-%03d.jpeg'
Note also that the pattern must not necessarily contain "%d" or
"%0Nd", for example to create a single image file
img.jpeg from the start of the input video you can employ the command:
ffmpeg -i in.avi -f image2 -frames:v 1 img.jpeg
The strftime option allows you to expand the filename with
date and time information. Check the documentation of
the strftime() function for the syntax.
To generate image files from the strftime() "%Y-%m-%d_%H-%M-%S" pattern,
the following ffmpeg command can be used:
ffmpeg -f v4l2 -r 1 -i /dev/video0 -f image2 -strftime 1 "%Y-%m-%d_%H-%M-%S.jpg"
Set the file name with current frame’s PTS:
ffmpeg -f v4l2 -r 1 -i /dev/video0 -copyts -f image2 -frame_pts true %d.jpg
Publish contents of your desktop directly to a WebDAV server every second:
ffmpeg -f x11grab -framerate 1 -i :0.0 -q:v 6 -update 1 -protocol_opts method=PUT http://example.com/desktop.jpg
21.51 ircam
Berkeley / IRCAM / CARL Sound Filesystem (BICSF) format muxer.
The Berkeley/IRCAM/CARL Sound Format, developed in the 1980s, is a result of the
merging of several different earlier sound file formats and systems including
the csound system developed by Dr Gareth Loy at the Computer Audio Research Lab
(CARL) at UC San Diego, the IRCAM sound file system developed by Rob Gross and
Dan Timis at the Institut de Recherche et Coordination Acoustique / Musique in
Paris and the Berkeley Fast Filesystem.
It was developed initially as part of the Berkeley/IRCAM/CARL Sound Filesystem,
a suite of programs designed to implement a filesystem for audio applications
running under Berkeley UNIX. It was particularly popular in academic music
research centres, and was used a number of times in the creation of early
computer-generated compositions.
This muxer accepts a single audio stream containing PCM data.
21.52 ivf
On2 IVF muxer.
IVF was developed by On2 Technologies (formerly known as Duck
Corporation), to store internally developed codecs.
This muxer accepts a single ‘vp8’, ‘vp9’, or ‘av1’
video stream.
21.53 jacosub
JACOsub subtitle format muxer.
This muxer accepts a single ‘jacosub’ subtitles stream.
For more information about the format, see
http://unicorn.us.com/jacosub/jscripts.html.
21.54 kvag
Simon & Schuster Interactive VAG muxer.
This custom VAG container is used by some Simon & Schuster Interactive
games such as "Real War", and "Real War: Rogue States".
This muxer accepts a single ‘adpcm_ima_ssi’ audio stream.
21.55 lc3
Bluetooth SIG Low Complexity Communication Codec audio (LC3), or
ETSI TS 103 634 Low Complexity Communication Codec plus (LC3plus).
This muxer accepts a single ‘lc3’ audio stream.
21.56 lrc
LRC lyrics file format muxer.
LRC (short for LyRiCs) is a computer file format that synchronizes
song lyrics with an audio file, such as MP3, Vorbis, or MIDI.
This muxer accepts a single ‘subrip’ or ‘text’ subtitles stream.
21.56.1 Metadata
The following metadata tags are converted to the format corresponding
metadata:
title
album
artist
author
creator
encoder
encoder_version
If ‘encoder_version’ is not explicitly set, it is automatically
set to the libavformat version.
21.57 matroska
Matroska container muxer.
This muxer implements the matroska and webm container specs.
21.57.1 Metadata
The recognized metadata settings in this muxer are:
title
Set title name provided to a single track. This gets mapped to
the FileDescription element for a stream written as attachment.
language
Specify the language of the track in the Matroska languages form.
The language can be either the 3 letters bibliographic ISO-639-2 (ISO
639-2/B) form (like "fre" for French), or a language code mixed with a
country code for specialities in languages (like "fre-ca" for Canadian
French).
stereo_mode
Set stereo 3D video layout of two views in a single video track.
The following values are recognized:
‘mono’
video is not stereo
‘left_right’
Both views are arranged side by side, Left-eye view is on the left
‘bottom_top’
Both views are arranged in top-bottom orientation, Left-eye view is at bottom
‘top_bottom’
Both views are arranged in top-bottom orientation, Left-eye view is on top
‘checkerboard_rl’
Each view is arranged in a checkerboard interleaved pattern, Left-eye view being first
‘checkerboard_lr’
Each view is arranged in a checkerboard interleaved pattern, Right-eye view being first
‘row_interleaved_rl’
Each view is constituted by a row based interleaving, Right-eye view is first row
‘row_interleaved_lr’
Each view is constituted by a row based interleaving, Left-eye view is first row
‘col_interleaved_rl’
Both views are arranged in a column based interleaving manner, Right-eye view is first column
‘col_interleaved_lr’
Both views are arranged in a column based interleaving manner, Left-eye view is first column
‘anaglyph_cyan_red’
All frames are in anaglyph format viewable through red-cyan filters
‘right_left’
Both views are arranged side by side, Right-eye view is on the left
‘anaglyph_green_magenta’
All frames are in anaglyph format viewable through green-magenta filters
‘block_lr’
Both eyes laced in one Block, Left-eye view is first
‘block_rl’
Both eyes laced in one Block, Right-eye view is first
For example a 3D WebM clip can be created using the following command line:
ffmpeg -i sample_left_right_clip.mpg -an -c:v libvpx -metadata stereo_mode=left_right -y stereo_clip.webm
21.57.2 Options
reserve_index_space size
By default, this muxer writes the index for seeking (called cues in Matroska
terms) at the end of the file, because it cannot know in advance how much space
to leave for the index at the beginning of the file. However for some use cases
– e.g.  streaming where seeking is possible but slow – it is useful to put the
index at the beginning of the file.
If this option is set to a non-zero value, the muxer will reserve size bytes
of space in the file header and then try to write the cues there when the muxing
finishes. If the reserved space does not suffice, no Cues will be written, the
file will be finalized and writing the trailer will return an error.
A safe size for most use cases should be about 50kB per hour of video.
Note that cues are only written if the output is seekable and this option will
have no effect if it is not.
cues_to_front bool
If set, the muxer will write the index at the beginning of the file
by shifting the main data if necessary. This can be combined with
reserve_index_space in which case the data is only shifted if
the initially reserved space turns out to be insufficient.
This option is ignored if the output is unseekable.
cluster_size_limit size
Store at most the provided amount of bytes in a cluster.
If not specified, the limit is set automatically to a sensible
hardcoded fixed value.
cluster_time_limit duration
Store at most the provided number of milliseconds in a cluster.
If not specified, the limit is set automatically to a sensible
hardcoded fixed value.
dash bool
Create a WebM file conforming to WebM DASH specification. By default
it is set to false.
dash_track_number index
Track number for the DASH stream. By default it is set to 1.
live bool
Write files assuming it is a live stream. By default it is set to
false.
allow_raw_vfw bool
Allow raw VFW mode. By default it is set to false.
flipped_raw_rgb bool
If set to true, store positive height for raw RGB bitmaps, which indicates
bitmap is stored bottom-up. Note that this option does not flip the bitmap
which has to be done manually beforehand, e.g. by using the ‘vflip’ filter.
Default is false and indicates bitmap is stored top down.
write_crc32 bool
Write a CRC32 element inside every Level 1 element. By default it is
set to true. This option is ignored for WebM.
default_mode mode
Control how the FlagDefault of the output tracks will be set.
It influences which tracks players should play by default. The default mode
is ‘passthrough’.
‘infer’
Every track with disposition default will have the FlagDefault set.
Additionally, for each type of track (audio, video or subtitle), if no track
with disposition default of this type exists, then the first track of this type
will be marked as default (if existing). This ensures that the default flag
is set in a sensible way even if the input originated from containers that
lack the concept of default tracks.
‘infer_no_subs’
This mode is the same as infer except that if no subtitle track with
disposition default exists, no subtitle track will be marked as default.
‘passthrough’
In this mode the FlagDefault is set if and only if the AV_DISPOSITION_DEFAULT
flag is set in the disposition of the corresponding stream.
21.58 md5
MD5 testing format.
This is a variant of the hash muxer. Unlike that muxer, it
defaults to using the MD5 hash function.
See also the hash and framemd5 muxers.
21.58.1 Examples
To compute the MD5 hash of the input converted to raw
audio and video, and store it in the file out.md5:
ffmpeg -i INPUT -f md5 out.md5
To print the MD5 hash to stdout:
ffmpeg -i INPUT -f md5 -
21.59 microdvd
MicroDVD subtitle format muxer.
This muxer accepts a single ‘microdvd’ subtitles stream.
21.60 mmf
Synthetic music Mobile Application Format (SMAF) format muxer.
SMAF is a music data format specified by Yamaha for portable
electronic devices, such as mobile phones and personal digital
assistants.
This muxer accepts a single ‘adpcm_yamaha’ audio stream.
21.61 mp3
The MP3 muxer writes a raw MP3 stream with the following optional features:
An ID3v2 metadata header at the beginning (enabled by default). Versions 2.3 and
2.4 are supported, the id3v2_version private option controls which one is
used (3 or 4). Setting id3v2_version to 0 disables the ID3v2 header
completely.
The muxer supports writing attached pictures (APIC frames) to the ID3v2 header.
The pictures are supplied to the muxer in form of a video stream with a single
packet. There can be any number of those streams, each will correspond to a
single APIC frame.  The stream metadata tags title and comment map
to APIC description and picture type respectively. See
http://id3.org/id3v2.4.0-frames for allowed picture types.
Note that the APIC frames must be written at the beginning, so the muxer will
buffer the audio frames until it gets all the pictures. It is therefore advised
to provide the pictures as soon as possible to avoid excessive buffering.
A Xing/LAME frame right after the ID3v2 header (if present). It is enabled by
default, but will be written only if the output is seekable. The
write_xing private option can be used to disable it.  The frame contains
various information that may be useful to the decoder, like the audio duration
or encoder delay.
A legacy ID3v1 tag at the end of the file (disabled by default). It may be
enabled with the write_id3v1 private option, but as its capabilities are
very limited, its usage is not recommended.
Examples:
Write an mp3 with an ID3v2.3 header and an ID3v1 footer:
ffmpeg -i INPUT -id3v2_version 3 -write_id3v1 1 out.mp3
To attach a picture to an mp3 file select both the audio and the picture stream
with map:
ffmpeg -i input.mp3 -i cover.png -c copy -map 0 -map 1
-metadata:s:v title="Album cover" -metadata:s:v comment="Cover (Front)" out.mp3
Write a "clean" MP3 without any extra features:
ffmpeg -i input.wav -write_xing 0 -id3v2_version 0 out.mp3
21.62 mpegts
MPEG transport stream muxer.
This muxer implements ISO 13818-1 and part of ETSI EN 300 468.
The recognized metadata settings in mpegts muxer are service_provider
and service_name. If they are not set the default for
service_provider is ‘FFmpeg’ and the default for
service_name is ‘Service01’.
21.62.1 Options
The muxer options are:
mpegts_transport_stream_id integer
Set the ‘transport_stream_id’. This identifies a transponder in DVB.
Default is 0x0001.
mpegts_original_network_id integer
Set the ‘original_network_id’. This is unique identifier of a
network in DVB. Its main use is in the unique identification of a service
through the path ‘Original_Network_ID, Transport_Stream_ID’. Default
is 0x0001.
mpegts_service_id integer
Set the ‘service_id’, also known as program in DVB. Default is
0x0001.
mpegts_service_type integer
Set the program ‘service_type’. Default is digital_tv.
Accepts the following options:
‘hex_value’
Any hexadecimal value between 0x01 and 0xff as defined in
ETSI 300 468.
‘digital_tv’
Digital TV service.
‘digital_radio’
Digital Radio service.
‘teletext’
Teletext service.
‘advanced_codec_digital_radio’
Advanced Codec Digital Radio service.
‘mpeg2_digital_hdtv’
MPEG2 Digital HDTV service.
‘advanced_codec_digital_sdtv’
Advanced Codec Digital SDTV service.
‘advanced_codec_digital_hdtv’
Advanced Codec Digital HDTV service.
mpegts_pmt_start_pid integer
Set the first PID for PMTs. Default is 0x1000, minimum is 0x0020,
maximum is 0x1ffa. This option has no effect in m2ts mode where the PMT
PID is fixed 0x0100.
mpegts_start_pid integer
Set the first PID for elementary streams. Default is 0x0100, minimum is
0x0020, maximum is 0x1ffa. This option has no effect in m2ts mode
where the elementary stream PIDs are fixed.
mpegts_m2ts_mode boolean
Enable m2ts mode if set to 1. Default value is -1 which
disables m2ts mode.
muxrate integer
Set a constant muxrate. Default is VBR.
pes_payload_size integer
Set minimum PES packet payload in bytes. Default is 2930.
mpegts_flags flags
Set mpegts flags. Accepts the following options:
‘resend_headers’
Reemit PAT/PMT before writing the next packet.
‘latm’
Use LATM packetization for AAC.
‘pat_pmt_at_frames’
Reemit PAT and PMT at each video frame.
‘system_b’
Conform to System B (DVB) instead of System A (ATSC).
‘initial_discontinuity’
Mark the initial packet of each stream as discontinuity.
‘nit’
Emit NIT table.
‘omit_rai’
Disable writing of random access indicator.
mpegts_copyts boolean
Preserve original timestamps, if value is set to 1. Default value
is -1, which results in shifting timestamps so that they start from 0.
omit_video_pes_length boolean
Omit the PES packet length for video packets. Default is 1 (true).
pcr_period integer
Override the default PCR retransmission time in milliseconds. Default is
-1 which means that the PCR interval will be determined automatically:
20 ms is used for CBR streams, the highest multiple of the frame duration which
is less than 100 ms is used for VBR streams.
pat_period duration
Maximum time in seconds between PAT/PMT tables. Default is 0.1.
sdt_period duration
Maximum time in seconds between SDT tables. Default is 0.5.
nit_period duration
Maximum time in seconds between NIT tables. Default is 0.5.
tables_version integer
Set PAT, PMT, SDT and NIT version (default 0, valid values are from 0 to 31, inclusively).
This option allows updating stream structure so that standard consumer may
detect the change. To do so, reopen output AVFormatContext (in case of API
usage) or restart ffmpeg instance, cyclically changing
tables_version value:
ffmpeg -i source1.ts -codec copy -f mpegts -tables_version 0 udp://1.1.1.1:1111
ffmpeg -i source2.ts -codec copy -f mpegts -tables_version 1 udp://1.1.1.1:1111
...
ffmpeg -i source3.ts -codec copy -f mpegts -tables_version 31 udp://1.1.1.1:1111
ffmpeg -i source1.ts -codec copy -f mpegts -tables_version 0 udp://1.1.1.1:1111
ffmpeg -i source2.ts -codec copy -f mpegts -tables_version 1 udp://1.1.1.1:1111
...
21.62.2 Example
ffmpeg -i file.mpg -c copy \
-mpegts_original_network_id 0x1122 \
-mpegts_transport_stream_id 0x3344 \
-mpegts_service_id 0x5566 \
-mpegts_pmt_start_pid 0x1500 \
-mpegts_start_pid 0x150 \
-metadata service_provider="Some provider" \
-metadata service_name="Some Channel" \
out.ts
21.63 mxf, mxf_d10, mxf_opatom
MXF muxer.
21.63.1 Options
The muxer options are:
store_user_comments bool
Set if user comments should be stored if available or never.
IRT D-10 does not allow user comments. The default is thus to write them for
mxf and mxf_opatom but not for mxf_d10
21.64 null
Null muxer.
This muxer does not generate any output file, it is mainly useful for
testing or benchmarking purposes.
For example to benchmark decoding with ffmpeg you can use the
command:
ffmpeg -benchmark -i INPUT -f null out.null
Note that the above command does not read or write the out.null
file, but specifying the output file is required by the ffmpeg
syntax.
Alternatively you can write the command as:
ffmpeg -benchmark -i INPUT -f null -
21.65 nut
-syncpoints flags
Change the syncpoint usage in nut:
default use the normal low-overhead seeking aids.
none do not use the syncpoints at all, reducing the overhead but making the stream non-seekable;
Use of this option is not recommended, as the resulting files are very damage
sensitive and seeking is not possible. Also in general the overhead from
syncpoints is negligible. Note, -write_index 0 can be used to disable
all growing data tables, allowing to mux endless streams with limited memory
and without these disadvantages.
timestamped extend the syncpoint with a wallclock field.
The none and timestamped flags are experimental.
-write_index bool
Write index at the end, the default is to write an index.
ffmpeg -i INPUT -f_strict experimental -syncpoints none - | processor
21.66 ogg
Ogg container muxer.
-page_duration duration
Preferred page duration, in microseconds. The muxer will attempt to create
pages that are approximately duration microseconds long. This allows the
user to compromise between seek granularity and container overhead. The default
is 1 second. A value of 0 will fill all segments, making pages as large as
possible. A value of 1 will effectively use 1 packet-per-page in most
situations, giving a small seek granularity at the cost of additional container
overhead.
-serial_offset value
Serial value from which to set the streams serial number.
Setting it to different and sufficiently large values ensures that the produced
ogg files can be safely chained.
21.67 rcwt
RCWT (Raw Captions With Time) is a format native to ccextractor, a commonly
used open source tool for processing 608/708 Closed Captions (CC) sources.
It can be used to archive the original extracted CC bitstream and to produce
a source file for later processing or conversion. The format allows
for interoperability between ccextractor and FFmpeg, is simple to parse,
and can be used to create a backup of the CC presentation.
This muxer implements the specification as of March 2024, which has
been stable and unchanged since April 2014.
This muxer will have some nuances from the way that ccextractor muxes RCWT.
No compatibility issues when processing the output with ccextractor
have been observed as a result of this so far, but mileage may vary
and outputs will not be a bit-exact match.
A free specification of RCWT can be found here:
https://github.com/CCExtractor/ccextractor/blob/master/docs/BINARY_FILE_FORMAT.TXT
21.67.1 Examples
Extract Closed Captions to RCWT using lavfi:
ffmpeg -f lavfi -i "movie=INPUT.mkv[out+subcc]" -map 0:s:0 -c:s copy -f rcwt CC.rcwt.bin
21.68 segment, stream_segment, ssegment
Basic stream segmenter.
This muxer outputs streams to a number of separate files of nearly
fixed duration. Output filename pattern can be set in a fashion
similar to image2, or by using a strftime template if
the strftime option is enabled.
stream_segment is a variant of the muxer used to write to
streaming output formats, i.e. which do not require global headers,
and is recommended for outputting e.g. to MPEG transport stream segments.
ssegment is a shorter alias for stream_segment.
Every segment starts with a keyframe of the selected reference stream,
which is set through the reference_stream option.
Note that if you want accurate splitting for a video file, you need to
make the input key frames correspond to the exact splitting times
expected by the segmenter, or the segment muxer will start the new
segment with the key frame found next after the specified start
time.
The segment muxer works best with a single constant frame rate video.
Optionally it can generate a list of the created segments, by setting
the option segment_list. The list type is specified by the
segment_list_type option. The entry filenames in the segment
list are set by default to the basename of the corresponding segment
files.
See also the hls muxer, which provides a more specific
implementation for HLS segmentation.
21.68.1 Options
The segment muxer supports the following options:
increment_tc 1|0
if set to 1, increment timecode between each segment
If this is selected, the input need to have
a timecode in the first video stream. Default value is
0.
reference_stream specifier
Set the reference stream, as specified by the string specifier.
If specifier is set to auto, the reference is chosen
automatically. Otherwise it must be a stream specifier (see the “Stream
specifiers” chapter in the ffmpeg manual) which specifies the
reference stream. The default value is auto.
segment_format format
Override the inner container format, by default it is guessed by the filename
extension.
segment_format_options options_list
Set output format options using a :-separated list of key=value
parameters. Values containing the : special character must be
escaped.
segment_list name
Generate also a listfile named name. If not specified no
listfile is generated.
segment_list_flags flags
Set flags affecting the segment list generation.
It currently supports the following flags:
‘cache’
Allow caching (only affects M3U8 list files).
‘live’
Allow live-friendly file generation.
segment_list_size size
Update the list file so that it contains at most size
segments. If 0 the list file will contain all the segments. Default
value is 0.
segment_list_entry_prefix prefix
Prepend prefix to each entry. Useful to generate absolute paths.
By default no prefix is applied.
segment_list_type type
Select the listing format.
The following values are recognized:
‘flat’
Generate a flat list for the created segments, one segment per line.
‘csv, ext’
Generate a list for the created segments, one segment per line,
each line matching the format (comma-separated values):
segment_filename,segment_start_time,segment_end_time
segment_filename is the name of the output file generated by the
muxer according to the provided pattern. CSV escaping (according to
RFC4180) is applied if required.
segment_start_time and segment_end_time specify
the segment start and end time expressed in seconds.
A list file with the suffix ".csv" or ".ext" will
auto-select this format.
‘ext’ is deprecated in favor or ‘csv’.
‘ffconcat’
Generate an ffconcat file for the created segments. The resulting file
can be read using the FFmpeg concat demuxer.
A list file with the suffix ".ffcat" or ".ffconcat" will
auto-select this format.
‘m3u8’
Generate an extended M3U8 file, version 3, compliant with
http://tools.ietf.org/id/draft-pantos-http-live-streaming.
A list file with the suffix ".m3u8" will auto-select this format.
If not specified the type is guessed from the list file name suffix.
segment_time time
Set segment duration to time, the value must be a duration
specification. Default value is "2". See also the
segment_times option.
Note that splitting may not be accurate, unless you force the
reference stream key-frames at the given time. See the introductory
notice and the examples below.
min_seg_duration time
Set minimum segment duration to time, the value must be a duration
specification. This prevents the muxer ending segments at a duration below
this value. Only effective with segment_time. Default value is "0".
segment_atclocktime 1|0
If set to "1" split at regular clock time intervals starting from 00:00
o’clock. The time value specified in segment_time is
used for setting the length of the splitting interval.
For example with segment_time set to "900" this makes it possible
to create files at 12:00 o’clock, 12:15, 12:30, etc.
Default value is "0".
segment_clocktime_offset duration
Delay the segment splitting times with the specified duration when using
segment_atclocktime.
For example with segment_time set to "900" and
segment_clocktime_offset set to "300" this makes it possible to
create files at 12:05, 12:20, 12:35, etc.
Default value is "0".
segment_clocktime_wrap_duration duration
Force the segmenter to only start a new segment if a packet reaches the muxer
within the specified duration after the segmenting clock time. This way you
can make the segmenter more resilient to backward local time jumps, such as
leap seconds or transition to standard time from daylight savings time.
Default is the maximum possible duration which means starting a new segment
regardless of the elapsed time since the last clock time.
segment_time_delta delta
Specify the accuracy time when selecting the start time for a
segment, expressed as a duration specification. Default value is "0".
When delta is specified a key-frame will start a new segment if its
PTS satisfies the relation:
PTS >= start_time - time_delta
This option is useful when splitting video content, which is always
split at GOP boundaries, in case a key frame is found just before the
specified split time.
In particular may be used in combination with the ffmpeg option
force_key_frames. The key frame times specified by
force_key_frames may not be set accurately because of rounding
issues, with the consequence that a key frame time may result set just
before the specified time. For constant frame rate videos a value of
1/(2*frame_rate) should address the worst case mismatch between
the specified time and the time set by force_key_frames.
segment_times times
Specify a list of split points. times contains a list of comma
separated duration specifications, in increasing order. See also
the segment_time option.
segment_frames frames
Specify a list of split video frame numbers. frames contains a
list of comma separated integer numbers, in increasing order.
This option specifies to start a new segment whenever a reference
stream key frame is found and the sequential number (starting from 0)
of the frame is greater or equal to the next value in the list.
segment_wrap limit
Wrap around segment index once it reaches limit.
segment_start_number number
Set the sequence number of the first segment. Defaults to 0.
strftime 1|0
Use the strftime function to define the name of the new
segments to write. If this is selected, the output segment name must
contain a strftime function template. Default value is
0.
break_non_keyframes 1|0
If enabled, allow segments to start on frames other than keyframes. This
improves behavior on some players when the time between keyframes is
inconsistent, but may make things worse on others, and can cause some oddities
during seeking. Defaults to 0.
reset_timestamps 1|0
Reset timestamps at the beginning of each segment, so that each segment
will start with near-zero timestamps. It is meant to ease the playback
of the generated segments. May not work with some combinations of
muxers/codecs. It is set to 0 by default.
initial_offset offset
Specify timestamp offset to apply to the output packet timestamps. The
argument must be a time duration specification, and defaults to 0.
write_empty_segments 1|0
If enabled, write an empty segment if there are no packets during the period a
segment would usually span. Otherwise, the segment will be filled with the next
packet written. Defaults to 0.
Make sure to require a closed GOP when encoding and to set the GOP
size to fit your segment time constraint.
21.68.2 Examples
Remux the content of file in.mkv to a list of segments
out-000.nut, out-001.nut, etc., and write the list of
generated segments to out.list:
ffmpeg -i in.mkv -codec hevc -flags +cgop -g 60 -map 0 -f segment -segment_list out.list out%03d.nut
Segment input and set output format options for the output segments:
ffmpeg -i in.mkv -f segment -segment_time 10 -segment_format_options movflags=+faststart out%03d.mp4
Segment the input file according to the split points specified by the
segment_times option:
ffmpeg -i in.mkv -codec copy -map 0 -f segment -segment_list out.csv -segment_times 1,2,3,5,8,13,21 out%03d.nut
Use the ffmpeg force_key_frames
option to force key frames in the input at the specified location, together
with the segment option segment_time_delta to account for
possible roundings operated when setting key frame times.
ffmpeg -i in.mkv -force_key_frames 1,2,3,5,8,13,21 -codec:v mpeg4 -codec:a pcm_s16le -map 0 \
-f segment -segment_list out.csv -segment_times 1,2,3,5,8,13,21 -segment_time_delta 0.05 out%03d.nut
In order to force key frames on the input file, transcoding is
required.
Segment the input file by splitting the input file according to the
frame numbers sequence specified with the segment_frames option:
ffmpeg -i in.mkv -codec copy -map 0 -f segment -segment_list out.csv -segment_frames 100,200,300,500,800 out%03d.nut
Convert the in.mkv to TS segments using the libx264
and aac encoders:
ffmpeg -i in.mkv -map 0 -codec:v libx264 -codec:a aac -f ssegment -segment_list out.list out%03d.ts
Segment the input file, and create an M3U8 live playlist (can be used
as live HLS source):
ffmpeg -re -i in.mkv -codec copy -map 0 -f segment -segment_list playlist.m3u8 \
-segment_list_flags +live -segment_time 10 out%03d.mkv
21.69 smoothstreaming
Smooth Streaming muxer generates a set of files (Manifest, chunks) suitable for serving with conventional web server.
window_size
Specify the number of fragments kept in the manifest. Default 0 (keep all).
extra_window_size
Specify the number of fragments kept outside of the manifest before removing from disk. Default 5.
lookahead_count
Specify the number of lookahead fragments. Default 2.
min_frag_duration
Specify the minimum fragment duration (in microseconds). Default 5000000.
remove_at_exit
Specify whether to remove all fragments when finished. Default 0 (do not remove).
21.70 streamhash
Per stream hash testing format.
This muxer computes and prints a cryptographic hash of all the input frames,
on a per-stream basis. This can be used for equality checks without having
to do a complete binary comparison.
By default audio frames are converted to signed 16-bit raw audio and
video frames to raw video before computing the hash, but the output
of explicit conversions to other codecs can also be used. Timestamps
are ignored. It uses the SHA-256 cryptographic hash function by default,
but supports several other algorithms.
The output of the muxer consists of one line per stream of the form:
streamindex,streamtype,algo=hash, where
streamindex is the index of the mapped stream, streamtype is a
single character indicating the type of stream, algo is a short string
representing the hash function used, and hash is a hexadecimal number
representing the computed hash.
hash algorithm
Use the cryptographic hash function specified by the string algorithm.
Supported values include MD5, murmur3, RIPEMD128,
RIPEMD160, RIPEMD256, RIPEMD320, SHA160,
SHA224, SHA256 (default), SHA512/224, SHA512/256,
SHA384, SHA512, CRC32 and adler32.
21.70.1 Examples
To compute the SHA-256 hash of the input converted to raw audio and
video, and store it in the file out.sha256:
ffmpeg -i INPUT -f streamhash out.sha256
To print an MD5 hash to stdout use the command:
ffmpeg -i INPUT -f streamhash -hash md5 -
See also the hash and framehash muxers.
21.71 tee
The tee muxer can be used to write the same data to several outputs, such as files or streams.
It can be used, for example, to stream a video over a network and save it to disk at the same time.
It is different from specifying several outputs to the ffmpeg
command-line tool. With the tee muxer, the audio and video data will be encoded only once.
With conventional multiple outputs, multiple encoding operations in parallel are initiated,
which can be a very expensive process. The tee muxer is not useful when using the libavformat API
directly because it is then possible to feed the same packets to several muxers directly.
Since the tee muxer does not represent any particular output format, ffmpeg cannot auto-select
output streams. So all streams intended for output must be specified using -map. See
the examples below.
Some encoders may need different options depending on the output format;
the auto-detection of this can not work with the tee muxer, so they need to be explicitly specified.
The main example is the global_header flag.
The slave outputs are specified in the file name given to the muxer,
separated by ’|’. If any of the slave name contains the ’|’ separator,
leading or trailing spaces or any special character, those must be
escaped (see (ffmpeg-utils)the "Quoting and escaping"
section in the ffmpeg-utils(1) manual).
21.71.1 Options
use_fifo bool
If set to 1, slave outputs will be processed in separate threads using the fifo
muxer. This allows to compensate for different speed/latency/reliability of
outputs and setup transparent recovery. By default this feature is turned off.
fifo_options
Options to pass to fifo pseudo-muxer instances. See fifo.
Muxer options can be specified for each slave by prepending them as a list of
key=value pairs separated by ’:’, between square brackets. If
the options values contain a special character or the ’:’ separator, they
must be escaped; note that this is a second level escaping.
The following special options are also recognized:
f
Specify the format name. Required if it cannot be guessed from the
output URL.
bsfs[/spec]
Specify a list of bitstream filters to apply to the specified
output.
It is possible to specify to which streams a given bitstream filter
applies, by appending a stream specifier to the option separated by
/. spec must be a stream specifier (see Format stream specifiers).
If the stream specifier is not specified, the bitstream filters will be
applied to all streams in the output. This will cause that output operation
to fail if the output contains streams to which the bitstream filter cannot
be applied e.g. h264_mp4toannexb being applied to an output containing an audio stream.
Options for a bitstream filter must be specified in the form of opt=value.
Several bitstream filters can be specified, separated by ",".
use_fifo bool
This allows to override tee muxer use_fifo option for individual slave muxer.
fifo_options
This allows to override tee muxer fifo_options for individual slave muxer.
See fifo.
select
Select the streams that should be mapped to the slave output,
specified by a stream specifier. If not specified, this defaults to
all the mapped streams. This will cause that output operation to fail
if the output format does not accept all mapped streams.
You may use multiple stream specifiers separated by commas (,) e.g.: a:0,v
onfail
Specify behaviour on output failure. This can be set to either abort (which is
default) or ignore. abort will cause whole process to fail in case of failure
on this slave output. ignore will ignore failure on this output, so other outputs
will continue without being affected.
21.71.2 Examples
Encode something and both archive it in a WebM file and stream it
as MPEG-TS over UDP:
ffmpeg -i ... -c:v libx264 -c:a mp2 -f tee -map 0:v -map 0:a
"archive-20121107.mkv|[f=mpegts]udp://10.0.1.255:1234/"
As above, but continue streaming even if output to local file fails
(for example local drive fills up):
ffmpeg -i ... -c:v libx264 -c:a mp2 -f tee -map 0:v -map 0:a
"[onfail=ignore]archive-20121107.mkv|[f=mpegts]udp://10.0.1.255:1234/"
Use ffmpeg to encode the input, and send the output
to three different destinations. The dump_extra bitstream
filter is used to add extradata information to all the output video
keyframes packets, as requested by the MPEG-TS format. The select
option is applied to out.aac in order to make it contain only
audio packets.
ffmpeg -i ... -map 0 -flags +global_header -c:v libx264 -c:a aac
-f tee "[bsfs/v=dump_extra=freq=keyframe]out.ts|[movflags=+faststart]out.mp4|[select=a]out.aac"
As above, but select only stream a:1 for the audio output. Note
that a second level escaping must be performed, as ":" is a special
character used to separate options.
ffmpeg -i ... -map 0 -flags +global_header -c:v libx264 -c:a aac
-f tee "[bsfs/v=dump_extra=freq=keyframe]out.ts|[movflags=+faststart]out.mp4|[select=\'a:1\']out.aac"
21.72 webm_chunk
WebM Live Chunk Muxer.
This muxer writes out WebM headers and chunks as separate files which can be
consumed by clients that support WebM Live streams via DASH.
21.72.1 Options
This muxer supports the following options:
chunk_start_index
Index of the first chunk (defaults to 0).
header
Filename of the header where the initialization data will be written.
audio_chunk_duration
Duration of each audio chunk in milliseconds (defaults to 5000).
21.72.2 Example
ffmpeg -f v4l2 -i /dev/video0 \
-f alsa -i hw:0 \
-map 0:0 \
-c:v libvpx-vp9 \
-s 640x360 -keyint_min 30 -g 30 \
-f webm_chunk \
-header webm_live_video_360.hdr \
-chunk_start_index 1 \
webm_live_video_360_%d.chk \
-map 1:0 \
-c:a libvorbis \
-b:a 128k \
-f webm_chunk \
-header webm_live_audio_128.hdr \
-chunk_start_index 1 \
-audio_chunk_duration 1000 \
webm_live_audio_128_%d.chk
21.73 webm_dash_manifest
WebM DASH Manifest muxer.
This muxer implements the WebM DASH Manifest specification to generate the DASH
manifest XML. It also supports manifest generation for DASH live streams.
For more information see:
WebM DASH Specification: https://sites.google.com/a/webmproject.org/wiki/adaptive-streaming/webm-dash-specification
ISO DASH Specification: http://standards.iso.org/ittf/PubliclyAvailableStandards/c065274_ISO_IEC_23009-1_2014.zip
21.73.1 Options
This muxer supports the following options:
adaptation_sets
This option has the following syntax: "id=x,streams=a,b,c id=y,streams=d,e" where x and y are the
unique identifiers of the adaptation sets and a,b,c,d and e are the indices of the corresponding
audio and video streams. Any number of adaptation sets can be added using this option.
live
Set this to 1 to create a live stream DASH Manifest. Default: 0.
chunk_start_index
Start index of the first chunk. This will go in the ‘startNumber’ attribute
of the ‘SegmentTemplate’ element in the manifest. Default: 0.
chunk_duration_ms
Duration of each chunk in milliseconds. This will go in the ‘duration’
attribute of the ‘SegmentTemplate’ element in the manifest. Default: 1000.
utc_timing_url
URL of the page that will return the UTC timestamp in ISO format. This will go
in the ‘value’ attribute of the ‘UTCTiming’ element in the manifest.
Default: None.
time_shift_buffer_depth
Smallest time (in seconds) shifting buffer for which any Representation is
guaranteed to be available. This will go in the ‘timeShiftBufferDepth’
attribute of the ‘MPD’ element. Default: 60.
minimum_update_period
Minimum update period (in seconds) of the manifest. This will go in the
‘minimumUpdatePeriod’ attribute of the ‘MPD’ element. Default: 0.
21.73.2 Example
ffmpeg -f webm_dash_manifest -i video1.webm \
-f webm_dash_manifest -i video2.webm \
-f webm_dash_manifest -i audio1.webm \
-f webm_dash_manifest -i audio2.webm \
-map 0 -map 1 -map 2 -map 3 \
-c copy \
-f webm_dash_manifest \
-adaptation_sets "id=0,streams=0,1 id=1,streams=2,3" \
manifest.xml
22 Metadata
FFmpeg is able to dump metadata from media files into a simple UTF-8-encoded
INI-like text file and then load it back using the metadata muxer/demuxer.
The file format is as follows:
A file consists of a header and a number of metadata tags divided into sections,
each on its own line.
The header is a ‘;FFMETADATA’ string, followed by a version number (now 1).
Metadata tags are of the form ‘key=value’
Immediately after header follows global metadata
After global metadata there may be sections with per-stream/per-chapter
metadata.
A section starts with the section name in uppercase (i.e. STREAM or CHAPTER) in
brackets (‘[’, ‘]’) and ends with next section or end of file.
At the beginning of a chapter section there may be an optional timebase to be
used for start/end values. It must be in form
‘TIMEBASE=num/den’, where num and den are
integers. If the timebase is missing then start/end times are assumed to
be in nanoseconds.
Next a chapter section must contain chapter start and end times in form
‘START=num’, ‘END=num’, where num is a positive
integer.
Empty lines and lines starting with ‘;’ or ‘#’ are ignored.
Metadata keys or values containing special characters (‘=’, ‘;’,
‘#’, ‘\’ and a newline) must be escaped with a backslash ‘\’.
Note that whitespace in metadata (e.g. ‘foo = bar’) is considered to be
a part of the tag (in the example above key is ‘foo ’, value is
‘ bar’).
A ffmetadata file might look like this:
;FFMETADATA1
title=bike\\shed
;this is a comment
artist=FFmpeg troll team
[CHAPTER]
TIMEBASE=1/1000
START=0
#chapter ends at 0:01:00
END=60000
title=chapter \#1
[STREAM]
title=multi\
line
By using the ffmetadata muxer and demuxer it is possible to extract
metadata from an input file to an ffmetadata file, and then transcode
the file into an output file with the edited ffmetadata file.
Extracting an ffmetadata file with ffmpeg goes as follows:
ffmpeg -i INPUT -f ffmetadata FFMETADATAFILE
Reinserting edited metadata information from the FFMETADATAFILE file can
be done as:
ffmpeg -i INPUT -i FFMETADATAFILE -map_metadata 1 -codec copy OUTPUT
23 Protocol Options
The libavformat library provides some generic global options, which
can be set on all the protocols. In addition each protocol may support
so-called private options, which are specific for that component.
Options may be set by specifying -option value in the
FFmpeg tools, or by setting the value explicitly in the
AVFormatContext options or using the libavutil/opt.h API
for programmatic use.
The list of supported options follows:
protocol_whitelist list (input)
Set a ","-separated list of allowed protocols. "ALL" matches all protocols. Protocols
prefixed by "-" are disabled.
All protocols are allowed by default but protocols used by an another
protocol (nested protocols) are restricted to a per protocol subset.
24 Protocols
Protocols are configured elements in FFmpeg that enable access to
resources that require specific protocols.
When you configure your FFmpeg build, all the supported protocols are
enabled by default. You can list all available ones using the
configure option "–list-protocols".
You can disable all the protocols using the configure option
"–disable-protocols", and selectively enable a protocol using the
option "–enable-protocol=PROTOCOL", or you can disable a
particular protocol using the option
"–disable-protocol=PROTOCOL".
The option "-protocols" of the ff* tools will display the list of
supported protocols.
All protocols accept the following options:
rw_timeout
Maximum time to wait for (network) read/write operations to complete,
in microseconds.
A description of the currently available protocols follows.
24.1 amqp
Advanced Message Queueing Protocol (AMQP) version 0-9-1 is a broker based
publish-subscribe communication protocol.
FFmpeg must be compiled with –enable-librabbitmq to support AMQP. A separate
AMQP broker must also be run. An example open-source AMQP broker is RabbitMQ.
After starting the broker, an FFmpeg client may stream data to the broker using
the command:
ffmpeg -re -i input -f mpegts amqp://[[user]:[password]@]hostname[:port][/vhost]
Where hostname and port (default is 5672) is the address of the broker. The
client may also set a user/password for authentication. The default for both
fields is "guest". Name of virtual host on broker can be set with vhost. The
default value is "/".
Muliple subscribers may stream from the broker using the command:
ffplay amqp://[[user]:[password]@]hostname[:port][/vhost]
In RabbitMQ all data published to the broker flows through a specific exchange,
and each subscribing client has an assigned queue/buffer. When a packet arrives
at an exchange, it may be copied to a client’s queue depending on the exchange
and routing_key fields.
The following options are supported:
exchange
Sets the exchange to use on the broker. RabbitMQ has several predefined
exchanges: "amq.direct" is the default exchange, where the publisher and
subscriber must have a matching routing_key; "amq.fanout" is the same as a
broadcast operation (i.e. the data is forwarded to all queues on the fanout
exchange independent of the routing_key); and "amq.topic" is similar to
"amq.direct", but allows for more complex pattern matching (refer to the RabbitMQ
documentation).
routing_key
Sets the routing key. The default value is "amqp". The routing key is used on
the "amq.direct" and "amq.topic" exchanges to decide whether packets are written
to the queue of a subscriber.
pkt_size
Maximum size of each packet sent/received to the broker. Default is 131072.
Minimum is 4096 and max is any large value (representable by an int). When
receiving packets, this sets an internal buffer size in FFmpeg. It should be
equal to or greater than the size of the published packets to the broker. Otherwise
the received message may be truncated causing decoding errors.
connection_timeout
The timeout in seconds during the initial connection to the broker. The
default value is rw_timeout, or 5 seconds if rw_timeout is not set.
delivery_mode mode
Sets the delivery mode of each message sent to broker.
The following values are accepted:
‘persistent’
Delivery mode set to "persistent" (2). This is the default value.
Messages may be written to the broker’s disk depending on its setup.
‘non-persistent’
Delivery mode set to "non-persistent" (1).
Messages will stay in broker’s memory unless the broker is under memory
pressure.
24.2 async
Asynchronous data filling wrapper for input stream.
Fill data in a background thread, to decouple I/O operation from demux thread.
async:URL
async:http://host/resource
async:cache:http://host/resource
24.3 bluray
Read BluRay playlist.
The accepted options are:
angle
BluRay angle
chapter
Start chapter (1...N)
playlist
Playlist to read (BDMV/PLAYLIST/?????.mpls)
Examples:
Read longest playlist from BluRay mounted to /mnt/bluray:
bluray:/mnt/bluray
Read angle 2 of playlist 4 from BluRay mounted to /mnt/bluray, start from chapter 2:
-playlist 4 -angle 2 -chapter 2 bluray:/mnt/bluray
24.4 cache
Caching wrapper for input stream.
Cache the input stream to temporary file. It brings seeking capability to live streams.
The accepted options are:
read_ahead_limit
Amount in bytes that may be read ahead when seeking isn’t supported. Range is -1 to INT_MAX.
-1 for unlimited. Default is 65536.
URL Syntax is
cache:URL
24.5 concat
Physical concatenation protocol.
Read and seek from many resources in sequence as if they were
a unique resource.
A URL accepted by this protocol has the syntax:
concat:URL1|URL2|...|URLN
where URL1, URL2, ..., URLN are the urls of the
resource to be concatenated, each one possibly specifying a distinct
protocol.
For example to read a sequence of files split1.mpeg,
split2.mpeg, split3.mpeg with ffplay use the
command:
ffplay concat:split1.mpeg\|split2.mpeg\|split3.mpeg
Note that you may need to escape the character "|" which is special for
many shells.
24.6 concatf
Physical concatenation protocol using a line break delimited list of
resources.
Read and seek from many resources in sequence as if they were
a unique resource.
A URL accepted by this protocol has the syntax:
concatf:URL
where URL is the url containing a line break delimited list of
resources to be concatenated, each one possibly specifying a distinct
protocol. Special characters must be escaped with backslash or single
quotes. See (ffmpeg-utils)the "Quoting and escaping"
section in the ffmpeg-utils(1) manual.
For example to read a sequence of files split1.mpeg,
split2.mpeg, split3.mpeg listed in separate lines within
a file split.txt with ffplay use the command:
ffplay concatf:split.txt
Where split.txt contains the lines:
split1.mpeg
split2.mpeg
split3.mpeg
24.7 crypto
AES-encrypted stream reading protocol.
The accepted options are:
key
Set the AES decryption key binary block from given hexadecimal representation.
iv
Set the AES decryption initialization vector binary block from given hexadecimal representation.
Accepted URL formats:
crypto:URL
crypto+URL
24.8 data
Data in-line in the URI. See http://en.wikipedia.org/wiki/Data_URI_scheme.
For example, to convert a GIF file given inline with ffmpeg:
ffmpeg -i "data:image/gif;base64,R0lGODdhCAAIAMIEAAAAAAAA//8AAP//AP///////////////ywAAAAACAAIAAADF0gEDLojDgdGiJdJqUX02iB4E8Q9jUMkADs=" smiley.png
24.9 fd
File descriptor access protocol.
The accepted syntax is:
fd: -fd file_descriptor
If fd is not specified, by default the stdout file descriptor will be
used for writing, stdin for reading. Unlike the pipe protocol, fd protocol has
seek support if it corresponding to a regular file. fd protocol doesn’t support
pass file descriptor via URL for security.
This protocol accepts the following options:
blocksize
Set I/O operation maximum block size, in bytes. Default value is
INT_MAX, which results in not limiting the requested block size.
Setting this value reasonably low improves user termination request reaction
time, which is valuable if data transmission is slow.
fd
Set file descriptor.
24.10 file
File access protocol.
Read from or write to a file.
A file URL can have the form:
file:filename
where filename is the path of the file to read.
An URL that does not have a protocol prefix will be assumed to be a
file URL. Depending on the build, an URL that looks like a Windows
path with the drive letter at the beginning will also be assumed to be
a file URL (usually not the case in builds for unix-like systems).
For example to read from a file input.mpeg with ffmpeg
use the command:
ffmpeg -i file:input.mpeg output.mpeg
This protocol accepts the following options:
truncate
Truncate existing files on write, if set to 1. A value of 0 prevents
truncating. Default value is 1.
blocksize
Set I/O operation maximum block size, in bytes. Default value is
INT_MAX, which results in not limiting the requested block size.
Setting this value reasonably low improves user termination request reaction
time, which is valuable for files on slow medium.
follow
If set to 1, the protocol will retry reading at the end of the file, allowing
reading files that still are being written. In order for this to terminate,
you either need to use the rw_timeout option, or use the interrupt callback
(for API users).
seekable
Controls if seekability is advertised on the file. 0 means non-seekable, -1
means auto (seekable for normal files, non-seekable for named pipes).
Many demuxers handle seekable and non-seekable resources differently,
overriding this might speed up opening certain files at the cost of losing some
features (e.g. accurate seeking).
24.11 ftp
FTP (File Transfer Protocol).
Read from or write to remote resources using FTP protocol.
Following syntax is required.
ftp://[user[:password]@]server[:port]/path/to/remote/resource.mpeg
This protocol accepts the following options.
timeout
Set timeout in microseconds of socket I/O operations used by the underlying low level
operation. By default it is set to -1, which means that the timeout is
not specified.
ftp-user
Set a user to be used for authenticating to the FTP server. This is overridden by the
user in the FTP URL.
ftp-password
Set a password to be used for authenticating to the FTP server. This is overridden by
the password in the FTP URL, or by ftp-anonymous-password if no user is set.
ftp-anonymous-password
Password used when login as anonymous user. Typically an e-mail address
should be used.
ftp-write-seekable
Control seekability of connection during encoding. If set to 1 the
resource is supposed to be seekable, if set to 0 it is assumed not
to be seekable. Default value is 0.
NOTE: Protocol can be used as output, but it is recommended to not do
it, unless special care is taken (tests, customized server configuration
etc.). Different FTP servers behave in different way during seek
operation. ff* tools may produce incomplete content due to server limitations.
24.12 gopher
Gopher protocol.
24.13 gophers
Gophers protocol.
The Gopher protocol with TLS encapsulation.
24.14 hls
Read Apple HTTP Live Streaming compliant segmented stream as
a uniform one. The M3U8 playlists describing the segments can be
remote HTTP resources or local files, accessed using the standard
file protocol.
The nested protocol is declared by specifying
"+proto" after the hls URI scheme name, where proto
is either "file" or "http".
hls+http://host/path/to/remote/resource.m3u8
hls+file://path/to/local/resource.m3u8
Using this protocol is discouraged - the hls demuxer should work
just as well (if not, please report the issues) and is more complete.
To use the hls demuxer instead, simply use the direct URLs to the
m3u8 files.
24.15 http
HTTP (Hyper Text Transfer Protocol).
This protocol accepts the following options:
seekable
Control seekability of connection. If set to 1 the resource is
supposed to be seekable, if set to 0 it is assumed not to be seekable,
if set to -1 it will try to autodetect if it is seekable. Default
value is -1.
chunked_post
If set to 1 use chunked Transfer-Encoding for posts, default is 1.
http_proxy
set HTTP proxy to tunnel through e.g. http://example.com:1234
headers
Set custom HTTP headers, can override built in default headers. The
value must be a string encoding the headers.
content_type
Set a specific content type for the POST messages or for listen mode.
user_agent
Override the User-Agent header. If not specified the protocol will use a
string describing the libavformat build. ("Lavf/<version>")
referer
Set the Referer header. Include ’Referer: URL’ header in HTTP request.
multiple_requests
Use persistent connections if set to 1, default is 0.
post_data
Set custom HTTP post data.
mime_type
Export the MIME type.
http_version
Exports the HTTP response version number. Usually "1.0" or "1.1".
cookies
Set the cookies to be sent in future requests. The format of each cookie is the
same as the value of a Set-Cookie HTTP response field. Multiple cookies can be
delimited by a newline character.
icy
If set to 1 request ICY (SHOUTcast) metadata from the server. If the server
supports this, the metadata has to be retrieved by the application by reading
the icy_metadata_headers and icy_metadata_packet options.
The default is 1.
icy_metadata_headers
If the server supports ICY metadata, this contains the ICY-specific HTTP reply
headers, separated by newline characters.
icy_metadata_packet
If the server supports ICY metadata, and icy was set to 1, this
contains the last non-empty metadata packet sent by the server. It should be
polled in regular intervals by applications interested in mid-stream metadata
updates.
metadata
Set an exported dictionary containing Icecast metadata from the bitstream, if present.
Only useful with the C API.
auth_type
Set HTTP authentication type. No option for Digest, since this method requires
getting nonce parameters from the server first and can’t be used straight away like
Basic.
none
Choose the HTTP authentication type automatically. This is the default.
basic
Choose the HTTP basic authentication.
Basic authentication sends a Base64-encoded string that contains a user name and password
for the client. Base64 is not a form of encryption and should be considered the same as
sending the user name and password in clear text (Base64 is a reversible encoding).
If a resource needs to be protected, strongly consider using an authentication scheme
other than basic authentication. HTTPS/TLS should be used with basic authentication.
Without these additional security enhancements, basic authentication should not be used
to protect sensitive or valuable information.
send_expect_100
Send an Expect: 100-continue header for POST. If set to 1 it will send, if set
to 0 it won’t, if set to -1 it will try to send if it is applicable. Default
value is -1.
location
An exported dictionary containing the content location. Only useful with the C
API.
offset
Set initial byte offset.
end_offset
Try to limit the request to bytes preceding this offset.
method
When used as a client option it sets the HTTP method for the request.
When used as a server option it sets the HTTP method that is going to be
expected from the client(s).
If the expected and the received HTTP method do not match the client will
be given a Bad Request response.
When unset the HTTP method is not checked for now. This will be replaced by
autodetection in the future.
reconnect
Reconnect automatically when disconnected before EOF is hit.
reconnect_at_eof
If set then eof is treated like an error and causes reconnection, this is useful
for live / endless streams.
reconnect_on_network_error
Reconnect automatically in case of TCP/TLS errors during connect.
reconnect_on_http_error
A comma separated list of HTTP status codes to reconnect on. The list can
include specific status codes (e.g. ’503’) or the strings ’4xx’ / ’5xx’.
reconnect_streamed
If set then even streamed/non seekable streams will be reconnected on errors.
reconnect_delay_max
Set the maximum delay in seconds after which to give up reconnecting.
reconnect_max_retries
Set the maximum number of times to retry a connection. Default unset.
reconnect_delay_total_max
Set the maximum total delay in seconds after which to give up reconnecting.
respect_retry_after
If enabled, and a Retry-After header is encountered, its requested reconnection
delay will be honored, rather than using exponential backoff. Useful for 429 and
503 errors. Default enabled.
listen
If set to 1 enables experimental HTTP server. This can be used to send data when
used as an output option, or read data from a client with HTTP POST when used as
an input option.
If set to 2 enables experimental multi-client HTTP server. This is not yet implemented
in ffmpeg.c and thus must not be used as a command line option.
# Server side (sending):
ffmpeg -i somefile.ogg -c copy -listen 1 -f ogg http://server:port
# Client side (receiving):
ffmpeg -i http://server:port -c copy somefile.ogg
# Client can also be done with wget:
wget http://server:port -O somefile.ogg
# Server side (receiving):
ffmpeg -listen 1 -i http://server:port -c copy somefile.ogg
# Client side (sending):
ffmpeg -i somefile.ogg -chunked_post 0 -c copy -f ogg http://server:port
# Client can also be done with wget:
wget --post-file=somefile.ogg http://server:port
resource
The resource requested by a client, when the experimental HTTP server is in use.
reply_code
The HTTP code returned to the client, when the experimental HTTP server is in use.
short_seek_size
Set the threshold, in bytes, for when a readahead should be prefered over a seek and
new HTTP request. This is useful, for example, to make sure the same connection
is used for reading large video packets with small audio packets in between.
24.15.1 HTTP Cookies
Some HTTP requests will be denied unless cookie values are passed in with the
request. The cookies option allows these cookies to be specified. At
the very least, each cookie must specify a value along with a path and domain.
HTTP requests that match both the domain and path will automatically include the
cookie value in the HTTP Cookie header field. Multiple cookies can be delimited
by a newline.
The required syntax to play a stream specifying a cookie is:
ffplay -cookies "nlqptid=nltid=tsn; path=/; domain=somedomain.com;" http://somedomain.com/somestream.m3u8
24.16 Icecast
Icecast protocol (stream to Icecast servers)
This protocol accepts the following options:
ice_genre
Set the stream genre.
ice_name
Set the stream name.
ice_description
Set the stream description.
ice_url
Set the stream website URL.
ice_public
Set if the stream should be public.
The default is 0 (not public).
user_agent
Override the User-Agent header. If not specified a string of the form
"Lavf/<version>" will be used.
password
Set the Icecast mountpoint password.
content_type
Set the stream content type. This must be set if it is different from
audio/mpeg.
legacy_icecast
This enables support for Icecast versions < 2.4.0, that do not support the
HTTP PUT method but the SOURCE method.
tls
Establish a TLS (HTTPS) connection to Icecast.
icecast://[username[:password]@]server:port/mountpoint
24.17 ipfs
InterPlanetary File System (IPFS) protocol support. One can access files stored
on the IPFS network through so-called gateways. These are http(s) endpoints.
This protocol wraps the IPFS native protocols (ipfs:// and ipns://) to be sent
to such a gateway. Users can (and should) host their own node which means this
protocol will use one’s local gateway to access files on the IPFS network.
This protocol accepts the following options:
gateway
Defines the gateway to use. When not set, the protocol will first try
locating the local gateway by looking at $IPFS_GATEWAY, $IPFS_PATH
and $HOME/.ipfs/, in that order.
One can use this protocol in 2 ways. Using IPFS:
ffplay ipfs://<hash>
Or the IPNS protocol (IPNS is mutable IPFS):
ffplay ipns://<hash>
24.18 mmst
MMS (Microsoft Media Server) protocol over TCP.
24.19 mmsh
MMS (Microsoft Media Server) protocol over HTTP.
The required syntax is:
mmsh://server[:port][/app][/playpath]
24.20 md5
MD5 output protocol.
Computes the MD5 hash of the data to be written, and on close writes
this to the designated output or stdout if none is specified. It can
be used to test muxers without writing an actual file.
Some examples follow.
# Write the MD5 hash of the encoded AVI file to the file output.avi.md5.
ffmpeg -i input.flv -f avi -y md5:output.avi.md5
# Write the MD5 hash of the encoded AVI file to stdout.
ffmpeg -i input.flv -f avi -y md5:
Note that some formats (typically MOV) require the output protocol to
be seekable, so they will fail with the MD5 output protocol.
24.21 pipe
UNIX pipe access protocol.
Read and write from UNIX pipes.
The accepted syntax is:
pipe:[number]
If fd isn’t specified, number is the number corresponding to the file descriptor of the
pipe (e.g. 0 for stdin, 1 for stdout, 2 for stderr).  If number
is not specified, by default the stdout file descriptor will be used
for writing, stdin for reading.
For example to read from stdin with ffmpeg:
cat test.wav | ffmpeg -i pipe:0
# ...this is the same as...
cat test.wav | ffmpeg -i pipe:
For writing to stdout with ffmpeg:
ffmpeg -i test.wav -f avi pipe:1 | cat > test.avi
# ...this is the same as...
ffmpeg -i test.wav -f avi pipe: | cat > test.avi
This protocol accepts the following options:
blocksize
Set I/O operation maximum block size, in bytes. Default value is
INT_MAX, which results in not limiting the requested block size.
Setting this value reasonably low improves user termination request reaction
time, which is valuable if data transmission is slow.
fd
Set file descriptor.
Note that some formats (typically MOV), require the output protocol to
be seekable, so they will fail with the pipe output protocol.
24.22 prompeg
Pro-MPEG Code of Practice #3 Release 2 FEC protocol.
The Pro-MPEG CoP#3 FEC is a 2D parity-check forward error correction mechanism
for MPEG-2 Transport Streams sent over RTP.
This protocol must be used in conjunction with the rtp_mpegts muxer and
the rtp protocol.
The required syntax is:
-f rtp_mpegts -fec prompeg=option=val... rtp://hostname:port
The destination UDP ports are port + 2 for the column FEC stream
and port + 4 for the row FEC stream.
This protocol accepts the following options:
l=n
The number of columns (4-20, LxD <= 100)
d=n
The number of rows (4-20, LxD <= 100)
Example usage:
-f rtp_mpegts -fec prompeg=l=8:d=4 rtp://hostname:port
24.23 rist
Reliable Internet Streaming Transport protocol
The accepted options are:
rist_profile
Supported values:
‘simple’
‘main’
This one is default.
‘advanced’
buffer_size
Set internal RIST buffer size in milliseconds for retransmission of data.
Default value is 0 which means the librist default (1 sec). Maximum value is 30
seconds.
fifo_size
Size of the librist receiver output fifo in number of packets. This must be a
power of 2.
Defaults to 8192 (vs the librist default of 1024).
overrun_nonfatal=1|0
Survive in case of librist fifo buffer overrun. Default value is 0.
pkt_size
Set maximum packet size for sending data. 1316 by default.
log_level
Set loglevel for RIST logging messages. You only need to set this if you
explicitly want to enable debug level messages or packet loss simulation,
otherwise the regular loglevel is respected.
secret
Set override of encryption secret, by default is unset.
encryption
Set encryption type, by default is disabled.
Acceptable values are 128 and 256.
24.24 rtmp
Real-Time Messaging Protocol.
The Real-Time Messaging Protocol (RTMP) is used for streaming multimedia
content across a TCP/IP network.
The required syntax is:
rtmp://[username:password@]server[:port][/app][/instance][/playpath]
The accepted parameters are:
username
An optional username (mostly for publishing).
password
An optional password (mostly for publishing).
server
The address of the RTMP server.
port
The number of the TCP port to use (by default is 1935).
app
It is the name of the application to access. It usually corresponds to
the path where the application is installed on the RTMP server
(e.g. /ondemand/, /flash/live/, etc.). You can override
the value parsed from the URI through the rtmp_app option, too.
playpath
It is the path or name of the resource to play with reference to the
application specified in app, may be prefixed by "mp4:". You
can override the value parsed from the URI through the rtmp_playpath
option, too.
listen
Act as a server, listening for an incoming connection.
timeout
Maximum time to wait for the incoming connection. Implies listen.
Additionally, the following parameters can be set via command line options
(or in code via AVOptions):
rtmp_app
Name of application to connect on the RTMP server. This option
overrides the parameter specified in the URI.
rtmp_buffer
Set the client buffer time in milliseconds. The default is 3000.
rtmp_conn
Extra arbitrary AMF connection parameters, parsed from a string,
e.g. like B:1 S:authMe O:1 NN:code:1.23 NS:flag:ok O:0.
Each value is prefixed by a single character denoting the type,
B for Boolean, N for number, S for string, O for object, or Z for null,
followed by a colon. For Booleans the data must be either 0 or 1 for
FALSE or TRUE, respectively.  Likewise for Objects the data must be 0 or
1 to end or begin an object, respectively. Data items in subobjects may
be named, by prefixing the type with ’N’ and specifying the name before
the value (i.e. NB:myFlag:1). This option may be used multiple
times to construct arbitrary AMF sequences.
rtmp_enhanced_codecs
Specify the list of codecs the client advertises to support in an
enhanced RTMP stream. This option should be set to a comma separated
list of fourcc values, like hvc1,av01,vp09 for multiple codecs
or hvc1 for only one codec. The specified list will be presented
in the "fourCcLive" property of the Connect Command Message.
rtmp_flashver
Version of the Flash plugin used to run the SWF player. The default
is LNX 9,0,124,2. (When publishing, the default is FMLE/3.0 (compatible;
<libavformat version>).)
rtmp_flush_interval
Number of packets flushed in the same request (RTMPT only). The default
is 10.
rtmp_live
Specify that the media is a live stream. No resuming or seeking in
live streams is possible. The default value is any, which means the
subscriber first tries to play the live stream specified in the
playpath. If a live stream of that name is not found, it plays the
recorded stream. The other possible values are live and
recorded.
rtmp_pageurl
URL of the web page in which the media was embedded. By default no
value will be sent.
rtmp_playpath
Stream identifier to play or to publish. This option overrides the
parameter specified in the URI.
rtmp_subscribe
Name of live stream to subscribe to. By default no value will be sent.
It is only sent if the option is specified or if rtmp_live
is set to live.
rtmp_swfhash
SHA256 hash of the decompressed SWF file (32 bytes).
rtmp_swfsize
Size of the decompressed SWF file, required for SWFVerification.
rtmp_swfurl
URL of the SWF player for the media. By default no value will be sent.
rtmp_swfverify
URL to player swf file, compute hash/size automatically.
rtmp_tcurl
URL of the target stream. Defaults to proto://host[:port]/app.
tcp_nodelay=1|0
Set TCP_NODELAY to disable Nagle’s algorithm. Default value is 0.
Remark: Writing to the socket is currently not optimized to minimize system calls and reduces the efficiency / effect of TCP_NODELAY.
For example to read with ffplay a multimedia resource named
"sample" from the application "vod" from an RTMP server "myserver":
ffplay rtmp://myserver/vod/sample
To publish to a password protected server, passing the playpath and
app names separately:
ffmpeg -re -i <input> -f flv -rtmp_playpath some/long/path -rtmp_app long/app/name rtmp://username:password@myserver/
24.25 rtmpe
Encrypted Real-Time Messaging Protocol.
The Encrypted Real-Time Messaging Protocol (RTMPE) is used for
streaming multimedia content within standard cryptographic primitives,
consisting of Diffie-Hellman key exchange and HMACSHA256, generating
a pair of RC4 keys.
24.26 rtmps
Real-Time Messaging Protocol over a secure SSL connection.
The Real-Time Messaging Protocol (RTMPS) is used for streaming
multimedia content across an encrypted connection.
24.27 rtmpt
Real-Time Messaging Protocol tunneled through HTTP.
The Real-Time Messaging Protocol tunneled through HTTP (RTMPT) is used
for streaming multimedia content within HTTP requests to traverse
firewalls.
24.28 rtmpte
Encrypted Real-Time Messaging Protocol tunneled through HTTP.
The Encrypted Real-Time Messaging Protocol tunneled through HTTP (RTMPTE)
is used for streaming multimedia content within HTTP requests to traverse
firewalls.
24.29 rtmpts
Real-Time Messaging Protocol tunneled through HTTPS.
The Real-Time Messaging Protocol tunneled through HTTPS (RTMPTS) is used
for streaming multimedia content within HTTPS requests to traverse
firewalls.
24.30 libsmbclient
libsmbclient permits one to manipulate CIFS/SMB network resources.
Following syntax is required.
smb://[[domain:]user[:password@]]server[/share[/path[/file]]]
This protocol accepts the following options.
timeout
Set timeout in milliseconds of socket I/O operations used by the underlying
low level operation. By default it is set to -1, which means that the timeout
is not specified.
truncate
Truncate existing files on write, if set to 1. A value of 0 prevents
truncating. Default value is 1.
workgroup
Set the workgroup used for making connections. By default workgroup is not specified.
For more information see: http://www.samba.org/.
24.31 libssh
Secure File Transfer Protocol via libssh
Read from or write to remote resources using SFTP protocol.
Following syntax is required.
sftp://[user[:password]@]server[:port]/path/to/remote/resource.mpeg
This protocol accepts the following options.
timeout
Set timeout of socket I/O operations used by the underlying low level
operation. By default it is set to -1, which means that the timeout
is not specified.
truncate
Truncate existing files on write, if set to 1. A value of 0 prevents
truncating. Default value is 1.
private_key
Specify the path of the file containing private key to use during authorization.
By default libssh searches for keys in the ~/.ssh/ directory.
Example: Play a file stored on remote server.
ffplay sftp://user:password@server_address:22/home/user/resource.mpeg
24.32 librtmp rtmp, rtmpe, rtmps, rtmpt, rtmpte
Real-Time Messaging Protocol and its variants supported through
librtmp.
Requires the presence of the librtmp headers and library during
configuration. You need to explicitly configure the build with
"–enable-librtmp". If enabled this will replace the native RTMP
protocol.
This protocol provides most client functions and a few server
functions needed to support RTMP, RTMP tunneled in HTTP (RTMPT),
encrypted RTMP (RTMPE), RTMP over SSL/TLS (RTMPS) and tunneled
variants of these encrypted types (RTMPTE, RTMPTS).
The required syntax is:
rtmp_proto://server[:port][/app][/playpath] options
where rtmp_proto is one of the strings "rtmp", "rtmpt", "rtmpe",
"rtmps", "rtmpte", "rtmpts" corresponding to each RTMP variant, and
server, port, app and playpath have the same
meaning as specified for the RTMP native protocol.
options contains a list of space-separated options of the form
key=val.
See the librtmp manual page (man 3 librtmp) for more information.
For example, to stream a file in real-time to an RTMP server using
ffmpeg:
ffmpeg -re -i myfile -f flv rtmp://myserver/live/mystream
To play the same stream using ffplay:
ffplay "rtmp://myserver/live/mystream live=1"
24.33 rtp
Real-time Transport Protocol.
The required syntax for an RTP URL is:
rtp://hostname[:port][?options]
port specifies the RTP port to use.
options contains a list of &-separated options of the form
key=val.
The following URL options are supported:
ttl=n
Set the TTL (Time-To-Live) value (for multicast only).
rtcpport=n
Set the remote RTCP port to n.
localrtpport=n
Set the local RTP port to n.
localrtcpport=n'
Set the local RTCP port to n.
pkt_size=n
Set max packet size (in bytes) to n.
buffer_size=size
Set the maximum UDP socket buffer size in bytes.
connect=0|1
Do a connect() on the UDP socket (if set to 1) or not (if set
to 0).
sources=ip[,ip]
List allowed source IP addresses.
block=ip[,ip]
List disallowed (blocked) source IP addresses.
write_to_source=0|1
Send packets to the source address of the latest received packet (if
set to 1) or to a default remote address (if set to 0).
localport=n
Set the local RTP port to n.
This is a deprecated option. Instead, localrtpport should be
used.
localaddr=addr
Local IP address of a network interface used for sending packets or joining
multicast groups.
timeout=n
Set timeout (in microseconds) of socket I/O operations to n.
Important notes:
If rtcpport is not set the RTCP port will be set to the RTP
port value plus 1.
If localrtpport (the local RTP port) is not set any available
port will be used for the local RTP and RTCP ports.
If localrtcpport (the local RTCP port) is not set it will be
set to the local RTP port value plus 1.
24.34 rtsp
Real-Time Streaming Protocol.
RTSP is not technically a protocol handler in libavformat, it is a demuxer
and muxer. The demuxer supports both normal RTSP (with data transferred
over RTP; this is used by e.g. Apple and Microsoft) and Real-RTSP (with
data transferred over RDT).
The muxer can be used to send a stream using RTSP ANNOUNCE to a server
supporting it (currently Darwin Streaming Server and Mischa Spiegelmock’s
RTSP server).
The required syntax for a RTSP url is:
rtsp://hostname[:port]/path
Options can be set on the ffmpeg/ffplay command
line, or set in code via AVOptions or in
avformat_open_input.
24.34.1 Muxer
The following options are supported.
rtsp_transport
Set RTSP transport protocols.
It accepts the following values:
‘udp’
Use UDP as lower transport protocol.
‘tcp’
Use TCP (interleaving within the RTSP control channel) as lower
transport protocol.
Default value is ‘0’.
rtsp_flags
Set RTSP flags.
The following values are accepted:
‘latm’
Use MP4A-LATM packetization instead of MPEG4-GENERIC for AAC.
‘rfc2190’
Use RFC 2190 packetization instead of RFC 4629 for H.263.
‘skip_rtcp’
Don’t send RTCP sender reports.
‘h264_mode0’
Use mode 0 for H.264 in RTP.
‘send_bye’
Send RTCP BYE packets when finishing.
Default value is ‘0’.
min_port
Set minimum local UDP port. Default value is 5000.
max_port
Set maximum local UDP port. Default value is 65000.
buffer_size
Set the maximum socket buffer size in bytes.
pkt_size
Set max send packet size (in bytes). Default value is 1472.
24.34.2 Demuxer
The following options are supported.
initial_pause
Do not start playing the stream immediately if set to 1. Default value
is 0.
rtsp_transport
Set RTSP transport protocols.
It accepts the following values:
‘udp’
Use UDP as lower transport protocol.
‘tcp’
Use TCP (interleaving within the RTSP control channel) as lower
transport protocol.
‘udp_multicast’
Use UDP multicast as lower transport protocol.
‘http’
Use HTTP tunneling as lower transport protocol, which is useful for
passing proxies.
‘https’
Use HTTPs tunneling as lower transport protocol, which is useful for
passing proxies and widely used for security consideration.
Multiple lower transport protocols may be specified, in that case they are
tried one at a time (if the setup of one fails, the next one is tried).
For the muxer, only the ‘tcp’ and ‘udp’ options are supported.
rtsp_flags
Set RTSP flags.
The following values are accepted:
‘filter_src’
Accept packets only from negotiated peer address and port.
‘listen’
Act as a server, listening for an incoming connection.
‘prefer_tcp’
Try TCP for RTP transport first, if TCP is available as RTSP RTP transport.
‘satip_raw’
Export raw MPEG-TS stream instead of demuxing. The flag will simply write out
the raw stream, with the original PAT/PMT/PIDs intact.
Default value is ‘none’.
allowed_media_types
Set media types to accept from the server.
The following flags are accepted:
‘video’
‘audio’
‘data’
‘subtitle’
By default it accepts all media types.
min_port
Set minimum local UDP port. Default value is 5000.
max_port
Set maximum local UDP port. Default value is 65000.
listen_timeout
Set maximum timeout (in seconds) to establish an initial connection. Setting
listen_timeout > 0 sets rtsp_flags to ‘listen’. Default is -1
which means an infinite timeout when ‘listen’ mode is set.
reorder_queue_size
Set number of packets to buffer for handling of reordered packets.
timeout
Set socket TCP I/O timeout in microseconds.
user_agent
Override User-Agent header. If not specified, it defaults to the
libavformat identifier string.
buffer_size
Set the maximum socket buffer size in bytes.
When receiving data over UDP, the demuxer tries to reorder received packets
(since they may arrive out of order, or packets may get lost totally). This
can be disabled by setting the maximum demuxing delay to zero (via
the max_delay field of AVFormatContext).
When watching multi-bitrate Real-RTSP streams with ffplay, the
streams to display can be chosen with -vst n and
-ast n for video and audio respectively, and can be switched
on the fly by pressing v and a.
24.34.3 Examples
The following examples all make use of the ffplay and
ffmpeg tools.
Watch a stream over UDP, with a max reordering delay of 0.5 seconds:
ffplay -max_delay 500000 -rtsp_transport udp rtsp://server/video.mp4
Watch a stream tunneled over HTTP:
ffplay -rtsp_transport http rtsp://server/video.mp4
Send a stream in realtime to a RTSP server, for others to watch:
ffmpeg -re -i input -f rtsp -muxdelay 0.1 rtsp://server/live.sdp
Receive a stream in realtime:
ffmpeg -rtsp_flags listen -i rtsp://ownaddress/live.sdp output
24.35 sap
Session Announcement Protocol (RFC 2974). This is not technically a
protocol handler in libavformat, it is a muxer and demuxer.
It is used for signalling of RTP streams, by announcing the SDP for the
streams regularly on a separate port.
24.35.1 Muxer
The syntax for a SAP url given to the muxer is:
sap://destination[:port][?options]
The RTP packets are sent to destination on port port,
or to port 5004 if no port is specified.
options is a &-separated list. The following options
are supported:
announce_addr=address
Specify the destination IP address for sending the announcements to.
If omitted, the announcements are sent to the commonly used SAP
announcement multicast address 224.2.127.254 (sap.mcast.net), or
ff0e::2:7ffe if destination is an IPv6 address.
announce_port=port
Specify the port to send the announcements on, defaults to
9875 if not specified.
ttl=ttl
Specify the time to live value for the announcements and RTP packets,
defaults to 255.
same_port=0|1
If set to 1, send all RTP streams on the same port pair. If zero (the
default), all streams are sent on unique ports, with each stream on a
port 2 numbers higher than the previous.
VLC/Live555 requires this to be set to 1, to be able to receive the stream.
The RTP stack in libavformat for receiving requires all streams to be sent
on unique ports.
Example command lines follow.
To broadcast a stream on the local subnet, for watching in VLC:
ffmpeg -re -i input -f sap sap://224.0.0.255?same_port=1
Similarly, for watching in ffplay:
ffmpeg -re -i input -f sap sap://224.0.0.255
And for watching in ffplay, over IPv6:
ffmpeg -re -i input -f sap sap://[ff0e::1:2:3:4]
24.35.2 Demuxer
The syntax for a SAP url given to the demuxer is:
sap://[address][:port]
address is the multicast address to listen for announcements on,
if omitted, the default 224.2.127.254 (sap.mcast.net) is used. port
is the port that is listened on, 9875 if omitted.
The demuxers listens for announcements on the given address and port.
Once an announcement is received, it tries to receive that particular stream.
Example command lines follow.
To play back the first stream announced on the normal SAP multicast address:
ffplay sap://
To play back the first stream announced on one the default IPv6 SAP multicast address:
ffplay sap://[ff0e::2:7ffe]
24.36 sctp
Stream Control Transmission Protocol.
The accepted URL syntax is:
sctp://host:port[?options]
The protocol accepts the following options:
listen
If set to any value, listen for an incoming connection. Outgoing connection is done by default.
max_streams
Set the maximum number of streams. By default no limit is set.
24.37 srt
Haivision Secure Reliable Transport Protocol via libsrt.
The supported syntax for a SRT URL is:
srt://hostname:port[?options]
options contains a list of &-separated options of the form
key=val.
or
options srt://hostname:port
options contains a list of ’-key val’
options.
This protocol accepts the following options.
connect_timeout=milliseconds
Connection timeout; SRT cannot connect for RTT > 1500 msec
(2 handshake exchanges) with the default connect timeout of
3 seconds. This option applies to the caller and rendezvous
connection modes. The connect timeout is 10 times the value
set for the rendezvous mode (which can be used as a
workaround for this connection problem with earlier versions).
ffs=bytes
Flight Flag Size (Window Size), in bytes. FFS is actually an
internal parameter and you should set it to not less than
recv_buffer_size and mss. The default value
is relatively large, therefore unless you set a very large receiver buffer,
you do not need to change this option. Default value is 25600.
inputbw=bytes/seconds
Sender nominal input rate, in bytes per seconds. Used along with
oheadbw, when maxbw is set to relative (0), to
calculate maximum sending rate when recovery packets are sent
along with the main media stream:
inputbw * (100 + oheadbw) / 100
if inputbw is not set while maxbw is set to
relative (0), the actual input rate is evaluated inside
the library. Default value is 0.
iptos=tos
IP Type of Service. Applies to sender only. Default value is 0xB8.
ipttl=ttl
IP Time To Live. Applies to sender only. Default value is 64.
latency=microseconds
Timestamp-based Packet Delivery Delay.
Used to absorb bursts of missed packet retransmissions.
This flag sets both rcvlatency and peerlatency
to the same value. Note that prior to version 1.3.0
this is the only flag to set the latency, however
this is effectively equivalent to setting peerlatency,
when side is sender and rcvlatency
when side is receiver, and the bidirectional stream
sending is not supported.
listen_timeout=microseconds
Set socket listen timeout.
maxbw=bytes/seconds
Maximum sending bandwidth, in bytes per seconds.
-1 infinite (CSRTCC limit is 30mbps)
0 relative to input rate (see inputbw)
>0 absolute limit value
Default value is 0 (relative)
mode=caller|listener|rendezvous
Connection mode.
caller opens client connection.
listener starts server to listen for incoming connections.
rendezvous use Rendez-Vous connection mode.
Default value is caller.
mss=bytes
Maximum Segment Size, in bytes. Used for buffer allocation
and rate calculation using a packet counter assuming fully
filled packets. The smallest MSS between the peers is
used. This is 1500 by default in the overall internet.
This is the maximum size of the UDP packet and can be
only decreased, unless you have some unusual dedicated
network settings. Default value is 1500.
nakreport=1|0
If set to 1, Receiver will send ‘UMSG_LOSSREPORT‘ messages
periodically until a lost packet is retransmitted or
intentionally dropped. Default value is 1.
oheadbw=percents
Recovery bandwidth overhead above input rate, in percents.
See inputbw. Default value is 25%.
passphrase=string
HaiCrypt Encryption/Decryption Passphrase string, length
from 10 to 79 characters. The passphrase is the shared
secret between the sender and the receiver. It is used
to generate the Key Encrypting Key using PBKDF2
(Password-Based Key Derivation Function). It is used
only if pbkeylen is non-zero. It is used on
the receiver only if the received data is encrypted.
The configured passphrase cannot be recovered (write-only).
enforced_encryption=1|0
If true, both connection parties must have the same password
set (including empty, that is, with no encryption). If the
password doesn’t match or only one side is unencrypted,
the connection is rejected. Default is true.
kmrefreshrate=packets
The number of packets to be transmitted after which the
encryption key is switched to a new key. Default is -1.
-1 means auto (0x1000000 in srt library). The range for
this option is integers in the 0 - INT_MAX.
kmpreannounce=packets
The interval between when a new encryption key is sent and
when switchover occurs. This value also applies to the
subsequent interval between when switchover occurs and
when the old encryption key is decommissioned. Default is -1.
-1 means auto (0x1000 in srt library). The range for
this option is integers in the 0 - INT_MAX.
snddropdelay=microseconds
The sender’s extra delay before dropping packets. This delay is
added to the default drop delay time interval value.
Special value -1: Do not drop packets on the sender at all.
payload_size=bytes
Sets the maximum declared size of a packet transferred
during the single call to the sending function in Live
mode. Use 0 if this value isn’t used (which is default in
file mode).
Default is -1 (automatic), which typically means MPEG-TS;
if you are going to use SRT
to send any different kind of payload, such as, for example,
wrapping a live stream in very small frames, then you can
use a bigger maximum frame size, though not greater than
1456 bytes.
pkt_size=bytes
Alias for ‘payload_size’.
peerlatency=microseconds
The latency value (as described in rcvlatency) that is
set by the sender side as a minimum value for the receiver.
pbkeylen=bytes
Sender encryption key length, in bytes.
Only can be set to 0, 16, 24 and 32.
Enable sender encryption if not 0.
Not required on receiver (set to 0),
key size obtained from sender in HaiCrypt handshake.
Default value is 0.
rcvlatency=microseconds
The time that should elapse since the moment when the
packet was sent and the moment when it’s delivered to
the receiver application in the receiving function.
This time should be a buffer time large enough to cover
the time spent for sending, unexpectedly extended RTT
time, and the time needed to retransmit the lost UDP
packet. The effective latency value will be the maximum
of this options’ value and the value of peerlatency
set by the peer side. Before version 1.3.0 this option
is only available as latency.
recv_buffer_size=bytes
Set UDP receive buffer size, expressed in bytes.
send_buffer_size=bytes
Set UDP send buffer size, expressed in bytes.
timeout=microseconds
Set raise error timeouts for read, write and connect operations. Note that the
SRT library has internal timeouts which can be controlled separately, the
value set here is only a cap on those.
tlpktdrop=1|0
Too-late Packet Drop. When enabled on receiver, it skips
missing packets that have not been delivered in time and
delivers the following packets to the application when
their time-to-play has come. It also sends a fake ACK to
the sender. When enabled on sender and enabled on the
receiving peer, the sender drops the older packets that
have no chance of being delivered in time. It was
automatically enabled in the sender if the receiver
supports it.
sndbuf=bytes
Set send buffer size, expressed in bytes.
rcvbuf=bytes
Set receive buffer size, expressed in bytes.
Receive buffer must not be greater than ffs.
lossmaxttl=packets
The value up to which the Reorder Tolerance may grow. When
Reorder Tolerance is > 0, then packet loss report is delayed
until that number of packets come in. Reorder Tolerance
increases every time a "belated" packet has come, but it
wasn’t due to retransmission (that is, when UDP packets tend
to come out of order), with the difference between the latest
sequence and this packet’s sequence, and not more than the
value of this option. By default it’s 0, which means that this
mechanism is turned off, and the loss report is always sent
immediately upon experiencing a "gap" in sequences.
minversion
The minimum SRT version that is required from the peer. A connection
to a peer that does not satisfy the minimum version requirement
will be rejected.
The version format in hex is 0xXXYYZZ for x.y.z in human readable
form.
streamid=string
A string limited to 512 characters that can be set on the socket prior
to connecting. This stream ID will be able to be retrieved by the
listener side from the socket that is returned from srt_accept and
was connected by a socket with that set stream ID. SRT does not enforce
any special interpretation of the contents of this string.
This option doesn’t make sense in Rendezvous connection; the result
might be that simply one side will override the value from the other
side and it’s the matter of luck which one would win
srt_streamid=string
Alias for ‘streamid’ to avoid conflict with ffmpeg command line option.
smoother=live|file
The type of Smoother used for the transmission for that socket, which
is responsible for the transmission and congestion control. The Smoother
type must be exactly the same on both connecting parties, otherwise
the connection is rejected.
messageapi=1|0
When set, this socket uses the Message API, otherwise it uses Buffer
API. Note that in live mode (see transtype) there’s only
message API available. In File mode you can chose to use one of two modes:
Stream API (default, when this option is false). In this mode you may
send as many data as you wish with one sending instruction, or even use
dedicated functions that read directly from a file. The internal facility
will take care of any speed and congestion control. When receiving, you
can also receive as many data as desired, the data not extracted will be
waiting for the next call. There is no boundary between data portions in
the Stream mode.
Message API. In this mode your single sending instruction passes exactly
one piece of data that has boundaries (a message). Contrary to Live mode,
this message may span across multiple UDP packets and the only size
limitation is that it shall fit as a whole in the sending buffer. The
receiver shall use as large buffer as necessary to receive the message,
otherwise the message will not be given up. When the message is not
complete (not all packets received or there was a packet loss) it will
not be given up.
transtype=live|file
Sets the transmission type for the socket, in particular, setting this
option sets multiple other parameters to their default values as required
for a particular transmission type.
live: Set options as for live transmission. In this mode, you should
send by one sending instruction only so many data that fit in one UDP packet,
and limited to the value defined first in payload_size (1316 is
default in this mode). There is no speed control in this mode, only the
bandwidth control, if configured, in order to not exceed the bandwidth with
the overhead transmission (retransmitted and control packets).
file: Set options as for non-live transmission. See messageapi
for further explanations
linger=seconds
The number of seconds that the socket waits for unsent data when closing.
Default is -1. -1 means auto (off with 0 seconds in live mode, on with 180
seconds in file mode). The range for this option is integers in the
0 - INT_MAX.
tsbpd=1|0
When true, use Timestamp-based Packet Delivery mode. The default behavior
depends on the transmission type: enabled in live mode, disabled in file
mode.
For more information see: https://github.com/Haivision/srt.
24.38 srtp
Secure Real-time Transport Protocol.
The accepted options are:
srtp_in_suite
srtp_out_suite
Select input and output encoding suites.
Supported values:
‘AES_CM_128_HMAC_SHA1_80’
‘SRTP_AES128_CM_HMAC_SHA1_80’
‘AES_CM_128_HMAC_SHA1_32’
‘SRTP_AES128_CM_HMAC_SHA1_32’
srtp_in_params
srtp_out_params
Set input and output encoding parameters, which are expressed by a
base64-encoded representation of a binary block. The first 16 bytes of
this binary block are used as master key, the following 14 bytes are
used as master salt.
24.39 subfile
Virtually extract a segment of a file or another stream.
The underlying stream must be seekable.
Accepted options:
start
Start offset of the extracted segment, in bytes.
end
End offset of the extracted segment, in bytes.
If set to 0, extract till end of file.
Examples:
Extract a chapter from a DVD VOB file (start and end sectors obtained
externally and multiplied by 2048):
subfile,,start,153391104,end,268142592,,:/media/dvd/VIDEO_TS/VTS_08_1.VOB
Play an AVI file directly from a TAR archive:
subfile,,start,183241728,end,366490624,,:archive.tar
Play a MPEG-TS file from start offset till end:
subfile,,start,32815239,end,0,,:video.ts
24.40 tee
Writes the output to multiple protocols. The individual outputs are separated
by |
tee:file://path/to/local/this.avi|file://path/to/local/that.avi
24.41 tcp
Transmission Control Protocol.
The required syntax for a TCP url is:
tcp://hostname:port[?options]
options contains a list of &-separated options of the form
key=val.
The list of supported options follows.
listen=2|1|0
Listen for an incoming connection. 0 disables listen, 1 enables listen in
single client mode, 2 enables listen in multi-client mode. Default value is 0.
local_addr=addr
Local IP address of a network interface used for tcp socket connect.
local_port=port
Local port used for tcp socket connect.
timeout=microseconds
Set raise error timeout, expressed in microseconds.
This option is only relevant in read mode: if no data arrived in more
than this time interval, raise error.
listen_timeout=milliseconds
Set listen timeout, expressed in milliseconds.
recv_buffer_size=bytes
Set receive buffer size, expressed bytes.
send_buffer_size=bytes
Set send buffer size, expressed bytes.
tcp_nodelay=1|0
Set TCP_NODELAY to disable Nagle’s algorithm. Default value is 0.
Remark: Writing to the socket is currently not optimized to minimize system calls and reduces the efficiency / effect of TCP_NODELAY.
tcp_mss=bytes
Set maximum segment size for outgoing TCP packets, expressed in bytes.
The following example shows how to setup a listening TCP connection
with ffmpeg, which is then accessed with ffplay:
ffmpeg -i input -f format tcp://hostname:port?listen
ffplay tcp://hostname:port
24.42 tls
Transport Layer Security (TLS) / Secure Sockets Layer (SSL)
The required syntax for a TLS/SSL url is:
tls://hostname:port[?options]
The following parameters can be set via command line options
(or in code via AVOptions):
ca_file, cafile=filename
A file containing certificate authority (CA) root certificates to treat
as trusted. If the linked TLS library contains a default this might not
need to be specified for verification to work, but not all libraries and
setups have defaults built in.
The file must be in OpenSSL PEM format.
tls_verify=1|0
If enabled, try to verify the peer that we are communicating with.
Note, if using OpenSSL, this currently only makes sure that the
peer certificate is signed by one of the root certificates in the CA
database, but it does not validate that the certificate actually
matches the host name we are trying to connect to. (With other backends,
the host name is validated as well.)
This is disabled by default since it requires a CA database to be
provided by the caller in many cases.
cert_file, cert=filename
A file containing a certificate to use in the handshake with the peer.
(When operating as server, in listen mode, this is more often required
by the peer, while client certificates only are mandated in certain
setups.)
key_file, key=filename
A file containing the private key for the certificate.
listen=1|0
If enabled, listen for connections on the provided port, and assume
the server role in the handshake instead of the client role.
http_proxy
The HTTP proxy to tunnel through, e.g. http://example.com:1234.
The proxy must support the CONNECT method.
Example command lines:
To create a TLS/SSL server that serves an input stream.
ffmpeg -i input -f format tls://hostname:port?listen&cert=server.crt&key=server.key
To play back a stream from the TLS/SSL server using ffplay:
ffplay tls://hostname:port
24.43 udp
User Datagram Protocol.
The required syntax for an UDP URL is:
udp://hostname:port[?options]
options contains a list of &-separated options of the form key=val.
In case threading is enabled on the system, a circular buffer is used
to store the incoming data, which allows one to reduce loss of data due to
UDP socket buffer overruns. The fifo_size and
overrun_nonfatal options are related to this buffer.
The list of supported options follows.
buffer_size=size
Set the UDP maximum socket buffer size in bytes. This is used to set either
the receive or send buffer size, depending on what the socket is used for.
Default is 32 KB for output, 384 KB for input.  See also fifo_size.
bitrate=bitrate
If set to nonzero, the output will have the specified constant bitrate if the
input has enough packets to sustain it.
burst_bits=bits
When using bitrate this specifies the maximum number of bits in
packet bursts.
localport=port
Override the local UDP port to bind with.
localaddr=addr
Local IP address of a network interface used for sending packets or joining
multicast groups.
pkt_size=size
Set the size in bytes of UDP packets.
reuse=1|0
Explicitly allow or disallow reusing UDP sockets.
ttl=ttl
Set the time to live value (for multicast only).
connect=1|0
Initialize the UDP socket with connect(). In this case, the
destination address can’t be changed with ff_udp_set_remote_url later.
If the destination address isn’t known at the start, this option can
be specified in ff_udp_set_remote_url, too.
This allows finding out the source address for the packets with getsockname,
and makes writes return with AVERROR(ECONNREFUSED) if "destination
unreachable" is received.
For receiving, this gives the benefit of only receiving packets from
the specified peer address/port.
sources=address[,address]
Only receive packets sent from the specified addresses. In case of multicast,
also subscribe to multicast traffic coming from these addresses only.
block=address[,address]
Ignore packets sent from the specified addresses. In case of multicast, also
exclude the source addresses in the multicast subscription.
fifo_size=units
Set the UDP receiving circular buffer size, expressed as a number of
packets with size of 188 bytes. If not specified defaults to 7*4096.
overrun_nonfatal=1|0
Survive in case of UDP receiving circular buffer overrun. Default
value is 0.
timeout=microseconds
Set raise error timeout, expressed in microseconds.
This option is only relevant in read mode: if no data arrived in more
than this time interval, raise error.
broadcast=1|0
Explicitly allow or disallow UDP broadcasting.
Note that broadcasting may not work properly on networks having
a broadcast storm protection.
24.43.1 Examples
Use ffmpeg to stream over UDP to a remote endpoint:
ffmpeg -i input -f format udp://hostname:port
Use ffmpeg to stream in mpegts format over UDP using 188
sized UDP packets, using a large input buffer:
ffmpeg -i input -f mpegts udp://hostname:port?pkt_size=188&buffer_size=65535
Use ffmpeg to receive over UDP from a remote endpoint:
ffmpeg -i udp://[multicast-address]:port ...
24.44 unix
Unix local socket
The required syntax for a Unix socket URL is:
unix://filepath
The following parameters can be set via command line options
(or in code via AVOptions):
timeout
Timeout in ms.
listen
Create the Unix socket in listening mode.
24.45 zmq
ZeroMQ asynchronous messaging using the libzmq library.
This library supports unicast streaming to multiple clients without relying on
an external server.
The required syntax for streaming or connecting to a stream is:
zmq:tcp://ip-address:port
Example:
Create a localhost stream on port 5555:
ffmpeg -re -i input -f mpegts zmq:tcp://127.0.0.1:5555
Multiple clients may connect to the stream using:
ffplay zmq:tcp://127.0.0.1:5555
Streaming to multiple clients is implemented using a ZeroMQ Pub-Sub pattern.
The server side binds to a port and publishes data. Clients connect to the
server (via IP address/port) and subscribe to the stream. The order in which
the server and client start generally does not matter.
ffmpeg must be compiled with the –enable-libzmq option to support
this protocol.
Options can be set on the ffmpeg/ffplay command
line. The following options are supported:
pkt_size
Forces the maximum packet size for sending/receiving data. The default value is
131,072 bytes. On the server side, this sets the maximum size of sent packets
via ZeroMQ. On the clients, it sets an internal buffer size for receiving
packets. Note that pkt_size on the clients should be equal to or greater than
pkt_size on the server. Otherwise the received message may be truncated causing
decoding errors.
25 Device Options
The libavdevice library provides the same interface as
libavformat. Namely, an input device is considered like a demuxer, and
an output device like a muxer, and the interface and generic device
options are the same provided by libavformat (see the ffmpeg-formats
manual).
In addition each input or output device may support so-called private
options, which are specific for that component.
Options may be set by specifying -option value in the
FFmpeg tools, or by setting the value explicitly in the device
AVFormatContext options or using the libavutil/opt.h API
for programmatic use.
26 Input Devices
Input devices are configured elements in FFmpeg which enable accessing
the data coming from a multimedia device attached to your system.
When you configure your FFmpeg build, all the supported input devices
are enabled by default. You can list all available ones using the
configure option "–list-indevs".
You can disable all the input devices using the configure option
"–disable-indevs", and selectively enable an input device using the
option "–enable-indev=INDEV", or you can disable a particular
input device using the option "–disable-indev=INDEV".
The option "-devices" of the ff* tools will display the list of
supported input devices.
A description of the currently available input devices follows.
26.1 alsa
ALSA (Advanced Linux Sound Architecture) input device.
To enable this input device during configuration you need libasound
installed on your system.
This device allows capturing from an ALSA device. The name of the
device to capture has to be an ALSA card identifier.
An ALSA identifier has the syntax:
hw:CARD[,DEV[,SUBDEV]]
where the DEV and SUBDEV components are optional.
The three arguments (in order: CARD,DEV,SUBDEV)
specify card number or identifier, device number and subdevice number
(-1 means any).
To see the list of cards currently recognized by your system check the
files /proc/asound/cards and /proc/asound/devices.
For example to capture with ffmpeg from an ALSA device with
card id 0, you may run the command:
ffmpeg -f alsa -i hw:0 alsaout.wav
For more information see:
http://www.alsa-project.org/alsa-doc/alsa-lib/pcm.html
26.1.1 Options
sample_rate
Set the sample rate in Hz. Default is 48000.
channels
Set the number of channels. Default is 2.
26.2 android_camera
Android camera input device.
This input devices uses the Android Camera2 NDK API which is
available on devices with API level 24+. The availability of
android_camera is autodetected during configuration.
This device allows capturing from all cameras on an Android device,
which are integrated into the Camera2 NDK API.
The available cameras are enumerated internally and can be selected
with the camera_index parameter. The input file string is
discarded.
Generally the back facing camera has index 0 while the front facing
camera has index 1.
26.2.1 Options
video_size
Set the video size given as a string such as 640x480 or hd720.
Falls back to the first available configuration reported by
Android if requested video size is not available or by default.
framerate
Set the video framerate.
Falls back to the first available configuration reported by
Android if requested framerate is not available or by default (-1).
camera_index
Set the index of the camera to use. Default is 0.
input_queue_size
Set the maximum number of frames to buffer. Default is 5.
26.3 avfoundation
AVFoundation input device.
AVFoundation is the currently recommended framework by Apple for streamgrabbing on OSX >= 10.7 as well as on iOS.
The input filename has to be given in the following syntax:
-i "[[VIDEO]:[AUDIO]]"
The first entry selects the video input while the latter selects the audio input.
The stream has to be specified by the device name or the device index as shown by the device list.
Alternatively, the video and/or audio input device can be chosen by index using the
-video_device_index <INDEX>
and/or
-audio_device_index <INDEX>
, overriding any
device name or index given in the input filename.
All available devices can be enumerated by using -list_devices true, listing
all device names and corresponding indices.
There are two device name aliases:
default
Select the AVFoundation default device of the corresponding type.
none
Do not record the corresponding media type.
This is equivalent to specifying an empty device name or index.
26.3.1 Options
AVFoundation supports the following options:
-list_devices <TRUE|FALSE>
If set to true, a list of all available input devices is given showing all
device names and indices.
-video_device_index <INDEX>
Specify the video device by its index. Overrides anything given in the input filename.
-audio_device_index <INDEX>
Specify the audio device by its index. Overrides anything given in the input filename.
-pixel_format <FORMAT>
Request the video device to use a specific pixel format.
If the specified format is not supported, a list of available formats is given
and the first one in this list is used instead. Available pixel formats are:
monob, rgb555be, rgb555le, rgb565be, rgb565le, rgb24, bgr24, 0rgb, bgr0, 0bgr, rgb0,
bgr48be, uyvy422, yuva444p, yuva444p16le, yuv444p, yuv422p16, yuv422p10, yuv444p10,
yuv420p, nv12, yuyv422, gray
-framerate
Set the grabbing frame rate. Default is ntsc, corresponding to a
frame rate of 30000/1001.
-video_size
Set the video frame size.
-capture_cursor
Capture the mouse pointer. Default is 0.
-capture_mouse_clicks
Capture the screen mouse clicks. Default is 0.
-capture_raw_data
Capture the raw device data. Default is 0.
Using this option may result in receiving the underlying data delivered to the AVFoundation framework. E.g. for muxed devices that sends raw DV data to the framework (like tape-based camcorders), setting this option to false results in extracted video frames captured in the designated pixel format only. Setting this option to true results in receiving the raw DV stream untouched.
26.3.2 Examples
Print the list of AVFoundation supported devices and exit:
$ ffmpeg -f avfoundation -list_devices true -i ""
Record video from video device 0 and audio from audio device 0 into out.avi:
$ ffmpeg -f avfoundation -i "0:0" out.avi
Record video from video device 2 and audio from audio device 1 into out.avi:
$ ffmpeg -f avfoundation -video_device_index 2 -i ":1" out.avi
Record video from the system default video device using the pixel format bgr0 and do not record any audio into out.avi:
$ ffmpeg -f avfoundation -pixel_format bgr0 -i "default:none" out.avi
Record raw DV data from a suitable input device and write the output into out.dv:
$ ffmpeg -f avfoundation -capture_raw_data true -i "zr100:none" out.dv
26.4 bktr
BSD video input device. Deprecated and will be removed - please contact
the developers if you are interested in maintaining it.
26.4.1 Options
framerate
Set the frame rate.
video_size
Set the video frame size. Default is vga.
standard
Available values are:
‘pal’
‘ntsc’
‘secam’
‘paln’
‘palm’
‘ntscj’
26.5 decklink
The decklink input device provides capture capabilities for Blackmagic
DeckLink devices.
To enable this input device, you need the Blackmagic DeckLink SDK and you
need to configure with the appropriate --extra-cflags
and --extra-ldflags.
On Windows, you need to run the IDL files through widl.
DeckLink is very picky about the formats it supports. Pixel format of the
input can be set with raw_format.
Framerate and video size must be determined for your device with
-list_formats 1. Audio sample rate is always 48 kHz and the number
of channels can be 2, 8 or 16. Note that all audio channels are bundled in one single
audio track.
26.5.1 Options
list_devices
If set to true, print a list of devices and exit.
Defaults to false. This option is deprecated, please use the
-sources option of ffmpeg to list the available input devices.
list_formats
If set to true, print a list of supported formats and exit.
Defaults to false.
format_code <FourCC>
This sets the input video format to the format given by the FourCC. To see
the supported values of your device(s) use list_formats.
Note that there is a FourCC 'pal ' that can also be used
as pal (3 letters).
Default behavior is autodetection of the input video format, if the hardware
supports it.
raw_format
Set the pixel format of the captured video.
Available values are:
‘auto’
This is the default which means 8-bit YUV 422 or 8-bit ARGB if format
autodetection is used, 8-bit YUV 422 otherwise.
‘uyvy422’
8-bit YUV 422.
‘yuv422p10’
10-bit YUV 422.
‘argb’
8-bit RGB.
‘bgra’
8-bit RGB.
‘rgb10’
10-bit RGB.
teletext_lines
If set to nonzero, an additional teletext stream will be captured from the
vertical ancillary data. Both SD PAL (576i) and HD (1080i or 1080p)
sources are supported. In case of HD sources, OP47 packets are decoded.
This option is a bitmask of the SD PAL VBI lines captured, specifically lines 6
to 22, and lines 318 to 335. Line 6 is the LSB in the mask. Selected lines
which do not contain teletext information will be ignored. You can use the
special all constant to select all possible lines, or
standard to skip lines 6, 318 and 319, which are not compatible with
all receivers.
For SD sources, ffmpeg needs to be compiled with --enable-libzvbi. For
HD sources, on older (pre-4K) DeckLink card models you have to capture in 10
bit mode.
channels
Defines number of audio channels to capture. Must be ‘2’, ‘8’ or ‘16’.
Defaults to ‘2’.
duplex_mode
Sets the decklink device duplex/profile mode. Must be ‘unset’, ‘half’, ‘full’,
‘one_sub_device_full’, ‘one_sub_device_half’, ‘two_sub_device_full’,
‘four_sub_device_half’
Defaults to ‘unset’.
Note: DeckLink SDK 11.0 have replaced the duplex property by a profile property.
For the DeckLink Duo 2 and DeckLink Quad 2, a profile is shared between any 2
sub-devices that utilize the same connectors. For the DeckLink 8K Pro, a profile
is shared between all 4 sub-devices. So DeckLink 8K Pro support four profiles.
Valid profile modes for DeckLink 8K Pro(with DeckLink SDK >= 11.0):
‘one_sub_device_full’, ‘one_sub_device_half’, ‘two_sub_device_full’,
‘four_sub_device_half’
Valid profile modes for DeckLink Quad 2 and DeckLink Duo 2:
‘half’, ‘full’
timecode_format
Timecode type to include in the frame and video stream metadata. Must be
‘none’, ‘rp188vitc’, ‘rp188vitc2’, ‘rp188ltc’,
‘rp188hfr’, ‘rp188any’, ‘vitc’, ‘vitc2’, or ‘serial’.
Defaults to ‘none’ (not included).
In order to properly support 50/60 fps timecodes, the ordering of the queried
timecode types for ‘rp188any’ is HFR, VITC1, VITC2 and LTC for >30 fps
content. Note that this is slightly different to the ordering used by the
DeckLink API, which is HFR, VITC1, LTC, VITC2.
video_input
Sets the video input source. Must be ‘unset’, ‘sdi’, ‘hdmi’,
‘optical_sdi’, ‘component’, ‘composite’ or ‘s_video’.
Defaults to ‘unset’.
audio_input
Sets the audio input source. Must be ‘unset’, ‘embedded’,
‘aes_ebu’, ‘analog’, ‘analog_xlr’, ‘analog_rca’ or
‘microphone’. Defaults to ‘unset’.
video_pts
Sets the video packet timestamp source. Must be ‘video’, ‘audio’,
‘reference’, ‘wallclock’ or ‘abs_wallclock’.
Defaults to ‘video’.
audio_pts
Sets the audio packet timestamp source. Must be ‘video’, ‘audio’,
‘reference’, ‘wallclock’ or ‘abs_wallclock’.
Defaults to ‘audio’.
draw_bars
If set to ‘true’, color bars are drawn in the event of a signal loss.
Defaults to ‘true’.
This option is deprecated, please use the signal_loss_action option.
signal_loss_action
Sets the action to take in the event of a signal loss. Accepts one of the
following values:
1, none
Do nothing on signal loss. This usually results in black frames.
2, bars
Draw color bars on signal loss. Only supported for 8-bit input signals.
3, repeat
Repeat the last video frame on signal loss.
Defaults to ‘bars’.
queue_size
Sets maximum input buffer size in bytes. If the buffering reaches this value,
incoming frames will be dropped.
Defaults to ‘1073741824’.
audio_depth
Sets the audio sample bit depth. Must be ‘16’ or ‘32’.
Defaults to ‘16’.
decklink_copyts
If set to true, timestamps are forwarded as they are without removing
the initial offset.
Defaults to false.
timestamp_align
Capture start time alignment in seconds. If set to nonzero, input frames are
dropped till the system timestamp aligns with configured value.
Alignment difference of up to one frame duration is tolerated.
This is useful for maintaining input synchronization across N different
hardware devices deployed for ’N-way’ redundancy. The system time of different
hardware devices should be synchronized with protocols such as NTP or PTP,
before using this option.
Note that this method is not foolproof. In some border cases input
synchronization may not happen due to thread scheduling jitters in the OS.
Either sync could go wrong by 1 frame or in a rarer case
timestamp_align seconds.
Defaults to ‘0’.
wait_for_tc (bool)
Drop frames till a frame with timecode is received. Sometimes serial timecode
isn’t received with the first input frame. If that happens, the stored stream
timecode will be inaccurate. If this option is set to true, input frames
are dropped till a frame with timecode is received.
Option timecode_format must be specified.
Defaults to false.
enable_klv(bool)
If set to true, extracts KLV data from VANC and outputs KLV packets.
KLV VANC packets are joined based on MID and PSC fields and aggregated into
one KLV packet.
Defaults to false.
26.5.2 Examples
List input devices:
ffmpeg -sources decklink
List supported formats:
ffmpeg -f decklink -list_formats 1 -i 'Intensity Pro'
Capture video clip at 1080i50:
ffmpeg -format_code Hi50 -f decklink -i 'Intensity Pro' -c:a copy -c:v copy output.avi
Capture video clip at 1080i50 10 bit:
ffmpeg -raw_format yuv422p10 -format_code Hi50 -f decklink -i 'UltraStudio Mini Recorder' -c:a copy -c:v copy output.avi
Capture video clip at 1080i50 with 16 audio channels:
ffmpeg -channels 16 -format_code Hi50 -f decklink -i 'UltraStudio Mini Recorder' -c:a copy -c:v copy output.avi
26.6 dshow
Windows DirectShow input device.
DirectShow support is enabled when FFmpeg is built with the mingw-w64 project.
Currently only audio and video devices are supported.
Multiple devices may be opened as separate inputs, but they may also be
opened on the same input, which should improve synchronism between them.
The input name should be in the format:
TYPE=NAME[:TYPE=NAME]
where TYPE can be either audio or video,
and NAME is the device’s name or alternative name..
26.6.1 Options
If no options are specified, the device’s defaults are used.
If the device does not support the requested options, it will
fail to open.
video_size
Set the video size in the captured video.
framerate
Set the frame rate in the captured video.
sample_rate
Set the sample rate (in Hz) of the captured audio.
sample_size
Set the sample size (in bits) of the captured audio.
channels
Set the number of channels in the captured audio.
list_devices
If set to true, print a list of devices and exit.
list_options
If set to true, print a list of selected device’s options
and exit.
video_device_number
Set video device number for devices with the same name (starts at 0,
defaults to 0).
audio_device_number
Set audio device number for devices with the same name (starts at 0,
defaults to 0).
pixel_format
Select pixel format to be used by DirectShow. This may only be set when
the video codec is not set or set to rawvideo.
audio_buffer_size
Set audio device buffer size in milliseconds (which can directly
impact latency, depending on the device).
Defaults to using the audio device’s
default buffer size (typically some multiple of 500ms).
Setting this value too low can degrade performance.
See also
http://msdn.microsoft.com/en-us/library/windows/desktop/dd377582(v=vs.85).aspx
video_pin_name
Select video capture pin to use by name or alternative name.
audio_pin_name
Select audio capture pin to use by name or alternative name.
crossbar_video_input_pin_number
Select video input pin number for crossbar device. This will be
routed to the crossbar device’s Video Decoder output pin.
Note that changing this value can affect future invocations
(sets a new default) until system reboot occurs.
crossbar_audio_input_pin_number
Select audio input pin number for crossbar device. This will be
routed to the crossbar device’s Audio Decoder output pin.
Note that changing this value can affect future invocations
(sets a new default) until system reboot occurs.
show_video_device_dialog
If set to true, before capture starts, popup a display dialog
to the end user, allowing them to change video filter properties
and configurations manually.
Note that for crossbar devices, adjusting values in this dialog
may be needed at times to toggle between PAL (25 fps) and NTSC (29.97)
input frame rates, sizes, interlacing, etc.  Changing these values can
enable different scan rates/frame rates and avoiding green bars at
the bottom, flickering scan lines, etc.
Note that with some devices, changing these properties can also affect future
invocations (sets new defaults) until system reboot occurs.
show_audio_device_dialog
If set to true, before capture starts, popup a display dialog
to the end user, allowing them to change audio filter properties
and configurations manually.
show_video_crossbar_connection_dialog
If set to true, before capture starts, popup a display
dialog to the end user, allowing them to manually
modify crossbar pin routings, when it opens a video device.
show_audio_crossbar_connection_dialog
If set to true, before capture starts, popup a display
dialog to the end user, allowing them to manually
modify crossbar pin routings, when it opens an audio device.
show_analog_tv_tuner_dialog
If set to true, before capture starts, popup a display
dialog to the end user, allowing them to manually
modify TV channels and frequencies.
show_analog_tv_tuner_audio_dialog
If set to true, before capture starts, popup a display
dialog to the end user, allowing them to manually
modify TV audio (like mono vs. stereo, Language A,B or C).
audio_device_load
Load an audio capture filter device from file instead of searching
it by name. It may load additional parameters too, if the filter
supports the serialization of its properties to.
To use this an audio capture source has to be specified, but it can
be anything even fake one.
audio_device_save
Save the currently used audio capture filter device and its
parameters (if the filter supports it) to a file.
If a file with the same name exists it will be overwritten.
video_device_load
Load a video capture filter device from file instead of searching
it by name. It may load additional parameters too, if the filter
supports the serialization of its properties to.
To use this a video capture source has to be specified, but it can
be anything even fake one.
video_device_save
Save the currently used video capture filter device and its
parameters (if the filter supports it) to a file.
If a file with the same name exists it will be overwritten.
use_video_device_timestamps
If set to false, the timestamp for video frames will be
derived from the wallclock instead of the timestamp provided by
the capture device. This allows working around devices that
provide unreliable timestamps.
26.6.2 Examples
Print the list of DirectShow supported devices and exit:
$ ffmpeg -list_devices true -f dshow -i dummy
Open video device Camera:
$ ffmpeg -f dshow -i video="Camera"
Open second video device with name Camera:
$ ffmpeg -f dshow -video_device_number 1 -i video="Camera"
Open video device Camera and audio device Microphone:
$ ffmpeg -f dshow -i video="Camera":audio="Microphone"
Print the list of supported options in selected device and exit:
$ ffmpeg -list_options true -f dshow -i video="Camera"
Specify pin names to capture by name or alternative name, specify alternative device name:
$ ffmpeg -f dshow -audio_pin_name "Audio Out" -video_pin_name 2 -i video=video="@device_pnp_\\?\pci#ven_1a0a&dev_6200&subsys_62021461&rev_01#4&e2c7dd6&0&00e1#{65e8773d-8f56-11d0-a3b9-00a0c9223196}\{ca465100-deb0-4d59-818f-8c477184adf6}":audio="Microphone"
Configure a crossbar device, specifying crossbar pins, allow user to adjust video capture properties at startup:
$ ffmpeg -f dshow -show_video_device_dialog true -crossbar_video_input_pin_number 0
-crossbar_audio_input_pin_number 3 -i video="AVerMedia BDA Analog Capture":audio="AVerMedia BDA Analog Capture"
26.7 fbdev
Linux framebuffer input device.
The Linux framebuffer is a graphic hardware-independent abstraction
layer to show graphics on a computer monitor, typically on the
console. It is accessed through a file device node, usually
/dev/fb0.
For more detailed information read the file
Documentation/fb/framebuffer.txt included in the Linux source tree.
See also http://linux-fbdev.sourceforge.net/, and fbset(1).
To record from the framebuffer device /dev/fb0 with
ffmpeg:
ffmpeg -f fbdev -framerate 10 -i /dev/fb0 out.avi
You can take a single screenshot image with the command:
ffmpeg -f fbdev -framerate 1 -i /dev/fb0 -frames:v 1 screenshot.jpeg
26.7.1 Options
framerate
Set the frame rate. Default is 25.
26.8 gdigrab
Win32 GDI-based screen capture device.
This device allows you to capture a region of the display on Windows.
Amongst options for the imput filenames are such elements as:
desktop
or
title=window_title
or
hwnd=window_hwnd
The first option will capture the entire desktop, or a fixed region of the
desktop. The second and third options will instead capture the contents of a single
window, regardless of its position on the screen.
For example, to grab the entire desktop using ffmpeg:
ffmpeg -f gdigrab -framerate 6 -i desktop out.mpg
Grab a 640x480 region at position 10,20:
ffmpeg -f gdigrab -framerate 6 -offset_x 10 -offset_y 20 -video_size vga -i desktop out.mpg
Grab the contents of the window named "Calculator"
ffmpeg -f gdigrab -framerate 6 -i title=Calculator out.mpg
26.8.1 Options
draw_mouse
Specify whether to draw the mouse pointer. Use the value 0 to
not draw the pointer. Default value is 1.
framerate
Set the grabbing frame rate. Default value is ntsc,
corresponding to a frame rate of 30000/1001.
show_region
Show grabbed region on screen.
If show_region is specified with 1, then the grabbing
region will be indicated on screen. With this option, it is easy to
know what is being grabbed if only a portion of the screen is grabbed.
Note that show_region is incompatible with grabbing the contents
of a single window.
For example:
ffmpeg -f gdigrab -show_region 1 -framerate 6 -video_size cif -offset_x 10 -offset_y 20 -i desktop out.mpg
video_size
Set the video frame size. The default is to capture the full screen if desktop is selected, or the full window size if title=window_title is selected.
offset_x
When capturing a region with video_size, set the distance from the left edge of the screen or desktop.
Note that the offset calculation is from the top left corner of the primary monitor on Windows. If you have a monitor positioned to the left of your primary monitor, you will need to use a negative offset_x value to move the region to that monitor.
offset_y
When capturing a region with video_size, set the distance from the top edge of the screen or desktop.
Note that the offset calculation is from the top left corner of the primary monitor on Windows. If you have a monitor positioned above your primary monitor, you will need to use a negative offset_y value to move the region to that monitor.
26.9 iec61883
FireWire DV/HDV input device using libiec61883.
To enable this input device, you need libiec61883, libraw1394 and
libavc1394 installed on your system. Use the configure option
--enable-libiec61883 to compile with the device enabled.
The iec61883 capture device supports capturing from a video device
connected via IEEE1394 (FireWire), using libiec61883 and the new Linux
FireWire stack (juju). This is the default DV/HDV input method in Linux
Kernel 2.6.37 and later, since the old FireWire stack was removed.
Specify the FireWire port to be used as input file, or "auto"
to choose the first port connected.
26.9.1 Options
dvtype
Override autodetection of DV/HDV. This should only be used if auto
detection does not work, or if usage of a different device type
should be prohibited. Treating a DV device as HDV (or vice versa) will
not work and result in undefined behavior.
The values auto, dv and hdv are supported.
dvbuffer
Set maximum size of buffer for incoming data, in frames. For DV, this
is an exact value. For HDV, it is not frame exact, since HDV does
not have a fixed frame size.
dvguid
Select the capture device by specifying its GUID. Capturing will only
be performed from the specified device and fails if no device with the
given GUID is found. This is useful to select the input if multiple
devices are connected at the same time.
Look at /sys/bus/firewire/devices to find out the GUIDs.
26.9.2 Examples
Grab and show the input of a FireWire DV/HDV device.
ffplay -f iec61883 -i auto
Grab and record the input of a FireWire DV/HDV device,
using a packet buffer of 100000 packets if the source is HDV.
ffmpeg -f iec61883 -i auto -dvbuffer 100000 out.mpg
26.10 jack
JACK input device.
To enable this input device during configuration you need libjack
installed on your system.
A JACK input device creates one or more JACK writable clients, one for
each audio channel, with name client_name:input_N, where
client_name is the name provided by the application, and N
is a number which identifies the channel.
Each writable client will send the acquired data to the FFmpeg input
device.
Once you have created one or more JACK readable clients, you need to
connect them to one or more JACK writable clients.
To connect or disconnect JACK clients you can use the jack_connect
and jack_disconnect programs, or do it through a graphical interface,
for example with qjackctl.
To list the JACK clients and their properties you can invoke the command
jack_lsp.
Follows an example which shows how to capture a JACK readable client
with ffmpeg.
# Create a JACK writable client with name "ffmpeg".
$ ffmpeg -f jack -i ffmpeg -y out.wav
# Start the sample jack_metro readable client.
$ jack_metro -b 120 -d 0.2 -f 4000
# List the current JACK clients.
$ jack_lsp -c
system:capture_1
system:capture_2
system:playback_1
system:playback_2
ffmpeg:input_1
metro:120_bpm
# Connect metro to the ffmpeg writable client.
$ jack_connect metro:120_bpm ffmpeg:input_1
For more information read:
http://jackaudio.org/
26.10.1 Options
channels
Set the number of channels. Default is 2.
26.11 kmsgrab
KMS video input device.
Captures the KMS scanout framebuffer associated with a specified CRTC or plane as a
DRM object that can be passed to other hardware functions.
Requires either DRM master or CAP_SYS_ADMIN to run.
If you don’t understand what all of that means, you probably don’t want this.  Look at
x11grab instead.
26.11.1 Options
device
DRM device to capture on.  Defaults to /dev/dri/card0.
format
Pixel format of the framebuffer.  This can be autodetected if you are running Linux 5.7
or later, but needs to be provided for earlier versions.  Defaults to bgr0,
which is the most common format used by the Linux console and Xorg X server.
format_modifier
Format modifier to signal on output frames.  This is necessary to import correctly into
some APIs.  It can be autodetected if you are running Linux 5.7 or later, but will need
to be provided explicitly when needed in earlier versions.  See the libdrm documentation
for possible values.
crtc_id
KMS CRTC ID to define the capture source.  The first active plane on the given CRTC
will be used.
plane_id
KMS plane ID to define the capture source.  Defaults to the first active plane found if
neither crtc_id nor plane_id are specified.
framerate
Framerate to capture at.  This is not synchronised to any page flipping or framebuffer
changes - it just defines the interval at which the framebuffer is sampled.  Sampling
faster than the framebuffer update rate will generate independent frames with the same
content.  Defaults to 30.
26.11.2 Examples
Capture from the first active plane, download the result to normal frames and encode.
This will only work if the framebuffer is both linear and mappable - if not, the result
may be scrambled or fail to download.
ffmpeg -f kmsgrab -i - -vf 'hwdownload,format=bgr0' output.mp4
Capture from CRTC ID 42 at 60fps, map the result to VAAPI, convert to NV12 and encode as H.264.
ffmpeg -crtc_id 42 -framerate 60 -f kmsgrab -i - -vf 'hwmap=derive_device=vaapi,scale_vaapi=w=1920:h=1080:format=nv12' -c:v h264_vaapi output.mp4
To capture only part of a plane the output can be cropped - this can be used to capture
a single window, as long as it has a known absolute position and size.  For example, to
capture and encode the middle quarter of a 1920x1080 plane:
ffmpeg -f kmsgrab -i - -vf 'hwmap=derive_device=vaapi,crop=960:540:480:270,scale_vaapi=960:540:nv12' -c:v h264_vaapi output.mp4
26.12 lavfi
Libavfilter input virtual device.
This input device reads data from the open output pads of a libavfilter
filtergraph.
For each filtergraph open output, the input device will create a
corresponding stream which is mapped to the generated output.
The filtergraph is specified through the option graph.
26.12.1 Options
graph
Specify the filtergraph to use as input. Each video open output must be
labelled by a unique string of the form "outN", where N is a
number starting from 0 corresponding to the mapped input stream
generated by the device.
The first unlabelled output is automatically assigned to the "out0"
label, but all the others need to be specified explicitly.
The suffix "+subcc" can be appended to the output label to create an extra
stream with the closed captions packets attached to that output
(experimental; only for EIA-608 / CEA-708 for now).
The subcc streams are created after all the normal streams, in the order of
the corresponding stream.
For example, if there is "out19+subcc", "out7+subcc" and up to "out42", the
stream #43 is subcc for stream #7 and stream #44 is subcc for stream #19.
If not specified defaults to the filename specified for the input
device.
graph_file
Set the filename of the filtergraph to be read and sent to the other
filters. Syntax of the filtergraph is the same as the one specified by
the option graph.
dumpgraph
Dump graph to stderr.
26.12.2 Examples
Create a color video stream and play it back with ffplay:
ffplay -f lavfi -graph "color=c=pink [out0]" dummy
As the previous example, but use filename for specifying the graph
description, and omit the "out0" label:
ffplay -f lavfi color=c=pink
Create three different video test filtered sources and play them:
ffplay -f lavfi -graph "testsrc [out0]; testsrc,hflip [out1]; testsrc,negate [out2]" test3
Read an audio stream from a file using the amovie source and play it
back with ffplay:
ffplay -f lavfi "amovie=test.wav"
Read an audio stream and a video stream and play it back with
ffplay:
ffplay -f lavfi "movie=test.avi[out0];amovie=test.wav[out1]"
Dump decoded frames to images and Closed Captions to an RCWT backup:
ffmpeg -f lavfi -i "movie=test.ts[out0+subcc]" -map v frame%08d.png -map s -c copy -f rcwt subcc.bin
26.13 libcdio
Audio-CD input device based on libcdio.
To enable this input device during configuration you need libcdio
installed on your system. It requires the configure option
--enable-libcdio.
This device allows playing and grabbing from an Audio-CD.
For example to copy with ffmpeg the entire Audio-CD in /dev/sr0,
you may run the command:
ffmpeg -f libcdio -i /dev/sr0 cd.wav
26.13.1 Options
speed
Set drive reading speed. Default value is 0.
The speed is specified CD-ROM speed units. The speed is set through
the libcdio cdio_cddap_speed_set function. On many CD-ROM
drives, specifying a value too large will result in using the fastest
speed.
paranoia_mode
Set paranoia recovery mode flags. It accepts one of the following values:
‘disable’
‘verify’
‘overlap’
‘neverskip’
‘full’
Default value is ‘disable’.
For more information about the available recovery modes, consult the
paranoia project documentation.
26.14 libdc1394
IIDC1394 input device, based on libdc1394 and libraw1394.
Requires the configure option --enable-libdc1394.
26.14.1 Options
framerate
Set the frame rate. Default is ntsc, corresponding to a frame
rate of 30000/1001.
pixel_format
Select the pixel format. Default is uyvy422.
video_size
Set the video size given as a string such as 640x480 or hd720.
Default is qvga.
26.15 openal
The OpenAL input device provides audio capture on all systems with a
working OpenAL 1.1 implementation.
To enable this input device during configuration, you need OpenAL
headers and libraries installed on your system, and need to configure
FFmpeg with --enable-openal.
OpenAL headers and libraries should be provided as part of your OpenAL
implementation, or as an additional download (an SDK). Depending on your
installation you may need to specify additional flags via the
--extra-cflags and --extra-ldflags for allowing the build
system to locate the OpenAL headers and libraries.
An incomplete list of OpenAL implementations follows:
Creative
The official Windows implementation, providing hardware acceleration
with supported devices and software fallback.
See http://openal.org/.
OpenAL Soft
Portable, open source (LGPL) software implementation. Includes
backends for the most common sound APIs on the Windows, Linux,
Solaris, and BSD operating systems.
See http://kcat.strangesoft.net/openal.html.
Apple
OpenAL is part of Core Audio, the official Mac OS X Audio interface.
See http://developer.apple.com/technologies/mac/audio-and-video.html
This device allows one to capture from an audio input device handled
through OpenAL.
You need to specify the name of the device to capture in the provided
filename. If the empty string is provided, the device will
automatically select the default device. You can get the list of the
supported devices by using the option list_devices.
26.15.1 Options
channels
Set the number of channels in the captured audio. Only the values
1 (monaural) and 2 (stereo) are currently supported.
Defaults to 2.
sample_size
Set the sample size (in bits) of the captured audio. Only the values
8 and 16 are currently supported. Defaults to
16.
sample_rate
Set the sample rate (in Hz) of the captured audio.
Defaults to 44.1k.
list_devices
If set to true, print a list of devices and exit.
Defaults to false.
26.15.2 Examples
Print the list of OpenAL supported devices and exit:
$ ffmpeg -list_devices true -f openal -i dummy out.ogg
Capture from the OpenAL device DR-BT101 via PulseAudio:
$ ffmpeg -f openal -i 'DR-BT101 via PulseAudio' out.ogg
Capture from the default device (note the empty string ” as filename):
$ ffmpeg -f openal -i '' out.ogg
Capture from two devices simultaneously, writing to two different files,
within the same ffmpeg command:
$ ffmpeg -f openal -i 'DR-BT101 via PulseAudio' out1.ogg -f openal -i 'ALSA Default' out2.ogg
Note: not all OpenAL implementations support multiple simultaneous capture -
try the latest OpenAL Soft if the above does not work.
26.16 oss
Open Sound System input device.
The filename to provide to the input device is the device node
representing the OSS input device, and is usually set to
/dev/dsp.
For example to grab from /dev/dsp using ffmpeg use the
command:
ffmpeg -f oss -i /dev/dsp /tmp/oss.wav
For more information about OSS see:
http://manuals.opensound.com/usersguide/dsp.html
26.16.1 Options
sample_rate
Set the sample rate in Hz. Default is 48000.
channels
Set the number of channels. Default is 2.
26.17 pulse
PulseAudio input device.
To enable this output device you need to configure FFmpeg with --enable-libpulse.
The filename to provide to the input device is a source device or the
string "default"
To list the PulseAudio source devices and their properties you can invoke
the command pactl list sources.
More information about PulseAudio can be found on http://www.pulseaudio.org.
26.17.1 Options
server
Connect to a specific PulseAudio server, specified by an IP address.
Default server is used when not provided.
name
Specify the application name PulseAudio will use when showing active clients,
by default it is the LIBAVFORMAT_IDENT string.
stream_name
Specify the stream name PulseAudio will use when showing active streams,
by default it is "record".
sample_rate
Specify the samplerate in Hz, by default 48kHz is used.
channels
Specify the channels in use, by default 2 (stereo) is set.
frame_size
This option does nothing and is deprecated.
fragment_size
Specify the size in bytes of the minimal buffering fragment in PulseAudio, it
will affect the audio latency. By default it is set to 50 ms amount of data.
wallclock
Set the initial PTS using the current time. Default is 1.
26.17.2 Examples
Record a stream from default device:
ffmpeg -f pulse -i default /tmp/pulse.wav
26.18 sndio
sndio input device.
To enable this input device during configuration you need libsndio
installed on your system.
The filename to provide to the input device is the device node
representing the sndio input device, and is usually set to
/dev/audio0.
For example to grab from /dev/audio0 using ffmpeg use the
command:
ffmpeg -f sndio -i /dev/audio0 /tmp/oss.wav
26.18.1 Options
sample_rate
Set the sample rate in Hz. Default is 48000.
channels
Set the number of channels. Default is 2.
26.19 video4linux2, v4l2
Video4Linux2 input video device.
"v4l2" can be used as alias for "video4linux2".
If FFmpeg is built with v4l-utils support (by using the
--enable-libv4l2 configure option), it is possible to use it with the
-use_libv4l2 input device option.
The name of the device to grab is a file device node, usually Linux
systems tend to automatically create such nodes when the device
(e.g. an USB webcam) is plugged into the system, and has a name of the
kind /dev/videoN, where N is a number associated to
the device.
Video4Linux2 devices usually support a limited set of
widthxheight sizes and frame rates. You can check which are
supported using -list_formats all for Video4Linux2 devices.
Some devices, like TV cards, support one or more standards. It is possible
to list all the supported standards using -list_standards all.
The time base for the timestamps is 1 microsecond. Depending on the kernel
version and configuration, the timestamps may be derived from the real time
clock (origin at the Unix Epoch) or the monotonic clock (origin usually at
boot time, unaffected by NTP or manual changes to the clock). The
-timestamps abs or -ts abs option can be used to force
conversion into the real time clock.
Some usage examples of the video4linux2 device with ffmpeg
and ffplay:
List supported formats for a video4linux2 device:
ffplay -f video4linux2 -list_formats all /dev/video0
Grab and show the input of a video4linux2 device:
ffplay -f video4linux2 -framerate 30 -video_size hd720 /dev/video0
Grab and record the input of a video4linux2 device, leave the
frame rate and size as previously set:
ffmpeg -f video4linux2 -input_format mjpeg -i /dev/video0 out.mpeg
For more information about Video4Linux, check http://linuxtv.org/.
26.19.1 Options
standard
Set the standard. Must be the name of a supported standard. To get a
list of the supported standards, use the list_standards
option.
channel
Set the input channel number. Default to -1, which means using the
previously selected channel.
video_size
Set the video frame size. The argument must be a string in the form
WIDTHxHEIGHT or a valid size abbreviation.
pixel_format
Select the pixel format (only valid for raw video input).
input_format
Set the preferred pixel format (for raw video) or a codec name.
This option allows one to select the input format, when several are
available.
framerate
Set the preferred video frame rate.
list_formats
List available formats (supported pixel formats, codecs, and frame
sizes) and exit.
Available values are:
‘all’
Show all available (compressed and non-compressed) formats.
‘raw’
Show only raw video (non-compressed) formats.
‘compressed’
Show only compressed formats.
list_standards
List supported standards and exit.
Available values are:
‘all’
Show all supported standards.
timestamps, ts
Set type of timestamps for grabbed frames.
Available values are:
‘default’
Use timestamps from the kernel.
‘abs’
Use absolute timestamps (wall clock).
‘mono2abs’
Force conversion from monotonic to absolute timestamps.
Default value is default.
use_libv4l2
Use libv4l2 (v4l-utils) conversion functions. Default is 0.
26.20 vfwcap
VfW (Video for Windows) capture input device.
The filename passed as input is the capture driver number, ranging from
0 to 9. You may use "list" as filename to print a list of drivers. Any
other filename will be interpreted as device number 0.
26.20.1 Options
video_size
Set the video frame size.
framerate
Set the grabbing frame rate. Default value is ntsc,
corresponding to a frame rate of 30000/1001.
26.21 x11grab
X11 video input device.
To enable this input device during configuration you need libxcb
installed on your system. It will be automatically detected during
configuration.
This device allows one to capture a region of an X11 display.
The filename passed as input has the syntax:
[hostname]:display_number.screen_number[+x_offset,y_offset]
hostname:display_number.screen_number specifies the
X11 display name of the screen to grab from. hostname can be
omitted, and defaults to "localhost". The environment variable
DISPLAY contains the default display name.
x_offset and y_offset specify the offsets of the grabbed
area with respect to the top-left border of the X11 screen. They
default to 0.
Check the X11 documentation (e.g. man X) for more detailed
information.
Use the xdpyinfo program for getting basic information about
the properties of your X11 display (e.g. grep for "name" or
"dimensions").
For example to grab from :0.0 using ffmpeg:
ffmpeg -f x11grab -framerate 25 -video_size cif -i :0.0 out.mpg
Grab at position 10,20:
ffmpeg -f x11grab -framerate 25 -video_size cif -i :0.0+10,20 out.mpg
26.21.1 Options
select_region
Specify whether to select the grabbing area graphically using the pointer.
A value of 1 prompts the user to select the grabbing area graphically
by clicking and dragging. A single click with no dragging will select the
whole screen. A region with zero width or height will also select the whole
screen. This option overwrites the video_size, grab_x, and
grab_y options. Default value is 0.
draw_mouse
Specify whether to draw the mouse pointer. A value of 0 specifies
not to draw the pointer. Default value is 1.
follow_mouse
Make the grabbed area follow the mouse. The argument can be
centered or a number of pixels PIXELS.
When it is specified with "centered", the grabbing region follows the mouse
pointer and keeps the pointer at the center of region; otherwise, the region
follows only when the mouse pointer reaches within PIXELS (greater than
zero) to the edge of region.
For example:
ffmpeg -f x11grab -follow_mouse centered -framerate 25 -video_size cif -i :0.0 out.mpg
To follow only when the mouse pointer reaches within 100 pixels to edge:
ffmpeg -f x11grab -follow_mouse 100 -framerate 25 -video_size cif -i :0.0 out.mpg
framerate
Set the grabbing frame rate. Default value is ntsc,
corresponding to a frame rate of 30000/1001.
show_region
Show grabbed region on screen.
If show_region is specified with 1, then the grabbing
region will be indicated on screen. With this option, it is easy to
know what is being grabbed if only a portion of the screen is grabbed.
region_border
Set the region border thickness if -show_region 1 is used.
Range is 1 to 128 and default is 3 (XCB-based x11grab only).
For example:
ffmpeg -f x11grab -show_region 1 -framerate 25 -video_size cif -i :0.0+10,20 out.mpg
With follow_mouse:
ffmpeg -f x11grab -follow_mouse centered -show_region 1 -framerate 25 -video_size cif -i :0.0 out.mpg
window_id
Grab this window, instead of the whole screen. Default value is 0, which maps to
the whole screen (root window).
The id of a window can be found using the xwininfo program, possibly with options -tree and
-root.
If the window is later enlarged, the new area is not recorded. Video ends when
the window is closed, unmapped (i.e., iconified) or shrunk beyond the video
size (which defaults to the initial window size).
This option disables options follow_mouse and select_region.
video_size
Set the video frame size. Default is the full desktop or window.
grab_x
grab_y
Set the grabbing region coordinates. They are expressed as offset from
the top left corner of the X11 window and correspond to the
x_offset and y_offset parameters in the device name. The
default value for both options is 0.
27 Output Devices
Output devices are configured elements in FFmpeg that can write
multimedia data to an output device attached to your system.
When you configure your FFmpeg build, all the supported output devices
are enabled by default. You can list all available ones using the
configure option "–list-outdevs".
You can disable all the output devices using the configure option
"–disable-outdevs", and selectively enable an output device using the
option "–enable-outdev=OUTDEV", or you can disable a particular
input device using the option "–disable-outdev=OUTDEV".
The option "-devices" of the ff* tools will display the list of
enabled output devices.
A description of the currently available output devices follows.
27.1 alsa
ALSA (Advanced Linux Sound Architecture) output device.
27.1.1 Examples
Play a file on default ALSA device:
ffmpeg -i INPUT -f alsa default
Play a file on soundcard 1, audio device 7:
ffmpeg -i INPUT -f alsa hw:1,7
27.2 AudioToolbox
AudioToolbox output device.
Allows native output to CoreAudio devices on OSX.
The output filename can be empty (or -) to refer to the default system output device or a number that refers to the device index as shown using: -list_devices true.
Alternatively, the audio input device can be chosen by index using the
-audio_device_index <INDEX>
, overriding any device name or index given in the input filename.
All available devices can be enumerated by using -list_devices true, listing
all device names, UIDs and corresponding indices.
27.2.1 Options
AudioToolbox supports the following options:
-audio_device_index <INDEX>
Specify the audio device by its index. Overrides anything given in the output filename.
27.2.2 Examples
Print the list of supported devices and output a sine wave to the default device:
$ ffmpeg -f lavfi -i sine=r=44100 -f audiotoolbox -list_devices true -
Output a sine wave to the device with the index 2, overriding any output filename:
$ ffmpeg -f lavfi -i sine=r=44100 -f audiotoolbox -audio_device_index 2 -
27.3 caca
CACA output device.
This output device allows one to show a video stream in CACA window.
Only one CACA window is allowed per application, so you can
have only one instance of this output device in an application.
To enable this output device you need to configure FFmpeg with
--enable-libcaca.
libcaca is a graphics library that outputs text instead of pixels.
For more information about libcaca, check:
http://caca.zoy.org/wiki/libcaca
27.3.1 Options
window_title
Set the CACA window title, if not specified default to the filename
specified for the output device.
window_size
Set the CACA window size, can be a string of the form
widthxheight or a video size abbreviation.
If not specified it defaults to the size of the input video.
driver
Set display driver.
algorithm
Set dithering algorithm. Dithering is necessary
because the picture being rendered has usually far more colours than
the available palette.
The accepted values are listed with -list_dither algorithms.
antialias
Set antialias method. Antialiasing smoothens the rendered
image and avoids the commonly seen staircase effect.
The accepted values are listed with -list_dither antialiases.
charset
Set which characters are going to be used when rendering text.
The accepted values are listed with -list_dither charsets.
color
Set color to be used when rendering text.
The accepted values are listed with -list_dither colors.
list_drivers
If set to true, print a list of available drivers and exit.
list_dither
List available dither options related to the argument.
The argument must be one of algorithms, antialiases,
charsets, colors.
27.3.2 Examples
The following command shows the ffmpeg output is an
CACA window, forcing its size to 80x25:
ffmpeg -i INPUT -c:v rawvideo -pix_fmt rgb24 -window_size 80x25 -f caca -
Show the list of available drivers and exit:
ffmpeg -i INPUT -pix_fmt rgb24 -f caca -list_drivers true -
Show the list of available dither colors and exit:
ffmpeg -i INPUT -pix_fmt rgb24 -f caca -list_dither colors -
27.4 decklink
The decklink output device provides playback capabilities for Blackmagic
DeckLink devices.
To enable this output device, you need the Blackmagic DeckLink SDK and you
need to configure with the appropriate --extra-cflags
and --extra-ldflags.
On Windows, you need to run the IDL files through widl.
DeckLink is very picky about the formats it supports. Pixel format is always
uyvy422, framerate, field order and video size must be determined for your
device with -list_formats 1. Audio sample rate is always 48 kHz.
27.4.1 Options
list_devices
If set to true, print a list of devices and exit.
Defaults to false. This option is deprecated, please use the
-sinks option of ffmpeg to list the available output devices.
list_formats
If set to true, print a list of supported formats and exit.
Defaults to false.
preroll
Amount of time to preroll video in seconds.
Defaults to 0.5.
duplex_mode
Sets the decklink device duplex/profile mode. Must be ‘unset’, ‘half’, ‘full’,
‘one_sub_device_full’, ‘one_sub_device_half’, ‘two_sub_device_full’,
‘four_sub_device_half’
Defaults to ‘unset’.
Note: DeckLink SDK 11.0 have replaced the duplex property by a profile property.
For the DeckLink Duo 2 and DeckLink Quad 2, a profile is shared between any 2
sub-devices that utilize the same connectors. For the DeckLink 8K Pro, a profile
is shared between all 4 sub-devices. So DeckLink 8K Pro support four profiles.
Valid profile modes for DeckLink 8K Pro(with DeckLink SDK >= 11.0):
‘one_sub_device_full’, ‘one_sub_device_half’, ‘two_sub_device_full’,
‘four_sub_device_half’
Valid profile modes for DeckLink Quad 2 and DeckLink Duo 2:
‘half’, ‘full’
timing_offset
Sets the genlock timing pixel offset on the used output.
Defaults to ‘unset’.
link
Sets the SDI video link configuration on the used output. Must be
‘unset’, ‘single’ link SDI, ‘dual’ link SDI or ‘quad’ link
SDI.
Defaults to ‘unset’.
sqd
Enable Square Division Quad Split mode for Quad-link SDI output.
Must be ‘unset’, ‘true’ or ‘false’.
Defaults to unset.
level_a
Enable SMPTE Level A mode on the used output.
Must be ‘unset’, ‘true’ or ‘false’.
Defaults to unset.
vanc_queue_size
Sets maximum output buffer size in bytes for VANC data. If the buffering reaches this value,
outgoing VANC data will be dropped.
Defaults to ‘1048576’.
27.4.2 Examples
List output devices:
ffmpeg -sinks decklink
List supported formats:
ffmpeg -i test.avi -f decklink -list_formats 1 'DeckLink Mini Monitor'
Play video clip:
ffmpeg -i test.avi -f decklink -pix_fmt uyvy422 'DeckLink Mini Monitor'
Play video clip with non-standard framerate or video size:
ffmpeg -i test.avi -f decklink -pix_fmt uyvy422 -s 720x486 -r 24000/1001 'DeckLink Mini Monitor'
27.5 fbdev
Linux framebuffer output device.
The Linux framebuffer is a graphic hardware-independent abstraction
layer to show graphics on a computer monitor, typically on the
console. It is accessed through a file device node, usually
/dev/fb0.
For more detailed information read the file
Documentation/fb/framebuffer.txt included in the Linux source tree.
27.5.1 Options
xoffset
yoffset
Set x/y coordinate of top left corner. Default is 0.
27.5.2 Examples
Play a file on framebuffer device /dev/fb0.
Required pixel format depends on current framebuffer settings.
ffmpeg -re -i INPUT -c:v rawvideo -pix_fmt bgra -f fbdev /dev/fb0
See also http://linux-fbdev.sourceforge.net/, and fbset(1).
27.6 opengl
OpenGL output device. Deprecated and will be removed.
To enable this output device you need to configure FFmpeg with --enable-opengl.
This output device allows one to render to OpenGL context.
Context may be provided by application or default SDL window is created.
When device renders to external context, application must implement handlers for following messages:
AV_DEV_TO_APP_CREATE_WINDOW_BUFFER - create OpenGL context on current thread.
AV_DEV_TO_APP_PREPARE_WINDOW_BUFFER - make OpenGL context current.
AV_DEV_TO_APP_DISPLAY_WINDOW_BUFFER - swap buffers.
AV_DEV_TO_APP_DESTROY_WINDOW_BUFFER - destroy OpenGL context.
Application is also required to inform a device about current resolution by sending AV_APP_TO_DEV_WINDOW_SIZE message.
27.6.1 Options
background
Set background color. Black is a default.
no_window
Disables default SDL window when set to non-zero value.
Application must provide OpenGL context and both window_size_cb and window_swap_buffers_cb callbacks when set.
window_title
Set the SDL window title, if not specified default to the filename specified for the output device.
Ignored when no_window is set.
window_size
Set preferred window size, can be a string of the form widthxheight or a video size abbreviation.
If not specified it defaults to the size of the input video, downscaled according to the aspect ratio.
Mostly usable when no_window is not set.
27.6.2 Examples
Play a file on SDL window using OpenGL rendering:
ffmpeg  -i INPUT -f opengl "window title"
27.7 oss
OSS (Open Sound System) output device.
27.8 pulse
PulseAudio output device.
To enable this output device you need to configure FFmpeg with --enable-libpulse.
More information about PulseAudio can be found on http://www.pulseaudio.org
27.8.1 Options
server
Connect to a specific PulseAudio server, specified by an IP address.
Default server is used when not provided.
name
Specify the application name PulseAudio will use when showing active clients,
by default it is the LIBAVFORMAT_IDENT string.
stream_name
Specify the stream name PulseAudio will use when showing active streams,
by default it is set to the specified output name.
device
Specify the device to use. Default device is used when not provided.
List of output devices can be obtained with command pactl list sinks.
buffer_size
buffer_duration
Control the size and duration of the PulseAudio buffer. A small buffer
gives more control, but requires more frequent updates.
buffer_size specifies size in bytes while
buffer_duration specifies duration in milliseconds.
When both options are provided then the highest value is used
(duration is recalculated to bytes using stream parameters). If they
are set to 0 (which is default), the device will use the default
PulseAudio duration value. By default PulseAudio set buffer duration
to around 2 seconds.
prebuf
Specify pre-buffering size in bytes. The server does not start with
playback before at least prebuf bytes are available in the
buffer. By default this option is initialized to the same value as
buffer_size or buffer_duration (whichever is bigger).
minreq
Specify minimum request size in bytes. The server does not request less
than minreq bytes from the client, instead waits until the buffer
is free enough to request more bytes at once. It is recommended to not set
this option, which will initialize this to a value that is deemed sensible
by the server.
27.8.2 Examples
Play a file on default device on default server:
ffmpeg  -i INPUT -f pulse "stream name"
27.9 sdl
SDL (Simple DirectMedia Layer) output device. Deprecated and will be removed.
For monitoring purposes in FFmpeg, pipes and a video player such as ffplay can be used:
ffmpeg -i INPUT -f nut -c:v rawvideo - | ffplay -
"sdl2" can be used as alias for "sdl".
This output device allows one to show a video stream in an SDL
window. Only one SDL window is allowed per application, so you can
have only one instance of this output device in an application.
To enable this output device you need libsdl installed on your system
when configuring your build.
For more information about SDL, check:
http://www.libsdl.org/
27.9.1 Options
window_borderless
Set SDL window border off.
Default value is 0 (enable window border).
window_enable_quit
Enable quit action (using window button or keyboard key)
when non-zero value is provided.
Default value is 1 (enable quit action).
window_fullscreen
Set fullscreen mode when non-zero value is provided.
Default value is zero.
window_size
Set the SDL window size, can be a string of the form
widthxheight or a video size abbreviation.
If not specified it defaults to the size of the input video,
downscaled according to the aspect ratio.
window_title
Set the SDL window title, if not specified default to the filename
specified for the output device.
window_x
window_y
Set the position of the window on the screen.
27.9.2 Interactive commands
The window created by the device can be controlled through the
following interactive commands.
q, ESC
Quit the device immediately.
27.9.3 Examples
The following command shows the ffmpeg output is an
SDL window, forcing its size to the qcif format:
ffmpeg -i INPUT -c:v rawvideo -pix_fmt yuv420p -window_size qcif -f sdl "SDL output"
27.10 sndio
sndio audio output device.
27.11 v4l2
Video4Linux2 output device.
27.12 xv
XV (XVideo) output device.
This output device allows one to show a video stream in a X Window System
window.
27.12.1 Options
display_name
Specify the hardware display name, which determines the display and
communications domain to be used.
The display name or DISPLAY environment variable can be a string in
the format hostname[:number[.screen_number]].
hostname specifies the name of the host machine on which the
display is physically attached. number specifies the number of
the display server on that host machine. screen_number specifies
the screen to be used on that server.
If unspecified, it defaults to the value of the DISPLAY environment
variable.
For example, dual-headed:0.1 would specify screen 1 of display
0 on the machine named “dual-headed”.
Check the X11 specification for more detailed information about the
display name format.
window_id
When set to non-zero value then device doesn’t create new window,
but uses existing one with provided window_id. By default
this options is set to zero and device creates its own window.
window_size
Set the created window size, can be a string of the form
widthxheight or a video size abbreviation. If not
specified it defaults to the size of the input video.
Ignored when window_id is set.
window_x
window_y
Set the X and Y window offsets for the created window. They are both
set to 0 by default. The values may be ignored by the window manager.
Ignored when window_id is set.
window_title
Set the window title, if not specified default to the filename
specified for the output device. Ignored when window_id is set.
For more information about XVideo see http://www.x.org/.
27.12.2 Examples
Decode, display and encode video input with ffmpeg at the
same time:
ffmpeg -i INPUT OUTPUT -f xv display
Decode and display the input video to multiple X11 windows:
ffmpeg -i INPUT -f xv normal -vf negate -f xv negated